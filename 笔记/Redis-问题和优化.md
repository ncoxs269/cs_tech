2025-11-26 16:03
Status: #idea
Tags:

# 1 缓存三大问题
## 1.1 缓存雪崩
缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理。应用将大量请求发送到数据库层，导致数据库层的压力激增。
原因和处理如下：
1. 第一个原因是有**大量数据同时过期**，处理方法：给过期时间加一个较小的随机数。
2. 第二个原因是**Redis 缓存实例故障宕机**，处理方法如下：
	1. 在业务系统中实现服务熔断或请求限流机制：当 Redis 不可用时，对数据库的请求进行限流；或者直接返回 "活动繁忙，请稍后再试"，不请求数据库。
	2. Redis 采用集群架构（如 3 主 3 从），避免单点故障
3. 第三个原因是**一致性hash环的集群特性**导致的：集群中某个节点挂掉了，请求分散到其他集群，但把其他集群也都冲垮了。 解决办法：如果场景是热的极热、冷的极冷，不建议使用一致性hash环。

## 1.2 缓存击穿
缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。
缓存击穿的情况，**经常发生在热点数据过期失效时**。

为了避免缓存击穿给数据库带来的激增压力，解决方法：
1. 对于访问特别频繁的热点数据不设置or设置比业务时间长的过期时间。
2. 访问数据时，刷新过期时间；
3. 如果访问太频繁可以定时刷新过期时间。
 
此外对数据库的访问要做好限流和熔断。

## 1.3 缓存穿透
缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。这样一来，缓存也就成了“摆设”，如果应用持续有大量请求访问数据，就会同时给缓存和数据库带来巨大压力。

一般来说，有两种情况：
- 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；
- 恶意攻击：专门访问数据库中没有的数据。

解决方法：
1. **第一种方案是，缓存空值或缺省值**。一旦发生缓存穿透，我们就可以针对查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值（例如，库存的缺省值可以设为 0）。这种情况的失效时间都设置比较短
2. **第二种方法是，使用布隆过滤器快速判断数据是否不存在，避免从数据库中查询数据是否存在，减轻数据库压力**。
	- 布隆过滤器由一个初值都为 0 的 bit 数组和 N 个哈希函数组成，可以用来快速判断某个数据是否存在。当我们想标记某个数据存在时（例如，数据已被写入数据库），布隆过滤器会通过三个操作完成标记：
		1. 首先，使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值。
	    2. 然后，我们把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置。
	    3. 最后，我们把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作。
    - **注意Redis实现的布隆过滤器bigkey问题**：Redis布隆过滤器是使用String类型实现的，存储的方式是一个bigkey，建议使用时单独部署一个实例，专门存放布隆过滤器的数据，不要和业务数据混用，否则在集群环境下，数据迁移时会导致Redis阻塞问题。
    - **预加载**：应用刚启动的时候，布隆过滤器全是0，所以需要预加载，把数据库的数据都来过滤器这边设置一遍。
    - TODO:
	    - 布隆过滤器和数据库一致性问题
	    - 删除数据后，怎么处理布隆过滤器？
3. **最后一种方案是，在请求入口的前端进行请求检测**。缓存穿透的一个原因是有大量的恶意请求访问不存在的数据。

# 2 BigKey
## 2.1 定义
Bigkey 是指 占用内存过大或元素数量过多 的 Redis Key，没有统一标准，通常参考：
- 字符串类型：体积 > 10KB（或根据业务调整为 50KB/100KB）；
- 集合类型（Hash/List/Set/ZSet）：元素数量 > 10000 个，或整体体积 > 100KB。

Bigkey 会导致：内存碎片化、主从同步延迟、过期删除 / DEL 命令阻塞、网络带宽占用过高 等问题。

## 2.2 Bigkey 发现与排查
核心思路：**非阻塞扫描 + 精确统计 + 监控预警**，避免使用 `KEYS *`（阻塞全量扫描）。

### 2.2.1 直接排查工具 / 命令
1. `redis-cli --bigkeys`（最常用）
	- 功能：非阻塞扫描所有 Key，按类型（string/hash/list/set/zset）统计 **最大 Key 的体积 / 元素数**，并输出整体分布；
	- 原理：基于 `SCAN` 迭代扫描，不会阻塞 Redis 主线程；
	- 用法：`redis-cli -h 127.0.0.1 -p 6379 -a password --bigkeys`
2. `MEMORY USAGE key [SAMPLES count]`（精确统计单 Key 内存）
	- 功能：返回 Key 的 **实际占用内存（包括元数据）**，集合类型可通过 `SAMPLES` 指定抽样字段数（默认 5）；
	- 用法：`MEMORY USAGE order:detail:202405 SAMPLES 100`
3. `SCAN` 迭代扫描 + 批量统计
	- 场景：需要自定义筛选条件（如只查哈希类型、按体积阈值过滤）；
	- 原理：`SCAN cursor MATCH pattern COUNT count` 非阻塞迭代，配合 `TYPE`/`MEMORY USAGE` 过滤，自己写代码实现流程

### 2.2.2 监控预警工具
1. Redis 自带监控
	- `INFO memory`：查看整体内存占用、碎片率，间接判断是否有 Bigkey（如内存突增但 Key 数少）；
	- `INFO replication`：主从同步延迟（Bigkey 同步占用带宽，延迟 > 1s 需警惕）；
	- 慢查询日志：`CONFIG SET slowlog-log-slower-than 10000`（记录 >10ms 命令），Bigkey 的 `GET`/`HGETALL`/`DEL` 易触发。
2. 第三方监控
	- Redis Insight：可视化 Key 大小、类型分布，支持筛选 Bigkey；
	- Prometheus + Grafana：通过 `redis_key_size`（需 exporter 采集）指标设置告警（如 Key 大小 > 50KB 报警）；
	- 业务监控：记录 Redis 命令耗时，若 `GET`/`HGETALL` 等命令耗时突增，可能是 Bigkey 导致。

## 2.3 Bigkey 解决方法
核心原则：**拆分（优先）、压缩、异步删除、替换存储**，避免直接 `DEL` 阻塞。

### 2.3.1 按 Key 类型针对性处理
1. 字符串类型（大文本 / 二进制）
	- 拆分：将大字符串按固定大小拆分（如 10KB / 段），存储为 `key:1`、`key:2`，读取时拼接；
	    - 示例：用户头像（20KB）→ 拆分为 `avatar:10086:1`（10KB）、`avatar:10086:2`（10KB）；
	- 压缩：用 `gzip` 压缩后存储（需业务层解压），适合文本类数据（压缩比可达 3-10 倍）；
	- 替换存储：大文件（如 >1MB）迁移至对象存储（OSS/S3），Redis 只存文件 URL 或索引。
2. 哈希类型（字段过多，如 >10000 个）
	- 分片拆分：按字段前缀 / 哈希取模拆分到多个哈希表；
    - 示例：订单详情 `order:detail`（10 万字段）→ 按用户 ID 取模 `order:detail:{uid%100}`，拆分到 100 个哈希表；
	- 冷热分离：只保留热点字段在 Redis，冷字段迁移至 MySQL/ES。
3. 列表类型（元素过多，如日志 / 消息队列）
	- 按时间分片：按天 / 小时拆分列表，如 `log:20240520`、`log:20240521`，定期删除历史列表；
	- 限制长度：用 `LPUSH + LTRIM` 组合，只保留最近 N 个元素（如 `LTRIM log:latest 0 9999` 保留 1 万条）；
	- 替换存储：高吞吐场景用 Kafka/RabbitMQ 替代 Redis 列表做消息队列。
4. 集合 / 有序集合（元素过多）
	- 分片拆分：按元素哈希取模拆分，如 `user:tags:{uid%50}`，拆分到 50 个集合；
	- 冷热分离：热点元素保留在 Redis，冷元素迁移至 ES/ClickHouse。

### 2.3.2 安全删除 Bigkey（避免阻塞）
1. Redis 4.0+：`UNLINK` 命令（推荐），异步删除 Key，主线程只标记 Key，后台线程异步清理内存，无阻塞；
2. 分批删除集合类型 Bigkey
	- 哈希：`HSCAN` 迭代删除字段（每次删 100 个，避免阻塞）
	- 列表：`LPOP/RPOP` 分批删除（每次删 1000 个）
	- 集合 / ZSet：`SSCAN/ZSCAN` 迭代删除元素，逻辑同哈希。

## 2.4 避免 Bigkey 出现的最佳实践
1. 设计层面：提前规避
	- 数据分片标准化：
	    - 集合类型：单 Key 元素数上限控制（如 ≤ 5000 个），超过则自动分片；
	    - 字符串类型：单 Key 体积上限（如 ≤ 10KB），大数据优先用对象存储；
	- Key 结构设计：
	    - 避免用 `all:xxx` 类 Key（如 `all:users` 存储所有用户），改为按维度分片（`user:10086`、`user:10087`）；
	    - 哈希类型：按业务模块拆分字段（如 `user:info:10086` 存基础信息，`user:tags:10086` 存标签），避免单哈希存所有字段。
2. 开发层面：规范操作
	- 禁用高危命令：
	    - 集合类型：禁用 `HGETALL`/`SMEMBERS`/`ZRANGEBYSCORE 0 +inf`（全量获取元素），改用 `HSCAN`/`SSCAN` 迭代获取；
	    - 字符串类型：避免存储大文本 / 二进制，优先存索引 / ID；
	- 序列化优化：用 Protocol Buffers（PB）替代 JSON（体积小 30%-50%），减少单 Key 体积；
	- 过期策略：给 Key 设置合理过期时间（`EXPIRE`），避免数据长期堆积形成 Bigkey。
3. 监控层面：提前预警
4. 运维层面：兜底保障
	- 内存碎片清理：开启 Redis 自动内存碎片整理（`CONFIG SET activedefrag yes`），避免 Bigkey 删除后产生大量碎片；
	- 定期数据迁移：将冷数据从 Redis 迁移至低成本存储（如 MySQL/ES），保持 Redis 存储热点数据。

---
# 3 引用
2025-05-11 16:49
Status: #idea
Tags:

# 1 场景题
## 1.1 问题排查处理
### 1.1.1 程序响应变慢排查
- 服务器负载过高：检查服务器的CPU、内存使用率。
- 数据库查询效率低下：慢查询日志
- 检查网络：是不是网络带宽不足或不稳定
- 查询数据量过大
- 外部依赖（如第三方服务）响应慢

## 1.2 TOP K 问题
### 1.2.1 10亿个数据中找出最大的10000个
#### 1.2.1.1 最小堆法
1. 先拿10000个数建堆
2. 然后逐个添加剩余元素
3. 如果大于堆顶的数（10000中最小的），将这个数替换堆顶，并调整结构使之仍然是一个最小堆
4. 遍历完后，堆中的10000个数就是所需的最大的10000个。

复杂度分析：时间复杂度是 O(nlogk)，空间复杂度 O(k)。

#### 1.2.1.2 优化
##### 1.2.1.2.1 并行计算
可以通过并行计算（多线程或者分布式运算）的方式进一步提高算法效率：
1. 通过Hash方法将n个数据随机切分成m份，需要的时间复杂度为 O(n)
2. 对于m份数据并行使用小顶堆选出最大的k个数据，需要的时间复杂度为 O(n/m\*logk) （因为是并行的），运算完后得到m组长度为k的小顶堆
3. 最后在合并节点上，同样使用大小为k的最小堆，将所有候选数依次插入堆中。最终堆中的k个数就是全局前k大的数

由于第二步和第三步可以并行计算，因此总的时间复杂度为：
$$
O(n + \frac{n}{m}\log_2k + mk\log_2k)
$$
对比没有并行的小顶堆算法，可以发现算法得到了常数级别的优化。

##### 1.2.1.2.2 数据倾斜
该方法存在一个瓶颈会明显影响效率，即数据倾斜。每个线程的处理速度可能不同，快的线程需要等待慢的线程，最终的处理速度取决于慢的线程。
解决的方法是，将数据划分成c×n个partition（c>1），每个线程处理完当前partition后主动取下一个partition继续处理，直到所有数据处理完毕。

### 1.2.2 有几台机器存储着几亿淘宝搜索日志，你只有一台 2g 的电脑，怎么选出搜索热度最高的十个？
针对top k类文本问题，通常比较好的方案是【**分治+trie树/hash+小顶堆**】，即
1. 先将数据集按照hash方法分解成多个小数据集
2. 然后使用trie树或者hash统计每个小数据集中的query词频
3. 之后用小顶堆求出每个数据集中出频率最高的前K个数
4. 最后用小顶堆在所有top K中求出最终的top K。

注意，如果总的不重复key比较少，并且key长度不长（1G约为10.7亿字节），那么就不用拆分，直接一个hash表就能装下。
可以看到，这个是 topK 问题的变种。只需要先预处理一下，求出每个key的频率，然后针对频率求 topK 即可。

### 1.2.3 100GB日志文件，存储滴滴下单的记录，每条记录包含司机ID和订单ID。求下单数量前10的司机
也是 topK 的变种。预处理如下：
1. 先将数据集按照hash方法（hash司机ID）分解成多个小数据集
2. 统计小数据集中，每个司机的订单数
3. 然后就是 topK问题了

### 1.2.4 从十亿数据中找到升序的第七亿个数
#### 1.2.4.1 快排
1. 随机挑一个元素作为基准值，将数据partition为`[left,mid-1]`和`[mid,right]`两个区间，其中`[left,mid-1]`的数都小于base值，`[mid,right]`都大于等于base值
2. 计算`[mid, right]`数组长度L：  
	- 如果L等于三亿，那么`[left,mid-1]`中的七亿个数字小于`[mid,right]`中的三亿个数字，只需要在`[left,mid-1]`中找到最大值即可
	- 如果L大于三亿，则将问题转化为在`[mid, right]`中找到第（L-三亿）个数
	- 如果L小于三亿则问题还是在`[left,mid-1]`中找到第七亿大的数

#### 1.2.4.2 桶排序
假如数据的范围是有限的（有最大值和最小值）且较均匀分布，那么使用桶排序可以进一步提升效率：
1. 获取数据的max和min
2. 将所有的n份数据分到m个文件中，同时记录每份子文件中的数据量
3. 从小到大累加文件数据量，找到第七亿个数所在的文件，记录前面文件的总数据量count
4. 将问题转化为在第七亿个数所在的文件中寻找第（七亿-count）个数

## 1.3 海量数据排序、去重问题
### 1.3.1 对十亿数据进行排序
使用多路归并排序：
1. 分割文件和小文件排序：将大文件中的n个数据分散到k个小文件中，对每一个小文件进行内存排序。时间复杂度 O(n + n/k\*log(n/k))
2. 多路归并排序，时间复杂度 O(nlogk)
	1. 读取每个有序文件中的第一个数（即该文件的最小数）及其文件索引，存放在大小为k的小根堆中。
	2. 取出小根堆中的根节点写入缓冲区（缓冲区满自动写入目标文件），同时读取根节点索引对应的小文件下一个数作为新的根节点，调整小根堆
	3. 重复step2，如果某个小文件为空则小根堆长度减一，直到取出所有的小文件中的数

### 1.3.2 对10亿数进行去重
#### 1.3.2.1 分片哈希去重
1. 使用均匀分布的哈希函数（如MD5、SHA-1或自定义哈希），将每条数据映射到固定数量的分片中。确保每个分片都能装入内存
2. 每个分片，使用hash表去重，结果写入最终输出文件

#### 1.3.2.2 位图
如果数字非负，并且范围不大，可以用bitmap。

#### 1.3.2.3 simhash
https://cloud.tencent.com/developer/article/1379302?from=14588

## 1.4 并发
### 1.4.1 如果一个外卖配送单子要发布，现在有200个骑手都想要接这一单，如何保证只有一个骑手接到单子？
- redis分布式锁
- mysql悲观锁、乐观锁

### 1.4.2 1000个任务分给10个人做
全局队列，每一个人都从一个队列中取一部分任务。
同时每个人自己有个队列。

## 1.5 中间件
### 1.5.1 如何用redis存储统计1亿用户一年的登陆情况，并快速检索任意时间窗口内的活跃用户数量
redis单独对bitmap提供了一套命令。可以对任意一位进行设置和读取。所以可以在位图中使用1表示活跃。
- `SETBIT`：设置某位为1
- `GETBIT`：获取某位的值
- 其他命令还有`bitcount，bitpos，bitop`等

因此问题可以拆解为：
1. 获取某一天id为88000的用户是否活跃：`getbit 2020-01-01 88000`。时间复杂度为O(1)
2. 统计某一天的所有的活跃用户数：`bitcount 2019-01-01`。时间复杂度为O(N)
3. 统计某一段时间内的活跃用户数，需要用到 `bitop` 命令。这个命令提供四种位运算，AND(与)，(OR)或，XOR(亦或)，NOT(非)。我们可以对某一段时间内的所有key进行OR(或)操作，或操作出来的位图是0的就代表这段时间内一次都没有登陆的用户。那只要我们求出1的个数就可以了

以下例子求出了2019-01-01到2019-01-05这段时间内的活跃用户数：
```bash
bitop or result 2019-01-01 2019-01-02 2019-01-03 2019-01-04 2019-01-05
bitcount result
```

## 1.6 其他知识
### 1.6.1 499状态码是什么
499是nginx记录的状态码。499产生的核心原因是**客户端在nginx完成响应之前断开了连接**。
- 可以不太严谨的概括就是**nginx完成的响应时间超过了客户端的超时时间。** 
- 如果客户端在nginx处理请求这个区间内，断开了连接，那么nginx就会返回499

# 2 设计题
## 2.1 库存管理设计
### 2.1.1 redis库存
#### 2.1.1.1 lua脚本实现原子性
常用方案redis+lua，借助redis单线程执行+lua脚本中的逻辑，可在一次执行中顺序完成的特性达到原子性（叫排它性更准确，因为不具备回滚动作，异常情况需自己手动编码回滚）：
```lua
-- 1. 获取库存缓存key KYES[1] = hot_{itemCode-skuCode}_stock
local hot_item_stock = KYES[1]

-- 2. 获取剩余库存数量
local stock = tonumber(redis.call('get', hot_item_stock))

-- 3. 购买数量
local buy_qty = tonumber(ARGV[1])

-- 4. 如果库存小于购买数量，则返回1，表达库存不足
if stock < buy_qty then
  return 1
end

-- 5. 库存足够，更新库存数量
stock = stock - buy_qty
redis.call('set', hot_item_stock, tostring(stock))

-- 6. 扣减成功则返回2，表达库存扣减成功
return 2
```

#### 2.1.1.2 幂等性和可追溯性
但脚本还有一些问题：
- 不具备幂等性，同个订单多次执行会导致重复扣减，手动回滚也无法判断是否会回滚过，会出现重复增加的问题    
- 不具备可追溯性，不知道库存被谁被哪个订单扣减了

增强后的lua脚本：
```lua
-- 1. 获取库存扣减记录缓存 key KYES[2] = hot_{itemCode-skuCode}_deduction_history
local  hot_deduction_history = KYES[2]

-- 2. 使用 Redis Cluster hash tag 保证 stock 和 history 在同一个槽
local exist = redis.call('hexists', hot_deduction_history, ARGV[2])
-- 3. 请求幂等判断,存在返回0,表达已扣减过库存
if exist == 1 then return 0 end

-- 4. 获取库存缓存key KYES[1] = hot_{itemCode-skuCode}_stock
local hot_item_stock = KYES[1]

-- 5. 获取剩余库存数量
local stock = tonumber(redis.call('get', hot_item_stock))

-- 6. 购买数量
local buy_qty = tonumber(ARGV[1])

-- 7. 如果库存小于购买数量 则返回1,表达库存不足
if stock < buy_qty then return 1 end

-- 8. 库存足够
-- 9. 1.更新库存数量
-- 10. 2.插入扣减记录 ARGV[2] = ${扣减请求唯一key} - ${扣减类型} 值为 buy_qty
stock = stock - buy_qty
redis.call('set', hot_item_stock, tostring(stock))
redis.call('hset', hot_deduction_history, ARGV[2], buy_qty)

-- 11. 如果剩余库存等于0则返回2,表达库存已为0
if stock == 0 then return 2 end

-- 12. 剩余库存不为0返回 3 表达还有剩余库存
return 3 end
```
利用Redis Cluster hash tag保证stock和history在同个槽，这样lua脚本才能正常执行。

回滚逻辑先判断hot_deduction_history里有没有 ${扣减请求唯一key}：
- 有，则执行回补逻辑，并删除唯一key
- 没有，则认定回补成功

#### 2.1.1.3 防悬挂
但这个回滚逻辑仍然有问题，不能防悬挂（订单取消的回滚请求先到，扣减请求后到）。
所以可以设计两个 deduction_history，一个保存正常请求，一个保存回滚请求（正常请求和回滚请求的key是一样的）。

正常请求：
- 如果 key 不在两个 history 中，则执行
- 如果 key 在两个 history 中任意一个，则不执行

回滚请求：
- 如果 key 在正常 history 中，且不在回滚 history 中，则执行
- 如果 key 不在两个 history 中，则把 key 写入回滚 history，不执行回滚

#### 2.1.1.4 高可用
运用Redis部署的高可用方案：
- 采用Redis Cluster（数据分片+ 多副本 + 同步多写 + 主从自动选举）
- 多写节点分（同城异地）多中心防止意外灾害

定期归档冷数据。定期 + 库存为0触发redis数据往DB同步。

部分头部电商采用弱缓存抗读（非库存不足，不实时更新），DB抗写的方案。该方案前提在于，通过一系列技术方案，流量落到库存已相对低且平滑了（扛得住，不用再自己实现操作原子性）。

## 2.2 抢红包系统设计
### 2.2.1 背景
和秒杀类型，抢红包也是读多写少。
抢红包有 3 个核心流程：**红包金额拆分->抢红包->打款**。

包红包、发红包、抢红包、拆红包
红包过期退款
难点分析：
- 不能超发
- 支持高并发：1亿用户抢红包
- 红包金额什么时候算、怎么算
- 打款

### 2.2.2 红包表结构
红包主表：
```sql
CREATE TABLE `t_redpack_activity`
(
    `id`         bigint(20)     NOT NULL COMMENT '主键',
    `total_amount`     decimal(10, 2) NOT NULL DEFAULT '0.00' COMMENT '总金额',
    `surplus_amount`     decimal(10, 2) NOT NULL DEFAULT '0.00' COMMENT '剩余金额',
    `total` bigint(20)     NOT NULL DEFAULT '0' COMMENT '红包总数',
    `surplus_total` bigint(20)     NOT NULL DEFAULT '0' COMMENT '红包剩余总数',
    `user_id`    bigint(20)     NOT NULL DEFAULT '0' COMMENT '用户编号',
    `version` bigint(20)     NOT NULL DEFAULT '0' COMMENT '版本号',
    PRIMARY KEY (`id`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8;
```

子红包表：
```sql
CREATE TABLE `t_redpack`
(
    `id`         bigint(20)     NOT NULL COMMENT '主键',
    `activity_id`         bigint(20)     NOT NULL DEFAULT 0 COMMENT '红包活动ID',
    `amount`     decimal(10, 2) NOT NULL DEFAULT '0.00' COMMENT '金额',
    `status`     TINYINT(4) NOT NULL DEFAULT 0 COMMENT '红包状态 1可用 2不可用',
    `version` bigint(20)     NOT NULL DEFAULT '0' COMMENT '版本号',
    PRIMARY KEY (`id`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8;
```

抢红包明细表：
```sql
CREATE TABLE `t_redpack_detail`
(
    `id`         bigint(20)     NOT NULL COMMENT '主键',
    `amount`     decimal(10, 2) NOT NULL DEFAULT '0.00' COMMENT '金额',
    `user_id`    bigint(20)     NOT NULL DEFAULT '0' COMMENT '用户编号',
    `redpack_id` bigint(20)     NOT NULL DEFAULT '0' COMMENT '红包编号',
    `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    `update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (`id`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8;
```

因为有了抢红包明细表，所以用户查询红包记录就可以用这个表。
而红包表就可以跳过分库分表拆分。

### 2.2.3 数据库方案
#### 2.2.3.1 发红包流程
![[image-137.png]]

#### 2.2.3.2 抢红包流程
![[image-138.png]]

### 2.2.4 缓存方案
#### 2.2.4.1 发红包流程
![[image-139.png]]

#### 2.2.4.2 抢红包流程
![[image-140.png]]

### 2.2.5 SET化方案
![[image-143.png]]

![[image-144.png]]
![[image-145.png]]

### 2.2.6 拆分方案
#### 2.2.6.1 实时拆分
实时拆分，指的是在**抢红包时实时计算**每个红包的金额，以实现红包的拆分过程，对系统性能和拆分算法要求较高，例如拆分过程要一直保证后续待拆分红包的金额不能为空，不容易做到拆分的红包金额服从正态分布规律。

![[image-148.png]]

#### 2.2.6.2 预先生成
预先生成，指的是在红包**开抢之前**已经完成了红包的**金额拆分**，抢红包时只是依次取出拆分好的红包金额，对拆分算法要求较低，可以拆分出随机性很好的红包金额，通常需要结合队列使用。

通常使用 **二倍均值法** 的算法拆分红包金额。拆分算法可以描述为：假设剩余拆分金额为 M，剩余待拆分红包个数为 N，红包最小金额为 1 元，那么定义当前红包的金额为：
```go
m=rand(1,floor(M/N∗2))
```
因为 N >= 2，所以 M/N\*2 <= M，表示一定能保证后续红包能拆分到金额。

![[image-146.png]]

![[image-147.png]]

### 2.2.7 限流
和秒杀系统一样。不过抢红包一般是内部系统，不需要针对性限流。

![[image-141.png]]

### 2.2.8 数据库分库分表优化
![[image-142.png]]

### 2.2.9 打款
打款可以用消息队列异步实现。

### 2.2.10 抢红包
#### 2.2.10.1 mysql抢红包
当多个 client 抢红包时，获取该活动下所有可用的红包明细，随机返回其中一条然后再去更新，更新成功则代表用户抢到了该红包，失败则代表出现了冲突，可以循环进行重试。
因为红包明细有多个，这样冲突也降低了。

#### 2.2.10.2 Redis队列方案
选用队列串行化的方案，抢红包整个过程只会操作 Redis，且都是简单高效的 Pop 和 Push 命令操作。
抢红包流程：先从红包队列中 **Pop** **占有红包**，然后 Push 红包到消息队列（待异步打款处理），并同步告知用户抢到红包的结果，抢红包流程就结束了。

当然，在实际应用中，占有红包过程中还会有一些前置规则校验，比如用户是否已经领取过，领取次数是否已经达到上限等？红包占有流程图如下：
![[image-136.png]]
使用lua脚本保证抢红包的原子性。

---
# 3 引用
[499状态码](https://blog.csdn.net/weixin_40619578/article/details/133646797)
[redis库存设计](https://www.cnblogs.com/JavaEdge/p/18381724)
[秒杀系统设计](https://cloud.tencent.com/developer/article/1863530)
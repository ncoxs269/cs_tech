2025-10-30 16:22
Status: #idea
Tags: [[场景题和设计题]]

# 1 前言
**秒杀其实主要解决两个问题，一个是并发读，一个是并发写**。
- 并发读的核心优化理念是尽量减少用户到服务端来“读”数据，或者让他们读更少的数据；
- 并发写的处理原则也一样，它要求我们在数据库层面独立出来一个库，做特殊的处理。
另外，我们还要针对秒杀系统做一些保护，针对意料之外的情况设计**兜底方案**，以防止最坏的情况发生。

秒杀的整体架构可以概括为“稳、准、快”几个关键字。
- 所谓“稳”，就是整个系统架构要满足**高可用**，流量符合预期时肯定要稳定，就是超出预期时也同样不能掉链子
- 然后就是“准”，一旦库存不对，那平台就要承担损失，所以“准”就是要求保证数据的**一致性**。
- 最后再看“快”，也就是**高性能**，不光是服务端要做极致的性能优化，而且在整个请求链路上都要做协同的优化，每个地方快一点，整个系统就完美了。
在整个用户请求路径上从浏览器到服务端我们要遵循几个**架构原则**，就是要**保证用户请求的数据尽量少、请求数尽量少、路径尽量短、依赖尽量少，并且不要有单点**。

# 2 架构原则
## 2.1 原则分类
### 2.1.1 数据尽量少
**首先是指用户请求的数据能少就少**。请求的数据包括上传给系统的数据和系统返回给用户的数据（通常就是网页）。
服务器在写网络时通常都要做压缩和字符编码，这些都非常消耗 CPU，所以减少传输的数据量可以显著减少 CPU 的使用。

**其次，“数据要尽量少”还要求系统依赖的数据能少就少**，包括系统完成某些业务逻辑需要读取和保存的数据，这些数据一般是和后台服务以及数据库打交道的。调用其他服务会涉及数据的序列化和反序列化，而这也是 CPU 的一大杀手，同样也会增加延时。而且，数据库本身也容易成为一个瓶颈，所以和数据库打交道越少越好，数据越简单、越小则越好。

### 2.1.2 请求数要尽量少
用户请求的页面返回后，浏览器渲染这个页面还要包含其他的**额外请求**，比如说，这个页面依赖的 CSS/JavaScript、图片，以及 Ajax 请求等等都定义为“额外请求”，这些额外请求应该尽量少。
因为浏览器每发出一个请求都多少会有一些消耗，例如建立连接要做三次握手，有的时候有页面依赖或者连接数限制，一些请求（例如 JavaScript）还需要串行加载等。另外，如果不同请求的域名不一样的话，还涉及这些域名的 DNS 解析，可能会耗时更久。
所以你要记住的是，减少请求数可以显著减少以上这些因素导致的资源消耗。

例如，减少请求数最常用的一个实践就是合并 CSS 和 JavaScript 文件，把多个 JavaScript 文件合并成一个文件，在 URL 中用逗号隔开（https://g.xxx.com/tm/xx-b/4.0.94/mods/??module-preview/index.xtpl.js,module-jhs/index.xtpl.js,module-focus/index.xtpl.js）。这种方式在服务端仍然是单个文件各自存放，只是服务端会有一个组件解析这个 URL，然后动态把这些文件合并起来一起返回。
不过现在浏览器都会有缓存，而且vue等框架会压缩合并静态资源，所以上面的技巧用处不大了。

### 2.1.3 路径要尽量短
所谓“路径”，就是用户发出请求到返回数据这个过程中，需求经过的中间的节点数。通常，这些节点可以表示为一个系统或者一个新的 Socket 连接（比如代理服务器只是创建一个新的 Socket 连接来转发请求）。每经过一个节点，一般都会产生一个新的 Socket 连接。
**要缩短访问路径有一种办法，就是多个相互强依赖的应用合并部署在一起，把远程过程调用（RPC）变成 JVM 内部之间的方法调用**。在《大型网站技术架构演进与性能优化》一书中，我也有一章介绍了这种技术的详细实现。

### 2.1.4 依赖要尽量少
这里的依赖指的是**强依赖**。比如说你要展示秒杀页面，而这个页面必须强依赖商品信息、用户信息，还有其他如优惠券、成交列表等这些对秒杀不是非要不可的信息（弱依赖），这些弱依赖在紧急情况下就可以去掉。

**要减少依赖，我们可以给系统进行分级**，比如 0 级系统、1 级系统、2 级系统、3 级系统，0 级系统如果是最重要的系统，那么 0 级系统强依赖的系统也同样是最重要的系统，以此类推。
注意，0 级系统要尽量减少对 1 级系统的强依赖，防止重要的系统被不重要的系统拖垮。例如支付系统是 0 级系统，而优惠券是 1 级系统的话，在极端情况下可以把优惠券给降级，防止支付系统被优惠券这个 1 级系统给拖垮。

### 2.1.5 不要有单点
那如何避免单点呢？**我认为关键点是避免将服务的状态和机器绑定，即把服务无状态化**，这样服务就可以在机器中随意移动。
如何那把服务的状态和机器解耦呢？这里也有很多实现方式。**例如把和机器相关的配置动态化，这些参数可以通过配置中心来动态推送**，在服务启动时动态拉取下来，我们在这些配置中心设置一些规则来方便地改变这些映射关系。

应用无状态化是有效避免单点的一种方式，但是像存储服务本身很难无状态化，因为数据要存储在磁盘上，本身就要和机器绑定，那么**这种场景一般要通过冗余多个备份的方式来解决单点问题**。

## 2.2 架构是平衡的艺术
前面介绍了这些设计上的一些原则，但是你有没有发现，我一直说的是“尽量”而不是“绝对”？
我们曾经把有些 CSS 内联进页面里，这样做可以减少依赖一个 CSS 的请求从而加快首页的渲染，但是同样也增大了页面的大小，又不符合“数据要尽量少”的原则，这种情况下我们为了提升首屏的渲染速度，只把首屏的 HTML 依赖的 CSS 内联进来，其他 CSS 仍然放到文件中作为依赖加载，尽量实现首屏的打开速度与整个页面加载性能的平衡。
所以说，**架构是一种平衡的艺术**，而最好的架构一旦脱离了它所适应的场景，一切都将是空谈。

## 2.3 不同场景下的不同架构案例
针对“秒杀”这个场景，怎样才是一个好的架构呢？下面我以淘宝早期秒杀系统架构的演进为主线，来帮你梳理不同的请求体量下，我认为的最佳秒杀系统架构。

如果你想快速搭建一个简单的秒杀系统，只需要把你的商品购买页面增加一个“定时上架”功能，仅在秒杀开始时才让用户看到购买按钮，当商品的库存卖完了也就结束了。这就是当时第一个版本的秒杀系统实现方式。

但随着请求量的加大（比如从 1w/s 到了 10w/s 的量级），这个简单的架构很快就遇到了瓶颈，因此需要做架构改造来提升系统性能。这些架构改造包括：
1. **独立系统**：把秒杀系统独立出来单独打造一个系统，这样可以有针对性地做优化
2. **独立集群**：在系统部署上也独立做一个机器集群，这样秒杀的大流量就不会影响到正常的商品购买集群的机器负载；
3. **缓存热点数据**：将热点数据（如库存数据）单独放到一个缓存系统中，以提高“读性能”；
4. **防刷**：增加秒杀答题，防止有秒杀器抢单。
此时的系统架构变成了下图这个样子。最重要的就是，秒杀详情成为了一个独立的新系统，另外核心的一些数据放到了缓存（Cache）中，其他的关联系统也都以独立集群的方式进行部署。
![[image-169.png]]

然而这个架构仍然支持不了超过 100w/s 的请求量，所以为了进一步提升秒杀系统的性能，我们又对架构做进一步升级，比如：
1. **动静分离**：对页面进行彻底的动静分离，使得用户秒杀时不需要刷新整个页面，而只需要点击抢宝按钮，借此把页面刷新的数据降到最少；
2. **本地缓存**：在服务端对秒杀商品进行本地缓存，不需要再调用依赖系统的后台服务获取数据，甚至不需要去公共的缓存集群中查询数据，这样不仅可以减少系统调用，而且能够避免压垮公共缓存集群。
	1. 这么优化主要是根据秒杀系统中的商品特性有关系，秒杀的商品基本不会临时再变动属性。前期上传审核成功后，就会做热点数据处理。
	2. 这里应用服务器有状态了，但为了极致的性能，不得已而为之
	3. 注意库存不会放在本地缓存，**本地缓存只放静态数据**。 库存是放在独立的缓存系统里，如redis。库存是采用主动失效的方式来失效缓存
3. **系统限流**：增加系统限流保护，防止最坏情况发生。
经过这些优化，系统架构变成了下图中的样子。最关键的详情和交易系统都增加了本地缓存，来提前缓存秒杀商品的信息，热点数据库也做了独立部署，等等。
![[image-170.png]]

秒杀的场景来说，不同QPS量级下瓶颈也会不一样，**10w级别可能瓶颈就在数据读取上**，通过增加缓存一般就能解决，**如果要到100w那么，可能服务端的网络可能都是瓶颈**，所以要把大部分的静态数据放到cdn上甚至缓存在浏览器里
**其实越到后面需要定制的地方越多，也就是越“不通用”**。例如，把秒杀商品缓存在每台机器的内存中，这种方式显然不适合太多的商品同时进行秒杀的情况，因为单机的内存始终有限。所以要取得极致的性能，就要在其他地方（比如，通用性、易用性、成本等方面）有所牺牲。

## 2.4 一些问题
- 通过什么方式往本地cache 写数据呢？
用订阅的方式，在系统初始化时加载到内存

- 秒杀系统的及时性非常高，把库存写进cache ，怎么及时更新呢？
有两种方法，一是定时更新取3秒；二是主动更新，数据库字段更新后发消息更新缓存，这个需要用到一个组件阿里叫metaq，就是数据库字段更新会产生一条消息，集群的环境下通过消息通知所有机器去更新缓存。
另外cache里库存不需要100%和数据库一致。缓存没有必要极致追求数据的准确性，只要保证最终一致性。缓存本身为了减少数据库的压力。

- 我对秒杀系统有个最大的疑惑，就是从页面发出的请求用同步还是异步？如果用同步的话：1，后端服务必然是分布式的，需要经过多个节点，时间可能会被拉的很长，同时失败的可能性也会增大；2，基于1的情况，会有一个长连接长时间存在，这样随着请求的增多，连接资源越来越少，系统吞吐量会是瓶颈。如果用异步的话：不断的轮询必然会增加系统的请求量，对连接资源也是一种浪费。所以，这应该怎么选择呢？
可以异步处理完后websocket推动前端

- 秒杀系统压测工具哪个比较好？
Apache ab就很好

# 3 动静分离
## 3.1 定义
所谓“动静分离”，其实就是把用户请求的数据（如 HTML 页面）划分为“动态数据”和“静态数据”。
**“动态数据”和“静态数据”的主要区别就是看页面中输出的数据是否和 URL、浏览者、时间、地域相关，以及是否含有 Cookie 等私密数据**。比如说：
1. 很多媒体类的网站，某一篇文章的内容不管是你访问还是我访问，它都是一样的。所以它就是一个典型的静态数据
2. 如果现在访问淘宝的首页，每个人看到的页面可能都是不一样的，淘宝首页中包含了很多根据访问者特征推荐的信息，而这些个性化的数据就可以理解为动态数据了。
**简单来说就是数据中是否含有和访问者相关的个性化数据**。

时间要以服务端为准，客户端的时间用户可以自己修改。

## 3.2 怎样对静态数据做缓存
怎样对静态数据做缓存呢？我在这里总结了几个重点。
**第一，你应该把静态数据缓存到离用户最近的地方**。常见的就三种，用户浏览器里、CDN 上或者在服务端的 Cache 中。你应该根据情况，把它们尽量缓存到离用户最近的地方。
**第二，静态化改造就是要直接缓存 HTTP 连接**。Web 代理服务器根据请求 URL，直接取出对应的 HTTP 响应头和响应体然后直接返回，这个响应过程简单得连 HTTP 协议都不用重新组装，甚至连 HTTP 请求头也不需要解析。
	URL唯一化，如果是https协议的链接，缓存还生效吗？
	阿里已经做过https的改造，不会直接缓存https的链接，在https只会在网站接入层的最外层，在服务器内部之间仍然是用http协议来做缓存。
**第三，让谁来缓存静态数据也很重要**。因为 Java 系统本身也有其弱点（比如不擅长处理大量连接请求，每个连接消耗的内存较多，Servlet 容器解析 HTTP 协议较慢），所以你可以不在 Java 层做缓存，而是直接在 Web 服务器层上做。Web 服务器（如 Nginx、Apache、Varnish）也更擅长处理大并发的静态文件请求。

## 3.3 如何做动静分离的改造
理解了动静态数据的“why”和“what”，接下来我们就要看“how”了。我们从以下 5 个方面来分离出动态内容。
1. **URL 唯一化**。商品详情系统天然地就可以做到 URL 唯一化，比如每个商品都由 ID 来标识，那么 http://item.xxx.com/item.htm?id=xxxx 就可以作为唯一的 URL 标识。就以 URL 作为缓存的 Key。
2. **分离浏览者相关的因素**。浏览者相关的因素包括是否已登录，以及登录身份等，这些相关因素我们可以单独拆分出来，通过动态请求来获取。
3. **分离时间因素**。服务端输出的时间也通过动态请求获取。
4. **异步化地域因素**。详情页面上与地域相关的因素做成异步方式获取，当然你也可以通过动态请求方式获取，只是这里通过异步获取更合适。
5. **缓存中去掉 Cookie**。服务端输出的页面包含的 Cookie 可以通过代码软件来删除，如 Web 服务器 Varnish 可以通过 unset req.http.cookie 命令去掉 Cookie。注意，这里说的去掉 Cookie 并不是用户端收到的页面就不含 Cookie 了，而是说，在缓存的静态数据中不含有 Cookie。

前面我们介绍里用缓存的方式来处理静态数据。而动态内容的处理通常有两种方案：ESI（Edge Side Includes）方案和 CSI（Client Side Include）方案。
1. **ESI 方案（或者 SSI）**：即在 Web 代理服务器上做动态内容请求，并将请求插入到静态页面中，当用户拿到页面时已经是一个完整的页面了。这种方式对服务端性能有些影响，但是用户体验较好。
	- 例如在静态页面中包含这种标签 <esi:src="xx.htm"/>，然后由varnish等软件来解析这种标签，再发起动态请求，把动态请求的结果合成到静态页面中，最终形成一个完整的页面
2. **CSI 方案**。即单独发起一个异步 JavaScript 请求，以向服务端获取动态内容。这种方式服务端性能更佳，但是用户端页面可能会延时，体验稍差。
假如在用户的浏览器里合并，那么服务端可以减少渲染整个页面的 CPU 消耗。如果在服务端合并的话，就要考虑缓存的数据是否进行 Gzip 压缩了：如果缓存 Gzip 压缩后的静态数据可以减少缓存的数据量，但是进行页面合并渲染时就要先解压；如果缓存未压缩的静态数据，这样不用解压静态数据，但是会增加缓存容量。虽然这些都是细节问题，但你在设计架构方案时都需要考虑清楚。

**秒杀推荐在客户端做，普通的商品推荐在服务端做**。

## 3.4 动静分离的几种架构方案
如何在系统架构上进一步对这些动态和静态数据重新组合，再完整地输出给用户呢？根据架构上的复杂度，有 3 种方案可选：
1. 实体机单机部署；
2. 统一 Cache 层；
3. 上 CDN。

### 3.4.1 方案 1：实体机单机部署
实体机单机部署是指反向代理服务器和缓存服务器和应用服务器都在同一台机器上部署。
这种方案是将虚拟机改为实体机，以增大 Cache 的容量，并且采用了一致性 Hash 分组（[[一些基础知识#1.2 一致性Hash分片]]）。这里将 Cache 分成若干组，是希望能达到利用率和访问热点的平衡。Hash 分组越少，缓存的利用率肯定就会越高，但短板是也会使单个商品集中在一个分组中，容易导致 Cache 被击穿，所以我们应该适当增加多个相同的分组，来平衡访问热点和利用率的问题。
![[image-171.png]]
注意，图里面最下面的缓存指redis这种。

实体机单机部署有以下几个优点：
1. 没有网络瓶颈，而且能使用大内存；
2. 既能提升利用率，又能减少 Gzip 压缩；
3. 减少 Cache 失效压力，因为采用定时失效方式，例如只缓存 3 秒钟，过期即自动失效。

这个方案中，虽然把通常只需要虚拟机或者容器运行的 Java 应用换成实体机，优势很明显，它会增加单机的内存容量，但是一定程度上也造成了 CPU 的浪费，因为单个的 Java 进程很难用完整个实体机的 CPU。
另外就是，一个实体机上部署了 Java 应用又作为 Cache 来使用，这造成了运维上的高复杂度，所以这是一个折中的方案。如果你的公司里，没有更多的系统有类似需求，那么这样做也比较合适，如果你们有多个业务系统都有静态化改造的需求，那还是建议把 Cache 层单独抽出来公用比较合理。

### 3.4.2 方案 2：统一 Cache 层
将单机的 Cache 统一分离出来，形成一个单独的 Cache 集群。统一 Cache 层是个更理想的可推广方案，该方案的结构图如下：
![[image-194.png]]
统一cache层的缓存是web型的缓存，**如varnish**。nginx 也可以实现缓存，单独加这一层是为了性能和稳定性考虑，让nginx只做负载均衡。

它还有一些优点：
1. 单独一个 Cache 层，可以减少多个应用接入时维护 Cache 的成本。这样接入的应用不需要单独维护 Cache，而只关心如何使用即可。
2. 统一 Cache 的方案更易于维护，如后面加强监控、配置的自动化，只需要一套解决方案就行，统一起来维护升级也比较方便。
3. 可以共享内存，最大化利用内存，不同系统之间的内存可以动态切换，从而能够有效应对各种攻击。

**缓存单点、热点问题通过hash分组解决，一组 Cache 缓存的内容相同。Hash分组是通过nginx完成的，一个分组的机器配在nginx的stream里**。不过后面varnish也支持Hash分组配置了。

### 3.4.3 方案 3：上 CDN
要想这么做，有以下几个问题需要解决：
1. **失效问题**。谈到静态数据时，我说过一个关键词叫“相对不变”。比如一篇文章，现在不变，但如果你发现个错别字，是不是就会变化了？我们需要保证 CDN 可以在秒级时间内，让分布在全国各地的 Cache 同时失效，这对 CDN 的失效系统要求很高。
2. **利用率问题**。如果将数据全部放到全国的 CDN 上，必然导致 Cache 分散，而 Cache 分散又会导致访问请求命中同一个 Cache 的可能性降低，那么利用率就成为一个问题。
3. **发布更新问题**。如果一个业务系统每周都有日常业务需要发布，那么发布系统必须足够简洁高效，而且你还要考虑有问题时快速回滚和排查问题的简便性。

那么是否可以选择若干个节点来尝试实施呢？答案是“可以”，但是这样的节点需要满足几个条件：
1. 靠近访问量比较集中的地区；
2. 离主站相对较远；
3. 节点到主站间的网络比较好，而且稳定；
4. 节点容量比较大，不会占用其他 CDN 太多的资源。
5. 节点不要太多。

于上面几个因素，**选择 CDN 的二级 Cache 比较合适**（指cdn设置了多级回源机制，就是如果缓存没有命中再到二级缓存中去取，而不是直接回服务端来请求）。因为二级 Cache 数量偏少，容量也更大，部署方式如下图所示：
![[image-195.png]]
使用 CDN 的二级 Cache 作为缓存，可以达到和当前服务端静态化 Cache 类似的利用率，因为节点数不多，Cache 不是很分散，访问量也比较集中，这样也就解决了利用率问题，同时能够给用户最好的访问体验，是当前比较理想的一种 CDN 化方案。

#### 3.4.3.1 浏览器缓存 VS CDN
你可能会问，存储在浏览器或 CDN 上，有多大区别？区别很大！**因为在 CDN 上，我们可以做主动失效，而在用户的浏览器里就更不可控**，如果用户不主动刷新的话，你很难主动地把消息推送给用户的浏览器。

有一些设置可以控制浏览器的缓存行为：
1. 主页设置Cache-Control: no-cache或max-age=0, 不缓存; 
2. 其它的资源设置Cache-Control: max-age=3600, 在缓存失效前chrome不会请求到cdn 
3. cdn中的资源只新增不更新, 当修改页面中相关资源内容的时候, 主页更新并, 直接从cdn加载新的url地址
4. 如果主页不更新, 哪怕是更新cdn中的资源也是无效的。chrome从54版本开始, 在缓存失效前不会请求到cdn, 不会查询验证last-modified或if-none-match, 会直接使用memory cache或disk-cache

# 4 热点数据处理
## 4.1 热点分类
**热点分为热点操作和热点数据**。
所谓“热点操作”，例如大量的刷新页面、大量的添加购物车、双十一零点大量的下单等都属于此类操作。对系统来说，这些操作可以抽象为“**读请求**”和“**写请求**”，这两种热点请求的处理方式大相径庭，读请求的优化空间要大一些，而写请求的瓶颈一般都在存储层，优化的思路就是根据 CAP 理论做平衡，这个内容我在“减库存”一文再详细介绍。

“热点数据”比较好理解，那就是用户的热点请求对应的数据。而**热点数据又分为“静态热点数据”和“动态热点数据”**。
**“静态热点数据”，就是能够提前预测的热点数据**。例如，我们可以通过卖家报名的方式提前筛选出来，通过报名系统对这些热点商品进行打标。另外，我们还可以通过大数据分析来提前发现热点商品，比如我们分析历史成交记录、用户的购物车记录，来发现哪些商品可能更热门、更好卖，这些都是可以提前分析出来的热点。
**所谓“动态热点数据”，就是不能被提前预测到的，系统在运行过程中临时产生的热点**。例如，卖家在抖音上做了广告，然后商品一下就火了，导致它在短时间内被大量购买。

由于热点操作是用户的行为，我们不好改变，但能做一些限制和保护，所以本文我主要针对热点数据来介绍如何进行优化。

## 4.2 发现热点数据
我们可以通过卖家报名或者大数据预测这些手段来提前预测静态热点数据，但这其中有一个痛点，就是实时性较差。这里我给出一个动态热点发现系统的具体实现。
1. 构建一个异步的系统，它可以收集交易链路上各个环节中的中间件产品的热点 Key，如 Nginx、缓存、RPC 服务框架等这些中间件（一些中间件产品本身已经有热点统计模块）。
2. 建立一个热点上报和可以按照需求订阅的热点服务的下发规范，主要目的是通过交易链路上各个系统（包括详情、购物车、交易、优惠、库存、物流等）访问的时间差，把上游已经发现的热点透传给下游系统，提前做好保护。比如，对于大促高峰期，详情系统是最早知道的，在统一接入层上 Nginx 模块统计的热点 URL。
3. 将上游系统收集的热点数据发送到热点服务台，然后下游系统（如交易系统）就会知道哪些商品会被频繁调用，然后做热点保护。

用户访问商品时经过的路径有很多，我们主要是依赖前面的导购页面（包括首页、搜索页面、商品详情、购物车等）提前识别哪些商品的访问量高，通过这些系统中的中间件来收集热点数据，并记录到日志中。
![[image-196.png]]
我们通过部署在每台机器上的 Agent 把日志汇总到聚合和分析集群中，然后把符合一定规则的热点数据，通过订阅分发系统再推送到相应的系统中。你可以是把热点数据填充到 Cache 中，或者直接推送到应用服务器的内存中，还可以对这些数据进行拦截，总之下游系统可以订阅这些数据，然后根据自己的需求决定如何处理这些数据。

打造热点发现系统时，我根据以往经验总结了几点注意事项。
1. **这个热点服务后台抓取热点数据日志最好采用异步方式**，因为“异步”一方面便于保证通用性，另一方面又不影响业务系统和中间件产品的主流程。
2. 热点服务发现和中间件自身的热点保护模块并存，每个中间件和应用还需要保护自己。热点服务台提供热点数据的收集和订阅服务，便于把各个系统的热点数据透明出来。
3. 热点发现要做到接近实时（3s 内完成热点数据的发现），因为只有做到接近实时，动态发现才有意义，才能实时地对下游系统提供保护。

## 4.3 处理热点数据
**处理热点数据通常有几种思路：一是优化，二是限制，三是隔离**。
**优化热点数据最有效的办法就是缓存热点数据**，如果热点数据做了动静分离，那么可以长期缓存静态数据。
限制更多的是一种保护机制，限制的办法也有很多，例如对被访问商品的 ID 做一致性 Hash，然后根据 Hash 做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。

最后介绍一下隔离。秒杀系统设计的第一个原则就是将这种热点数据隔离出来，不要让 1% 的请求影响到另外的 99%，隔离出来后也更方便对这 1% 的请求做针对性的优化。
1. **业务隔离**。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就有了已知热点，因此可以提前做好预热。
2. **系统隔离**。系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外 99% 分开。秒杀可以申请单独的域名，目的也是让请求落到不同的集群中。
3. **数据隔离**。秒杀所调用的数据大部分都是热点数据，比如会启用单独的 Cache 集群或者 MySQL 数据库来放热点数据，目的也是不想 0.01% 的数据有机会影响 99.99% 数据。

# 5 流量削峰
**流量削峰的一些操作思路：答题、分层过滤、排队**。这几种方式都是**无损**（即不会损失用户的发出请求）的实现方案。
当然还有些有损的实现方案，包括我们后面要介绍的关于稳定性的一些办法，比如限流和机器负载保护等一些强制措施也能达到削峰保护的目的，当然这都是不得已的一些措施，因此就不归类到这里了。
## 5.1 答题
这主要是为了增加购买的复杂度，从而达到两个目的。
1. 第一个目的是防止部分买家使用秒杀器在参加秒杀时作弊。
2. 第二个目的其实就是延缓请求，起到对请求流量进行削峰的作用。这样一来，**请求峰值基于时间分片**了。由于请求具有先后顺序，靠后的请求到来时自然也就没有库存了，因此根本到不了最后的下单步骤，所以真正的并发写就非常有限了。
	这种设计思路目前用得非常普遍，如当年支付宝的“咻一咻”、微信的“摇一摇”都是类似的方式。

重点说一下秒杀答题的设计思路。
![[image-197.png]]
1. **题库生成模块**，这个部分主要就是生成一个个问题和答案
2. **题库的推送模块**，用于在秒杀答题前，把题目提前推送给详情系统和交易系统。题库的推送主要是为了保证每次用户请求的题目是唯一的，目的也是防止答题作弊。
3. **题目的图片生成模块**，用于把题目生成为图片格式，并且在图片里增加一些干扰因素。由于答题时网络比较拥挤，我们应该把题目的图片提前推送到 CDN 上并且要进行预热。

验证的逻辑如下图所示：
![[image-198.png]]
这里面的验证逻辑，除了验证问题的答案以外，还包括用户本身身份的验证，例如是否已经登录、用户的 Cookie 是否完整、用户是否重复频繁提交等。

除了做正确性验证，我们还可以对提交答案的时间做些限制，例如从开始答题到接受答案要超过 1s，因为小于 1s 是人为操作的可能性很小，这样也能防止机器答题的情况。

### 5.1.1 答题系统应该也有性能瓶颈，如何处理？

## 5.2 分层过滤
分层过滤其实就是采用“漏斗”式设计来处理请求的，如下图所示。
![[image-199.png]]
1. 大部分数据和流量在用户浏览器或者 CDN 上获取，这一层可以拦截大部分数据的读取；
2. 经过第二层（即前台系统）时数据（包括强一致性的数据）尽量得走 Cache，过滤一些无效的请求（也就是库存没有了，没法再抢到商品的请求）；
3. 再到第三层后台系统，主要做数据的二次检验，对系统做好保护和限流，这样数据量和请求就进一步减少；
4. 最后在数据层完成数据的强一致性校验。

分层校验的基本原则是：
1. 将动态请求的读数据缓存（Cache）在 Web 端，过滤掉重复的数据读；
2. 对读数据不做强一致性校验，减少因为一致性校验产生瓶颈的问题；
3. 对写数据进行基于时间的合理分片，过滤掉过期的失效请求；
4. 对写请求做限流保护，将超出系统承载能力的请求过滤掉；
5. 对写数据进行强一致性校验，只保留最后有效的数据。

分层校验的目的是：在读系统中，尽量减少由于一致性校验带来的系统瓶颈，但是尽量将不影响性能的检查条件提前，如用户是否具有秒杀资格、商品状态是否正常、用户答题是否正确、秒杀是否已经结束、是否非法请求、营销等价物是否充足等；在写数据系统中，主要对写的数据（如“库存”）做一致性检查，最后在数据库层保证数据的最终准确性（如“库存”不能减为负数）。

## 5.3 排队
要对流量进行削峰，最容易想到的解决方案就是用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另一端平滑地将消息推送出去。
如果流量峰值持续一段时间达到了消息队列的处理上限，例如本机的消息积压达到了存储空间的上限，消息队列同样也会被压垮，这样虽然保护了下游的系统，但是和直接把请求丢弃也没多大的区别。
所以MQ之前应该有很多层限流, 其中可以考虑加一层抢令牌。 比如说我要放100个手机用于秒杀, 那么放10000个令牌给不同的用户, 足够了。其它的抢不到令牌的, 直接返回秒杀结束。
**不过异步处理的话，处理结果用户无法立即知晓，体验较差**。可以给前端一个查询接口，这种查询流量，因为后端完全知晓结果, 可以全部放到redis中(甚至local cache), 不会有穿透到DB的流量, 因此可以做到速度很快。

# 6 影响性能的因素
前面的四篇文章里，我介绍的内容多少都和优化有关：第一篇介绍了一些指导原则；第二篇和第三篇从动静分离和热点数据两个维度，介绍了如何有针对性地对数据进行区分和优化处理；第四篇介绍了在保证实现基本业务功能的前提下，尽量减少和过滤一些无效请求的思路。

## 6.1 性能指标
我们讨论的主要是系统服务端性能，一般用 **QPS（Query Per Second，每秒请求数）** 来衡量，还有一个影响和 QPS 也息息相关，那就是**响应时间（Response Time，RT）**，它可以理解为服务器处理响应的耗时。
正常情况下响应时间（RT）越短，一秒钟处理的请求数（QPS）自然也就会越多，这在单线程处理的情况下看起来是线性的关系，即我们只要把每个请求的响应时间降到最低，那么性能就会最高。
通过多线程处理请求，这样就变成了“总 QPS =（1000ms / 响应时间）× 线程数量”，**这样性能就和两个因素相关了，一个是一次响应的服务端耗时，一个是处理请求的线程数**。

### 6.1.1 响应时间和QPS
对于大部分的 Web 系统而言，响应时间一般都是由 **CPU 执行时间**和**线程等待时间**（比如 RPC、IO 等待、Sleep、Wait 等）组成。
根据我们实际的测试发现，减少线程等待时间对提升性能的影响没有我们想象得那么大，它并不是线性的提升关系。这点在很多代理服务器（Proxy）上可以做验证：如果代理服务器本身没有 CPU 消耗，我们在每次给代理服务器代理的请求加个延时，即增加响应时间，但是这对代理服务器本身的吞吐量并没有多大的影响，因为代理服务器本身的资源并没有被消耗，可以通过增加代理服务器的处理线程数，来弥补响应时间对代理服务器的 QPS 的影响。
**真正对性能有影响的是 CPU 的执行时间**。这也很好理解，因为 CPU 的执行真正消耗了服务器的资源。经过实际的测试，如果减少 CPU 一半的执行时间，就可以增加一倍的 QPS。

### 6.1.2 线程数和QPS
单看“总 QPS”的计算公式，你会觉得线程数越多 QPS 也就会越高，但这会一直正确吗？线程本身也消耗资源，也受到其他因素的制约。例如，线程越多系统的线程切换成本就会越高，而且每个线程也都会耗费一定内存。

设置什么样的线程数最合理呢？其实很多多线程的场景都有一个默认配置，即“**线程数 = 2 * CPU 核数 + 1**”。除去这个配置，还有一个根据最佳实践得出来的公式：
```
线程数 = [(线程等待时间 + 线程 CPU 时间) / 线程 CPU 时间] × CPU 数量
```
第一个公式其实就是第二个公式中“线程等待时间”=0的情况，并且考虑到了超线程。
当然，最好的办法是通过性能测试来发现最佳的线程数。

要提升性能我们就要减少 CPU 的执行时间，另外就是要设置一个合理的并发线程数，通过这两方面来显著提升服务器的性能。

## 6.2 如何发现瓶颈
不同的系统对瓶颈的关注度也不一样，例如对缓存系统而言，制约它的是内存，而对存储型系统来说 I/O 更容易是瓶颈。**秒杀它的瓶颈更多地发生在 CPU 上**。
有很多 CPU 诊断工具可以发现 CPU 的消耗，最常用的就是 JProfiler 和 Yourkit 这两个工具，它们可以列出整个请求中每个函数的 CPU 执行时间，可以发现哪个函数消耗的 CPU 时间最多，以便你有针对性地做优化。

虽说秒杀系统的瓶颈大部分在 CPU，但这并不表示其他方面就一定不出现瓶颈。例如，如果海量请求涌过来，你的页面又比较大，那么网络就有可能出现瓶颈。
怎样简单地判断 CPU 是不是瓶颈呢？**一个办法就是看当 QPS 达到极限时，你的服务器的 CPU 使用率是不是超过了 95%**，如果没有超过，那么表示 CPU 还有提升的空间，要么是有锁限制，要么是有过多的本地 I/O 等待发生。
除了CPU，系统的每一个中间件, 每一台机器, 都应该有promethus监控大屏。**系统到qps极限时, 查监控大屏上谁的的cpu/内存/磁盘/网络满了, 差不多就是瓶颈了**。

## 6.3 如何优化系统
对 Java 系统来说，可以优化的地方很多，这里我重点说一下比较有效的几种手段，供你参考，它们是：减少编码、减少序列化、Java 极致优化、并发读优化。
### 6.3.1 减少编码
Java 的编码运行比较慢，这是 Java 的一大硬伤。在很多场景下，只要涉及字符串的操作（如输入输出操作、I/O 操作）都比较耗 CPU 资源，不管它是磁盘 I/O 还是网络 I/O，因为都需要将字符转换成字节，而这个转换必须编码。每个字符的编码都需要查表，而这种查表的操作非常耗资源。

那么如何才能减少编码呢？例如，网页输出是可以直接进行流输出的，即用 resp.getOutputStream() 函数写数据，把一些静态的数据提前转化成字节，等到真正往外写的时候再直接用 OutputStream() 函数写，就可以减少静态数据的编码转换。
我在《深入分析 Java Web 技术内幕》一书中介绍的“Velocity 优化实践”一章的内容，就是基于把静态的字符串提前编码成字节并缓存，然后直接输出字节内容到页面，从而大大减少编码的性能消耗的，网页输出的性能比没有提前进行字符到字节转换时提升了 30% 左右。

### 6.3.2 减少序列化
序列化也是 Java 性能的一大天敌，减少 Java 中的序列化操作也能大大提升性能。又因为序列化往往是和编码同时发生的，所以减少序列化也就减少了编码。
序列化大部分是在 RPC 中发生的，因此避免或者减少 RPC 就可以减少序列化，当然当前的序列化协议也已经做了很多优化来提升性能。有一种新的方案，就是可以将多个关联性比较强的应用进行“**合并部署**”，而减少不同应用之间的 RPC 也可以减少序列化的消耗。
所谓“合并部署”，就是把两个原本在不同机器上的不同应用合并部署到一台机器上，当然不仅仅是部署在一台机器上，还要在同一个 Tomcat 容器中，且不能走本机的 Socket，这样才能避免序列化的产生。

### 6.3.3 Java 极致优化
Java 和通用的 Web 服务器（如 Nginx 或 Apache 服务器）相比，在处理大并发的 HTTP 请求时要弱一点，所以一般我们都会对大流量的 Web 系统做静态化改造，让大部分请求和数据直接在 Nginx 服务器或者 Web 代理服务器（如 Varnish、Squid 等）上直接返回（这样可以减少数据的序列化与反序列化），而 Java 层只需处理少量数据的动态请求。
针对这些请求，我们可以使用以下手段进行优化：
- 直接使用 Servlet 处理请求。避免使用传统的 MVC 框架，这样可以绕过一大堆复杂且用处不大的处理逻辑，节省 1ms 时间（具体取决于你对 MVC 框架的依赖程度）。
- 直接输出流数据。使用 resp.getOutputStream() 而不是 resp.getWriter() 函数，可以省掉一些不变字符数据的编码，从而提升性能；数据输出时推荐使用 JSON 而不是模板引擎（一般都是解释执行）来输出页面。

### 6.3.4 并发读优化
虽然单台缓存机器也能支撑 30w/s 的请求，但还是远不足以应对像“大秒”这种级别的热点商品。那么，该**如何彻底解决单点的瓶颈呢**？
**答案是采用应用层的 LocalCache**，即在秒杀系统的单机上缓存商品相关的数据。你需要划分成动态数据和静态数据分别进行处理：
- 像商品中的“标题”和“描述”这些本身不变的数据，会在秒杀开始之前全量推送到秒杀机器上，并一直缓存到秒杀结束；
- 像库存这类动态数据，会采用“被动失效”的方式缓存一定时间（一般是数秒），失效后再去缓存拉取最新的数据。

你可能还会有疑问：像库存这种频繁更新的数据，一旦数据不一致，会不会导致超卖？
这就要用到前面介绍的读数据的分层校验原则了，**读的场景可以允许一定的脏数据，因为这里的误判只会导致少量原本无库存的下单请求被误认为有库存，可以等到真正写数据时再保证最终的一致性**，通过在数据的高可用性和一致性之间的平衡，来解决高并发的数据读取问题。
任何在页面上展示给用户的数据, 都是只能拿来看看而已, 都不能作为参数去操作DB。真正操作DB的时候, 除了uid之外, 所有其它数据(包括:价格, 数量, 余额等等)的来源, 都必须来源于DB本身,只有这样, 才有机会做到事务一致性。

## 6.4 总结
1. **首先是“发现短板”**：考虑以下因素的一些限制：网速、网络结构（交换机 / 网卡的限制）、TCP/IP、虚拟机（内存 /CPU/IO 等资源的限制）和应用本身的一些瓶颈等。
2. **其次是减少数据**。事实上，有两个地方特别影响性能，一是服务端在处理数据时不可避免地存在字符到字节的相互转化，二是 HTTP 请求时要做 Gzip 压缩，还有网络传输的耗时，这些都和数据大小密切相关。
3. **再次是数据分级**，也就是要保证首屏为先、重要信息为先，次要信息则异步加载，以这种方式提升用户获取数据的体验。
4. **最后就是要减少中间环节**，减少字符到字节的转换，增加预处理（提前做字符到字节的转换）去掉不需要的操作。
5. **此外要做好应用基线**，比如性能基线（QPS、RT等，何时性能突然下降）、成本基线（去年双 11 用了多少台机器）、链路基线（依赖哪些关键接口，我们的系统发生了哪些变化），你可以通过这些基线持续关注系统的性能，做到在代码上提升编码质量，在业务上改掉不合理的调用，在架构和调用链路上不断的改进。

# 7 库存扣减
## 7.1 减库存有哪几种方式
用户的实际购买过程一般分为两步：下单和付款。
减库存操作一般有如下几个方式：
- **下单减库存**，这是最简单的减库存方式，也是控制最精确的一种，下单时直接通过数据库的事务机制控制商品库存，这样一定不会出现超卖的情况。但是你要知道，有些人下完单可能并不会付款。
- **付款减库存**，因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为可能商品已经被其他人买走了。
- **预扣库存**，这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如 10 分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在买家付款前，系统会校验它的订单库存是否还有保留：如果没有保留，则再次尝试预扣；如果预扣失败则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。

## 7.2 减库存可能存在的问题
假如我们采用“下单减库存”的方式，恶意下单的人是不会真正付款的，那么这款商品就不能正常售卖了。
“付款减库存”又会导致另外一个问题：**库存超卖**。因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，就会导致很多买家下单成功但是付不了款，买家的购物体验自然比较差。
预扣库存”在一定程度上缓解上面的问题。但是否就彻底解决了呢？虽然把有效的付款时间设置为 10 分钟，但是恶意买家完全可以在 10 分钟后再次下单，或者采用一次下单很多件的方式把库存减完。针对这种情况，解决办法还是要结合安全和反作弊的措施来制止。
例如，给经常下单不付款的买家进行识别打标（可以在被打标的买家下单时不减库存）、给某些类目设置最大购买件数（例如，参加活动的商品一人最多只能买 3 件），以及对重复下单不付款的操作进行次数限制等。

## 7.3 秒杀中的库存扣减
业务系统中最常见的就是预扣库存方案。
由于参加秒杀的商品，一般都是“抢到就是赚到”，所以成功下单后却不付款的情况比较少，再加上卖家对秒杀商品的库存有严格限制，所以秒杀商品采用“下单减库存”更加合理。另外，理论上由于“下单减库存”比“预扣库存”以及涉及第三方支付的“付款减库存”在逻辑上更为简单，所以性能上更占优势。

---
# 8 引用
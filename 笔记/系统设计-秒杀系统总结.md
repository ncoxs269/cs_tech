2025-10-28 16:04
Status: #idea
Tags: [[场景题和设计题]]

# 1 概览
高可靠系统的三个维度：高可用，一致性，高性能。
实现高可靠的架构原则：
1. 数据尽量少：请求的上传和响应数据、系统依赖的数据都要少
2. 请求数尽量少
3. 路径尽量短：极致方法是合并部署
4. 强依赖尽量少：对系统分级，高级系统尽量减少对低级系统的强依赖
5. 不要有单点：通过无状态、或冗余备份（如数据库）实现

秒杀系统关键问题：瞬时高并发。
秒杀系统的技术场景：读多写少

秒杀业务流程：秒杀 -> 下单 -> 支付
秒杀系统架构：
- ~~秒杀详情系统~~
- ~~秒杀交易系统~~
- 秒杀系统
- ~~商品、库存系统~~
- 交易系统
- 支付系统

问题：
- MQ异步下单：要注意以下消息问题
	- 消息丢失：生产端使用消息发送表和定时任务来解决
	- 重复消费：消费端使用消息处理表保证幂等消费
- 订单超时取消如何实现
	- 一个实现方法是定时任务轮询。
	- 另一个方法是使用延迟队列。下单时消息生产者会先生成订单，此时状态为待支付，然后会向延迟队列中发一条消息。
		- 达到了延迟时间，消息消费者读取消息之后，会查询该订单的状态是否为待支付。
		- 如果是待支付状态，则会更新订单状态为取消状态。如果不是待支付状态，说明该订单已经支付过了，则直接返回。
- 缓存预热
- 加了缓存之后的三大问题：击穿、穿透、雪崩
	- 击穿：极热热点，用本地缓存或多缓存解决
	- 穿透：不存在的商品，用临时缓存解决
	- 雪崩：随机设置超时时间
- 防止用户重复秒杀
	- 前端限制：一次点击之后按钮置灰几秒钟
	- 后端限制：在redis中记录哪些用户已经秒杀过了
- 答题系统怎么抗住高并发？

# 2 关键技术点
## 2.1 安全防护
### 2.1.1 恶意请求拒绝
恶意请求和黄牛攻击是秒杀系统面临的安全挑战。黄牛脚本的危害不仅是 "抢走商品"，还会占用大量带宽和服务器资源，导致真实用户抢不到商品。
防护策略从三个维度展开。
1. **设备指纹识别**：通过前端采集用户设备信息（如浏览器 UA、屏幕分辨率、操作系统版本、设备唯一标识），生成 "设备指纹"。若某设备指纹短期内多次请求，或与黑名单指纹匹配，直接拦截。
2. **行为分析**：真人用户的操作有 "时间间隔" 和 "正常轨迹"（如先浏览商品、再加入购物车、最后抢购），而脚本是 "瞬时连续点击"。通过后端分析用户行为：若从进入页面到点击抢购的时间＜1 秒，或同一用户 1 分钟内点击抢购＞10 次，标记为疑似作弊，要求完成 "滑块验证码" 或 "图文验证码"。
3. **黑名单机制**：将历史作弊用户（如用脚本下单的用户、多次取消秒杀订单的用户）的 ID、IP、设备指纹加入黑名单，后续请求直接拒绝。某平台通过黑名单机制，减少了 40% 的作弊请求。

还可以针对用户ID、IP限流，参见 [[#2.2.4.1 针对性限流]]
### 2.1.2 防止重复秒杀
#### 2.1.2.1 重试的关键限制规则
用户没秒杀成功，则允许重试但不能无限制，需通过以下规则避免系统压力：
1. 时间限制：仅在秒杀活动有效期内允许重试，活动结束后直接隐藏按钮或置灰。
2. 频率限制：同一用户 / IP / 设备对同一商品，设置重试间隔（如 3-5 秒），避免高频连续点击。
3. 次数限制：可设置单用户单商品最大重试次数（如 5 次），超过次数后提示 “今日参与次数已用尽”。
4. 失败类型区分：
    - 允许重试场景：网络超时、系统繁忙、库存暂时不足（未售罄）。
    - 禁止重试场景：已抢到过该商品（无论是否支付）、账号疑似作弊、活动已结束、商品售罄。
5. 高并发峰值：当系统 QPS 接近阈值时，可临时收紧重试规则（如延长重试间隔、减少重试次数），优先保障系统稳定。
#### 2.1.2.2 前端层：提前拦截重复操作
前端是第一道防线，主要拦截用户无意识的重复点击或简单脚本重复提交。
- 按钮置灰与禁用：用户点击 “抢购” 后，立即将按钮置灰并禁用（如 1-3 秒），禁止短时间内重复点击。
- 本地存储标记：用户成功发起一次抢购请求后，通过 localStorage/sessionStorage 记录 “已参与秒杀（商品 ID + 用户 ID）”，下次点击时直接提示 “已参与，请勿重复提交”。
- 请求防抖：使用防抖函数（如 300ms），过滤短时间内的多次点击，仅保留最后一次有效请求。
- 页面跳转限制：抢购成功后，直接跳转到订单页或结果页，禁止回退到秒杀页再次提交。
#### 2.1.2.3 接入层：拦截重复请求
API 网关 / 负载均衡层进一步过滤重复请求，减少后端压力：
- ~~基于请求 ID 去重：前端发起请求时生成唯一 requestID（如 UUID），携带在请求头中；网关层记录近期 requestID，重复请求直接拦截。~~
- IP + 商品维度限流：限制同一 IP 对同一商品的请求频率（如 10 秒内最多 2 次），避免脚本高频重复提交。
- 令牌桶限流：网关层为每个用户分配秒杀令牌，同一用户对同一商品仅能获取 1 个有效令牌，重复请求无令牌直接拒绝。通过限制令牌数量，也能限制总体请求的用户数量
#### 2.1.2.4 应用层：核心去重校验
应用层通过业务规则和分布式存储，确保重复请求无法通过核心逻辑。
- 唯一标识校验：以 “用户 ID + 商品 ID” 作为唯一组合，秒杀前先查询 Redis（如键为`seckill:user:${userID}:${goodsID}`），次数为0则返回 “已参与”，否则扣减次数（设置过期时间与秒杀活动时长一致）。

**通过缓存限制秒杀失败的用户**。
#### 2.1.2.5 数据层：最终一致性保障
数据层作为最后一道防线，通过数据库约束杜绝重复记录。
- 唯一索引约束：在秒杀订单表中，为 “用户 ID + 商品 ID” 建立联合唯一索引，即使前面校验失效，数据库也会拒绝重复插入订单，直接抛出主键冲突异常。

**数据库记录秒杀成功的用户**。
## 2.2 高可用
### 2.2.1 隔离
- 业务隔离：让商家报名，使热点已知，方便提前预热
- 系统隔离：独立系统&集群
- 数据隔离：独立数据库、独立缓存
### 2.2.2 多活架构
将系统部署在多个地域的机房（如华东、华北），通过 DNS 解析将用户流量引导到就近机房；若某机房故障，自动将流量切换到其他机房，实现 "异地多活"。
### 2.2.3 流量削峰
答题or验证码：
- 防止用户刷接口
- 让流量基于时间分片

分层过滤：
- 分层架构设计，通过层层过滤和分流，将瞬时流量压力逐级化解。典型的五层架构包括：接入层(CDN、负载均衡、API)、应用层、缓存层、消息队列层和存储层​。每一层都承担" 过滤无效请求、减轻下游压力 "的职责，形成一个" 流量漏斗 "​。
- 秒杀系统：
	- 第一层在浏览器和CDN拦截大部分静态数据读取
	- 第二层前端校验，检查用户资格、活动状态、答题正确性等
	- 第三层应用层读系统，数据走Cache，过滤无效请求（库存没有了之后的请求）
	- 第四层应用层写系统，做数据的二次检验，对系统做好保护和限流
	- 第五层数据层，完成数据的强一致性校验

排队：
- 消息队列承接瞬时流量，把同步请求变成异步
- 也需要保护MQ，MQ之前应该有很多层限流。
#### 2.2.3.1 TODO：答题&验证码系统怎么抗住高并发
### 2.2.4 限流
分层限流：
- 在客户端，在远程调用时我们设置连接池的线程数，超出这个并发线程请求，就将线程进行排队或者直接超时丢弃
- 在接入层
	- 基于 Nginx/OpenResty 设置全局限流（如 10 万 QPS）
	- 还可以加入针对性限流
	- 还有令牌桶限流：网关层为每个用户分配秒杀令牌，同一用户对同一商品仅能获取 1 个有效令牌，重复请求无令牌直接拒绝。通过限制令牌数量，也能限制总体请求的用户数量
- 在应用层
	- 使用 Redis 实现分布式限流，通过 Lua 脚本保证原子性
	- 单个机器可以用令牌桶、滑动窗口限流算法
- 在服务层，采用 Hystrix 或 Sentinel 实现熔断降级，当依赖服务故障时快速返回默认结果
#### 2.2.4.1 针对性限流
可以对同一用户ID限流。但有时候只对某个用户限流是不够的，有些高手可以模拟多个用户请求，这时需要加同一ip限流功能。
但这种限流方式可能会有误杀的情况，比如同一个公司或网吧的出口ip是相同的，如果里面有多个正常用户同时发起请求，有些用户可能会被限制住。
别以为限了用户和ip就万事大吉，有些高手甚至可以使用代理，每次都请求都换一个ip。这时可以限制请制求的接口总次数。
### 2.2.5 降级
它是一个有目的、有计划的执行过程，所以对降级我们一般需要有一套预案来配合执行。如果我们把它系统化，就可以通过预案系统和开关系统来实现降级。
### 2.2.6 熔断
使用 Sentinel 或 Hystrix 监控服务调用情况，当某服务调用失败率超过 50%，自动熔断，暂时停止调用该服务，返回默认结果（如 "支付暂时不可用，请稍后重试"），避免连锁故障。
### 2.2.7 拒绝服务
当系统负载达到一定阈值时，例如 CPU 使用率达到 90% 或者系统 load 值达到 2\*CPU 核数时，系统直接拒绝所有请求，这种方式是最暴力但也最有效的系统保护方式。
这种系统过载保护虽然在过载时无法提供服务，但是系统仍然可以运作，当负载下降时又很容易恢复，所以每个系统和每个环节都应该设置这个兜底方案，对系统做最坏情况下的保护。
### 2.2.8 监控告警体系
监控告警体系是系统稳定运行的保障。使用 Prometheus+Grafana 监控 QPS、响应时间、错误率、库存剩余量、消息队列堆积数等指标，设置阈值告警（如 QPS 超过 50 万、错误率超过 1% 时，通过短信 / 邮件告警）。同时，通过 SkyWalking 或 Zipkin 追踪秒杀请求的全链路，快速定位耗时节点。
### 2.2.9 故障恢复
### 2.2.10 缓存三大问题
参见[[Redis-应用#3 缓存三大问题]]
### 2.2.11 TODO：请求持久化与重试
## 2.3 一致性
### 2.3.1 库存读取的最终一致性
库存的读取（判断还有没有商品、要不要防请求进来）缓存没有必要极致追求数据的准确性，只要保证最终一致性。缓存本身为了减少数据库的压力。
最坏情况也就是多放了一些请求进来。
### 2.3.2 库存扣减的强一致性
通过redis或mysql的原子操作实现
### 2.3.3 下单和库存两个操作的事务怎么保证
背景：下单、库存操作分别是两个系统。
解决办法：
1. 两阶段提交：可以分两步来做，先创建订单但是先不生效，然后减库存，如果减库存成功后再生效订单，否则订单不生效。类似于MySQL日志的两阶段提交
2. 分布式事务
### 2.3.4 TODO：订单超时怎么补偿库存
## 2.4 高性能
### 2.4.1 性能影响因素
性能指标：
- **响应时间（Response Time，RT）**：服务器处理响应的耗时，由**CPU 执行时间**和**线程等待时间**（比如 RPC、IO 等待、Sleep、Wait 等）组成。
	- CPU 的执行真正消耗了服务器的资源，对性能影响最大
- **QPS（Query Per Second，每秒请求数）** =（1000ms / 响应时间）× 线程数量
- 线程数最佳实践：`线程数 = [(线程等待时间 + 线程 CPU 时间) / 线程 CPU 时间] × CPU 数量`。如果考虑超线程，还可以 x 2

发现瓶颈：
- 性能工具： JProfiler 和 Yourkit 这两个工具，它们可以列出整个请求中每个函数的 CPU 执行时间
- 压测：
	- 简单地判断 CPU 是不是瓶颈：一个办法就是看当 QPS 达到极限时，你的服务器的 CPU 使用率是不是超过了 95%。如果没有超过，那么表示 CPU 还有提升的空间，要么是有锁限制，要么是有过多的本地 I/O 等待发生。
	- 除了CPU，系统的每一个中间件, 每一台机器, 都应该有promethus监控大屏。系统到qps极限时, 查监控大屏上谁的的cpu/内存/磁盘/网络满了, 差不多就是瓶颈了。

做好应用基线：
- 比如性能基线（QPS、RT等，何时性能突然下降）、成本基线（去年双 11 用了多少台机器）、链路基线（依赖哪些关键接口，我们的系统发生了哪些变化）
- 你可以通过这些基线持续关注系统的性能，做到在代码上提升编码质量，在业务上改掉不合理的调用，在架构和调用链路上不断的改进。
### 2.4.2 动静分离
动态静态分类：数据中是否含有和访问者相关的个性化数据。

静态数据
- 缓存地点要离用户近
- 让web型缓存（varnish）或CDN缓存
- 可以对URL的结果进行缓存。https协议的链接只在最外层，内部系统用http
- CDN要点
	- 离访问量大的地区近，离主站远但和主站的网络好
	- 节点容量大且数量不多，数量不多则访问量集中、命中率高
	- CDN作为二级缓存，没取到去一级缓存（web型缓存）
	- vs 浏览器。浏览器不可控，CDN可以主动失效

动态数据：
- ESI：web服务器请求动态数据，把结果插入到静态页面中返回
- CSI：浏览器自己请求动态内容，对服务器友好，适合秒杀系统
### 2.4.3 热点数据
热点数据发现
- 静态热点数据：就是能够提前预测的热点数据
- 动态热点数据发现系统
	- 收集交易链路上各个环节中的中间件产品的热点Key或抓取日志，如 Nginx、缓存、RPC 服务框架等这些中间件
	- 提供订阅给其他系统

热点数据缓存
- 更新方式
	- 定时更新
	- 主动更新：
		- 用阿里metaq技术，就是数据库字段更新会产生一条消息。让一个失效中心去监控，收到更新后给缓存发送失效请求
		- 没有的话，就在数据库库存更新操作时，手动发一条MQ消息
- 一致性：缓存没有必要极致追求数据的准确性，只要保证最终一致性。缓存本身为了减少数据库的压力。
- 单点问题
	- 冗余备份：当热点数据过热时，单个缓存也撑不住，需要弄多个实例缓存一样的内容，用nginx路由。用在web型缓存中
	- 本地缓存：热点数据存在机器内存上面
	- 分段缓存：例如将商品总库存逻辑上划分为 N 个分片，每个分片持有 T/N 的库存。当用户请求到达时，随机或轮询选择一个分片进行扣减操作，有效分散了热点压力。
		- 但是这样又面临其他问题
- 分层缓存：本地缓存、redis

热点数据限制：对被访问商品的 ID 做一致性 Hash，在部分服务调用的地方对请求进行 Hash 分组，每个分组设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。

热点数据隔离
- 热点数据移到其他单独缓存、数据库中
- 动态隔离怎么做
#### 2.4.3.1 本地缓存的主动失效
本地缓存的失效设计核心是 **“主动通知 + 被动兜底”**，既要确保库存变更后各机器的本地缓存能及时同步，又要避免因通知丢失导致的长期不一致，具体可按 “实时失效” 和 “最终一致” 两层设计落地。
##### 2.4.3.1.1 第一层：实时失效 —— 库存变更后主动通知所有机器
###### 2.4.3.1.1.1 基于 “消息队列广播” 的主动通知
这是通用性最强、可靠性最高的方案，适合多机器分布式部署场景，步骤如下：
1. 库存变更时发送广播消息：在数据库扣减库存的事务提交后，立即向消息队列发送一条 “库存变更广播消息”，消息体包含 商品 ID，并将队列设置为 “**广播模式**”，确保同一条广播消息能被所有机器消费到
2. 应用机器接收消息后清空本地缓存：每个应用机器启动一个消息消费线程，监听 “库存变更广播队列”，收到消息后调用本地缓存的删除方法，清空该商品的本地缓存；

通知实时性高（延迟通常 < 100ms），所有机器能同步清空缓存；消息队列有持久化机制，即使某台机器临时离线，重启后仍能消费消息补清缓存，避免遗漏。
###### 2.4.3.1.1.2 基于 “Redis 发布订阅” 的轻量通知（适合中小规模）
若已使用 Redis，可无需额外引入 MQ，用 Redis 的 Pub/Sub（发布订阅）机制实现广播，步骤更简洁：
1. 库存变更时发布 Redis 消息：事务提交后，调用 Redis 的`PUBLISH "stock_change_topic" "商品ID"`，向 “库存变更主题” 发布消息。
2. 应用机器订阅主题并清空缓存：每个应用机器启动一个 Redis 订阅线程，订阅`"stock_change_topic"`，收到消息后立即清空对应商品的本地缓存。

注意：Redis Pub/Sub 是 “无持久化” 的，若机器离线期间发布的消息会丢失，需搭配 “被动兜底” 机制（见下文）；适合机器数量少（<50 台）、对通知可靠性要求不极致的场景。
##### 2.4.3.1.2 第二层：被动兜底 —— 避免通知丢失导致的缓存不一致
即使主动通知机制 99% 可靠，仍可能因 “消息队列宕机”“网络抖动”“机器离线” 导致部分机器的本地缓存未清空，此时需通过 “被动失效” 确保最终一致，核心是 **“设置缓存过期时间 + 缓存刷新策略”**。
1. 给本地缓存设置 “短过期时间”（基础兜底）：为所有商品的本地缓存设置 **5-30 秒的过期时间**（具体时长按库存变更频率调整：秒杀场景变更频繁，设 5 秒；普通商品变更少，设 30 秒）。
2. 定时刷新（针对热点商品）：启动一个定时任务（如每 10 秒），批量查询热点商品的最新库存，主动更新本地缓存（覆盖旧值），进一步缩短不一致窗口。
	- 被动过期后首次查询会触发数据库请求（缓存穿透），高并发下可能出现 “缓存雪崩”
	- 主动刷新则可以批量刷新，避免集中穿透，而且它主要聚焦热点商品（如秒杀爆款）
3. “查询时校验” 终极兜底（极端场景）：
	- 当本地缓存显示 “库存> 0” 时，且缓存快过期了（如剩余时间<2s），先查询一次 Redis或数据库（轻量查询），确认库存是否真实 > 0；若真实库存已为 0，立即清空本地缓存，避免用旧缓存拦截请求；
	- 注意：给 “校验” 加 “频率限制”—— 同一商品短时间内只校验 1 次，例如当前时间 - 上次校验时间 > 500ms（可调整），则执行 1 次数据库校验，同时更新上次校验时间。
#### 2.4.3.2 TODO：分层缓存
#### 2.4.3.3 TODO：分段缓存解决单点问题
### 2.4.4 TODO：数据库主从模式&分库分表
让从库抗库存读查询的并发，反正保证最终一致性就行
### 2.4.5 库存扣减
#### 2.4.5.1 库存扣减的方式
1. 下单减库存：简单精准，但是有人可能恶意不支付。
	- 秒杀系统会用，因为秒杀下单不支付的现象是很少的
2. 付款减库存：会有库存超卖现象
3. 预扣库存：下单后库存为其保留一定的时间（如 10 分钟），超过库存将自动释放。一定程度防止恶意支付。这是业务系统常用方式
	- 但恶意买家完全可以在 10 分钟后再次下单，或者采用一次下单很多件的方式把库存减完。
	- 结合安全和反作弊的措施：
		- 给经常下单不付款的买家进行识别打标
		- 给某些类目设置最大购买件数
		- 以及对重复下单不付款的操作进行次数限制
		- ......
#### 2.4.5.2 缓存扣减
lua脚本实现原子性，**防止超卖**。
前提：如果你的秒杀商品的减库存逻辑非常单一，比如没有复杂的 SKU 库存和总库存这种联动关系的话，我觉得完全可以。但是如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存。

Redis 挂了后库存数据恢复的核心是 “持久化 + 兜底校验 + 故障转移”，确保缓存数据不丢失、恢复后与数据库一致。
##### 2.4.5.2.1 核心恢复原则
Redis 库存数据恢复的核心是 “双重保障”：一是通过 Redis 自身持久化减少数据丢失，二是依赖数据库底账做最终校验，避免恢复后数据不一致。
##### 2.4.5.2.2 Redis 层面：减少库存数据丢失
通过 Redis 持久化机制，确保挂了之后能恢复大部分库存数据，减少丢失范围。
1. 开启混合持久化（RDB+AOF）
	- RDB：定时生成内存快照（如每 5 分钟，或满足 “1000 次写操作 + 60 秒”），保存库存键（如`seckill:stock:${goodsId}`）的当前值。
	- AOF：记录每一次库存扣减的写操作（如`DECR seckill:stock:1001`），以日志形式追加到文件。
	- 混合模式：Redis 4.0 + 支持，AOF 文件头部是 RDB 快照，后续是增量 AOF 日志，兼顾 RDB 的恢复速度和 AOF 的完整性。
2. 关键配置优化
	- AOF 刷盘策略设为`everysec`：每秒将 AOF 缓冲区数据刷到磁盘，既保证性能，又将数据丢失风险控制在 1 秒内。
	- 关闭 AOF 重写期间的 fsync：避免重写时阻塞写操作，同时确保重写后日志完整。
3. 主从同步：开启 Redis 集群（主从 + 哨兵 / Cluster）：主节点挂了后，哨兵自动将从节点提升为主节点，从节点通过复制同步了主节点的库存数据，实现秒级故障转移，几乎无数据丢失。
##### 2.4.5.2.3 业务层面：兜底校验与数据一致性
即使 Redis 持久化恢复失败，也能通过数据库和业务逻辑兜底，确保库存数据准确。
1. 异步同步：每次 Redis 扣减库存后，通过消息队列发送 “库存变更日志” 到数据库，异步更新数据库。
	- 需要注意同步插入本地消息表防止消息丢失，然后用异步消息发送API。异步插入消息表+批量插入数据库可以提升性能，但有消息丢失风险。
	- 秒杀成功率低，所以对数据库插入压力不大。注意消息大小要小，快速插入。
	- 若 Redis 扣减成功，但数据库插入失败，需立即执行 Redis INCR 操作回滚库存，避免库存不一致。
2. 数据扣减库存和下单在同一事务：这样保障了一旦出什么事故也不会超卖
3. 定时对账：三层校验
	- 实时层：Redis 库存 vs 本地消息表（确保 Redis 操作完整，1 分钟 / 次）；
	- 中间层：本地消息表（已发送） vs 数据库订单 / 库存（确保消息被正确消费，5 分钟 / 次）；
	- 最终层：数据库库存 vs 订单汇总（确保数据库自身一致，10 分钟 / 次）。
4. 库存重加载：恢复时：从数据库读取对应商品的库存底账，重新写入 Redis，覆盖可能丢失的缓存数据。
	- 库存重加载需加锁：避免多实例同时重加载导致 Redis 库存被重复覆盖
	- 还需要等消息队列中的消息都消费完，才能同步到redis
5. 故障期间的降级处理
	- Redis 挂了后，暂时降级为 “数据库直接处理库存”。注意要通过限流+排队+降级保护数据库，防止被冲垮。
	- 待 Redis 恢复并加载完数据库底账后，再切回 “Redis 扣减 + DB 兜底” 模式。
##### 2.4.5.2.4 具体恢复流程（Redis 挂了之后）
1. **故障检测**：哨兵或监控系统发现 Redis 主节点挂了，触发告警。
2. **故障转移（集群场景）**：哨兵自动选举健康的从节点升级为主节点，应用通过哨兵获取新主节点地址。
3. **单机恢复（非集群场景）**：重启 Redis，优先通过混合持久化文件恢复数据：先加载 RDB 快照，再回放 AOF 增量日志，恢复到挂掉前的库存状态。
4. **库存重加载**：从数据库读取对应商品库存，重新写入 Redis。
5. **解除限制**：逐步放宽接入层限流阈值，恢复非核心业务逻辑
6. **恢复服务**：确认 Redis 库存与数据库一致后，恢复正常秒杀流程，Redis 继续承担高并发扣减任务。
#### 2.4.5.3 MySQL扣减
基于数据库的乐观锁，防止超卖：
```sql
update product set stock=stock-1 where id=product and stock > 0;
```

需要解决热点商品占满数据库连接、和高并发抢锁的问题
- 热点商品动态迁移到单独库中
- 事务轻量化：避免大事务，事务内不进行复杂计算；拆分事务，仅 “扣减库存” 放在独立事务，订单创建、日志记录等移至事务外异步执行（通过本地消息表或 MQ）。
- 排队：
	- Redis分布式锁：将并发控制从数据库层上移到缓存层。优点是响应延迟低，缺点是单商品QPS低（500-1000 QPS），适合中小规模秒杀
	- 应用层做排队：按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量。
		- 应用层只能做到单机的排队，但是应用机器数本身很多，可能一个商品在很多机器上都有队列，所以这种排队方式控制并发的能力仍然有限。
		- 注意队列限流，给每个商品的本地队列设置容量上限（如 500 条），超过则直接返回 “系统繁忙，请重试”，避免队列无限堆积导致超时。同时监控队列长度，超过阈值（如 300 条）则触发告警，手动扩容机器。
		- 负载均衡要确保同一商品的请求均匀分布到所有应用机器，避免单台机器被热点商品压垮。
	- 消息队列排队：
		- 优点是流量削峰能力强，支持更大的QPS
			- 故障隔离，系统容错性更强：若 MySQL 临时不可用，消费端可暂停消费，消息队列会持久化存储消息，待 MySQL 恢复后继续处理，避免请求丢失
			- 支持动态扩容，弹性应对流量：秒杀过程中若消息堆积，可快速扩容消费端实例（如从 2 台增至 10 台），分摊处理压力，比纯 MySQL 方案的扩容更灵活（无需调整分表分片）。
		- 缺点是请求变成异步，需要额外想办法通知用户结果
			- 增加维护成本，消息丢失、重复消费等问题都要解决
	- 数据库层做排队：阿里的数据库团队开发了针对这种 MySQL 的 InnoDB 层上的补丁程序（patch），可以在数据库层上对单行记录做到并发排队。
		- 缺点：依赖特定 MySQL 分支，通用性差；维护成本高，需深度数据库经验，不适合中小团队；排队延迟可能累积，不适合低延迟场景。

总结：

| 方案            | 削峰能力                | 一致性保障难度            | 延迟情况        | 维护成本         | 适用场景                      |
| ------------- | ------------------- | ------------------ | ----------- | ------------ | ------------------------- |
| 消息队列方案        | 强（支持 10 万 + QPS 峰值） | 高（需处理丢失 / 重复 / 顺序） | 中（1-5 秒）    | 中（需维护 MQ）    | 中大规模秒杀，容忍延迟               |
| InnoDB 排队补丁方案 | 3000-5000 TPS       | 低                  | 中（排队延迟）     | 高（需内核经验）     | 大规模秒杀，依赖 MySQL 生态，团队有内核能力 |
| 应用层本地队列方案     | 中（支持 2000-5000 QPS） | 低（仅单机器串行）          | 低（10-100ms） | 低（无额外组件）     | 中小规模秒杀，追求低延迟              |
| Redis 分布式锁方案  | 弱（支持 500-1000 QPS）  | 中（需处理锁超时 / 死锁）     | 低（5-20ms）   | 中（需维护 Redis） | 小规模秒杀，对一致性要求高             |

## 2.5 用户体验
### 2.5.1 TODO：异步请求怎么通知用户结果
以下方案：
1. 一是可以给前端一个查询接口，这种查询流量，因为后端完全知晓结果, 可以全部放到redis中(甚至local cache), 不会有穿透到DB的流量, 因此可以做到速度很快。缺点是服务端的请求数会增加不少。
2. 二是采用主动 push 的方式，这种就要求服务端和客户端保持连接了，服务端处理完请求主动 push 给客户端，这种方式的缺点是服务端的连接数会比较多。

异步的请求失败直接丢弃就好了，最坏的结果就是这个人没有抢到而已。

## 2.6 事后复盘优化
每次秒杀活动结束后，都要进行全面的复盘分析：
- 数据统计：统计活动的各项数据，包括参与人数、成功人数、成功率、峰值 QPS、平均响应时间等；
- 问题分析：分析活动中出现的问题，如系统故障、性能瓶颈、用户投诉等，找出问题的根本原因；
- 性能评估：评估系统的性能表现，与预期目标对比，分析差距和改进空间；
- 用户反馈：收集用户的反馈意见，了解用户体验，发现产品和流程的改进点；
- 优化建议：根据复盘结果，提出系统优化建议，包括架构调整、代码优化、流程改进等。

# 3 流程
## 3.1 预热期：秒杀前准备
1. 选择哪些商品参与秒杀，每个商品多少库存。
2. 秒杀消息宣发，吸引用户
3. 用户报名，大致得知多少用户参与
4. 预热缓存
	1. 静态资源（如商品标题、描述、图片等）同步到 CDN
	2. 将商品库存加载到缓存
5. 热点数据识别和隔离
6. API 网关配置限流规则，服务集群扩容至目标实例数
7. 系统初始化与校验：检查所有服务组件是否正常运行，包括 Redis 集群、MySQL 数据库、消息队列、API 网关等。进行压力测试，模拟一定规模的并发请求，验证系统的稳定性和性能。设置限流规则、熔断策略、降级预案等，确保系统能够应对突发情况。

## 3.2 抢购期：流量峰值处理
1. 秒杀系统展示商品信息和秒杀按钮，秒杀开始前按钮置灰。这里是动静分离的地方，静态资源请求发给CDN，CDN获取不到再回源到源站。
2. 开始后，用户点击秒杀按钮，前端首先进行本地校验，包括：检查当前时间是否在活动时间内；验证用户是否已经登录；检查用户是否已经参与过本次秒杀；进行简单的防重复点击处理（按钮置灰 300ms）。
3. 然后答题or验证码，请求按时间分片，开始秒杀。秒杀请求发到秒杀系统
4. 秒杀请求达到lvs/nginx负载均衡集群，请求被分配到不同的API网关
	- 注意：nginx也可以实现全局限流
5. API网关实现限流（IP / 用户 ID / 接口维度）、用户登录、初步校验（活动参与资格、黑名单）等功能
	- 然后是热点数据限制（感觉在API网关做更好？）：用商品的hash分组把请求划分成不同的队列进行处理。避免热点商品抢占了所有连接
6. 然后请求到达秒杀服务器，这里也可以再用令牌桶算法实现一道限流
7. （假设不用MQ排队请求，这样是同步请求）
	- 问题：用了MQ之后的流程
8. 防重判断：如果用户用完了秒杀次数，那么就直接返回秒杀失败
	- 问题：怎么实现？用数据库判断就很慢，需要用缓存
9. 安全和反作弊措施：给经常下单不付款的买家进行识别打标（可以在被打标的买家下单时不减库存）、给某些类目设置最大购买件数（例如，参加活动的商品一人最多只能买 3 件）、以及对重复下单不付款的操作进行次数限制等
10. 缓存查询：先查询库存的 本地||redis 缓存，不存在再去数据库找。库存为0了就直接返回失败，否则继续往下走
	- 这里允许一定的缓存数据不一致，最坏情况就是多放了些请求
	- 本地缓存的问题是，当更新数据库时，难以让别的机器上的本地缓存失效。
		- 低效的方法
			- 弄个RPC接口，更新数据库时广播所有机器，但是这样效率低、消息丢失(RPC调用失败)问题
			- 对商品做hash分组，让某一个商品只对应一个机器，但是这样机器就有状态并且过热了，有击穿风险
		- 有效的方法：可以加一个失效中心，让它监控数据库变更并广播给所有机器。依靠消息队列能有效地传递消息
			- 问题：查查失效中心的实现？
	- 问题：还有一个分段库存的办法
	- 问题：还有分层缓存，也就是本地缓存、redis缓存都用上
11. 接下来是扣减库存。扣减失败返回秒杀失败，否则继续往下走
	- 扣减逻辑不复杂，比如没有复杂的 SKU 库存和总库存这种联动关系的话，那么可以直接在redis中扣减
		- 数据一致性兜底策略：redis挂了数据丢失也没关系，可以在重启时进行数据库里的订单商品数进行计算，计算出剩余库存，然后存到redis中。
		- 问题：兜底怎么实现？
	- 复杂的扣减，还是需要在mysql中扣减.。要做好排队，减少抢锁冲突，应对高并发写
		- 应用层做排队：上面步骤中的商品hash分组队列。可以用Redis分布式锁实现，这样能在应用层全局实现商品hash排队，而不仅仅是单个机器
		- 数据库层做排队：阿里的技术
12. 扣减成功，返回秒杀成功

## 3.3 下单&履约期：异步创建订单
1. MQ异步调用订单系统生成订单。可以采用分布式通知型事务保证一致性。
	- MQ事务消息：先发送半消息，然后扣减，扣减成功发送commit，扣减失败发送rollback（防止消息丢失还需要消息表）。订单系统再commit之后可以收到消息，从而触发订单生成。订单系统需要注意消费幂等，防止重复下单。
	- 本地消息表：参见分布式-事务
2. 通知服务消费消息，向用户发送短信 / APP 推送
3. 用户支付完成，则秒杀彻底结束。如果一段时间没支付，超时订单取消，则继续往下走
4. 订单取消，订单系统会调用秒杀系统的RPC告知，秒杀系统恢复这个商品的库存
	- redis扣减库存，则在redis里面恢复即可
	- mysql扣减库存，则在mysql里面恢复，并且要删除缓存

---
# 4 引用
2025-10-30 16:22
Status: #idea
Tags: [[场景题和设计题]]

# 1 前言
**秒杀其实主要解决两个问题，一个是并发读，一个是并发写**。
- 并发读的核心优化理念是尽量减少用户到服务端来“读”数据，或者让他们读更少的数据；
- 并发写的处理原则也一样，它要求我们在数据库层面独立出来一个库，做特殊的处理。
另外，我们还要针对秒杀系统做一些保护，针对意料之外的情况设计**兜底方案**，以防止最坏的情况发生。

秒杀的整体架构可以概括为“稳、准、快”几个关键字。
- 所谓“稳”，就是整个系统架构要满足**高可用**，流量符合预期时肯定要稳定，就是超出预期时也同样不能掉链子
- 然后就是“准”，一旦库存不对，那平台就要承担损失，所以“准”就是要求保证数据的**一致性**。
- 最后再看“快”，也就是**高性能**，不光是服务端要做极致的性能优化，而且在整个请求链路上都要做协同的优化，每个地方快一点，整个系统就完美了。
在整个用户请求路径上从浏览器到服务端我们要遵循几个**架构原则**，就是要**保证用户请求的数据尽量少、请求数尽量少、路径尽量短、依赖尽量少，并且不要有单点**。

# 2 架构原则
## 2.1 原则分类
### 2.1.1 数据尽量少
**首先是指用户请求的数据能少就少**。请求的数据包括上传给系统的数据和系统返回给用户的数据（通常就是网页）。
服务器在写网络时通常都要做压缩和字符编码，这些都非常消耗 CPU，所以减少传输的数据量可以显著减少 CPU 的使用。

**其次，“数据要尽量少”还要求系统依赖的数据能少就少**，包括系统完成某些业务逻辑需要读取和保存的数据，这些数据一般是和后台服务以及数据库打交道的。调用其他服务会涉及数据的序列化和反序列化，而这也是 CPU 的一大杀手，同样也会增加延时。而且，数据库本身也容易成为一个瓶颈，所以和数据库打交道越少越好，数据越简单、越小则越好。

### 2.1.2 请求数要尽量少
用户请求的页面返回后，浏览器渲染这个页面还要包含其他的**额外请求**，比如说，这个页面依赖的 CSS/JavaScript、图片，以及 Ajax 请求等等都定义为“额外请求”，这些额外请求应该尽量少。
因为浏览器每发出一个请求都多少会有一些消耗，例如建立连接要做三次握手，有的时候有页面依赖或者连接数限制，一些请求（例如 JavaScript）还需要串行加载等。另外，如果不同请求的域名不一样的话，还涉及这些域名的 DNS 解析，可能会耗时更久。
所以你要记住的是，减少请求数可以显著减少以上这些因素导致的资源消耗。

例如，减少请求数最常用的一个实践就是合并 CSS 和 JavaScript 文件，把多个 JavaScript 文件合并成一个文件，在 URL 中用逗号隔开（https://g.xxx.com/tm/xx-b/4.0.94/mods/??module-preview/index.xtpl.js,module-jhs/index.xtpl.js,module-focus/index.xtpl.js）。这种方式在服务端仍然是单个文件各自存放，只是服务端会有一个组件解析这个 URL，然后动态把这些文件合并起来一起返回。
不过现在浏览器都会有缓存，而且vue等框架会压缩合并静态资源，所以上面的技巧用处不大了。

### 2.1.3 路径要尽量短
所谓“路径”，就是用户发出请求到返回数据这个过程中，需求经过的中间的节点数。通常，这些节点可以表示为一个系统或者一个新的 Socket 连接（比如代理服务器只是创建一个新的 Socket 连接来转发请求）。每经过一个节点，一般都会产生一个新的 Socket 连接。
**要缩短访问路径有一种办法，就是多个相互强依赖的应用合并部署在一起，把远程过程调用（RPC）变成 JVM 内部之间的方法调用**。在《大型网站技术架构演进与性能优化》一书中，我也有一章介绍了这种技术的详细实现。

### 2.1.4 依赖要尽量少
这里的依赖指的是**强依赖**。比如说你要展示秒杀页面，而这个页面必须强依赖商品信息、用户信息，还有其他如优惠券、成交列表等这些对秒杀不是非要不可的信息（弱依赖），这些弱依赖在紧急情况下就可以去掉。

**要减少依赖，我们可以给系统进行分级**，比如 0 级系统、1 级系统、2 级系统、3 级系统，0 级系统如果是最重要的系统，那么 0 级系统强依赖的系统也同样是最重要的系统，以此类推。
注意，0 级系统要尽量减少对 1 级系统的强依赖，防止重要的系统被不重要的系统拖垮。例如支付系统是 0 级系统，而优惠券是 1 级系统的话，在极端情况下可以把优惠券给降级，防止支付系统被优惠券这个 1 级系统给拖垮。

### 2.1.5 不要有单点
那如何避免单点呢？**我认为关键点是避免将服务的状态和机器绑定，即把服务无状态化**，这样服务就可以在机器中随意移动。
如何那把服务的状态和机器解耦呢？这里也有很多实现方式。**例如把和机器相关的配置动态化，这些参数可以通过配置中心来动态推送**，在服务启动时动态拉取下来，我们在这些配置中心设置一些规则来方便地改变这些映射关系。

应用无状态化是有效避免单点的一种方式，但是像存储服务本身很难无状态化，因为数据要存储在磁盘上，本身就要和机器绑定，那么**这种场景一般要通过冗余多个备份的方式来解决单点问题**。

## 2.2 架构是平衡的艺术
前面介绍了这些设计上的一些原则，但是你有没有发现，我一直说的是“尽量”而不是“绝对”？
我们曾经把有些 CSS 内联进页面里，这样做可以减少依赖一个 CSS 的请求从而加快首页的渲染，但是同样也增大了页面的大小，又不符合“数据要尽量少”的原则，这种情况下我们为了提升首屏的渲染速度，只把首屏的 HTML 依赖的 CSS 内联进来，其他 CSS 仍然放到文件中作为依赖加载，尽量实现首屏的打开速度与整个页面加载性能的平衡。
所以说，**架构是一种平衡的艺术**，而最好的架构一旦脱离了它所适应的场景，一切都将是空谈。

## 2.3 不同场景下的不同架构案例
针对“秒杀”这个场景，怎样才是一个好的架构呢？下面我以淘宝早期秒杀系统架构的演进为主线，来帮你梳理不同的请求体量下，我认为的最佳秒杀系统架构。

如果你想快速搭建一个简单的秒杀系统，只需要把你的商品购买页面增加一个“定时上架”功能，仅在秒杀开始时才让用户看到购买按钮，当商品的库存卖完了也就结束了。这就是当时第一个版本的秒杀系统实现方式。

但随着请求量的加大（比如从 1w/s 到了 10w/s 的量级），这个简单的架构很快就遇到了瓶颈，因此需要做架构改造来提升系统性能。这些架构改造包括：
1. **独立系统**：把秒杀系统独立出来单独打造一个系统，这样可以有针对性地做优化
2. **独立集群**：在系统部署上也独立做一个机器集群，这样秒杀的大流量就不会影响到正常的商品购买集群的机器负载；
3. **缓存热点数据**：将热点数据（如库存数据）单独放到一个缓存系统中，以提高“读性能”；
4. **防刷**：增加秒杀答题，防止有秒杀器抢单。
此时的系统架构变成了下图这个样子。最重要的就是，秒杀详情成为了一个独立的新系统，另外核心的一些数据放到了缓存（Cache）中，其他的关联系统也都以独立集群的方式进行部署。
![[image-169.png]]

然而这个架构仍然支持不了超过 100w/s 的请求量，所以为了进一步提升秒杀系统的性能，我们又对架构做进一步升级，比如：
1. **动静分离**：对页面进行彻底的动静分离，使得用户秒杀时不需要刷新整个页面，而只需要点击抢宝按钮，借此把页面刷新的数据降到最少；
2. **本地缓存**：在服务端对秒杀商品进行本地缓存，不需要再调用依赖系统的后台服务获取数据，甚至不需要去公共的缓存集群中查询数据，这样不仅可以减少系统调用，而且能够避免压垮公共缓存集群。
	1. 这么优化主要是根据秒杀系统中的商品特性有关系，秒杀的商品基本不会临时再变动属性。前期上传审核成功后，就会做热点数据处理。
	2. 这里应用服务器有状态了，但为了极致的性能，不得已而为之
	3. 注意库存不会放在本地缓存，**本地缓存只放静态数据**。 库存是放在独立的缓存系统里，如redis。库存是采用主动失效的方式来失效缓存
3. **系统限流**：增加系统限流保护，防止最坏情况发生。
经过这些优化，系统架构变成了下图中的样子。最关键的详情和交易系统都增加了本地缓存，来提前缓存秒杀商品的信息，热点数据库也做了独立部署，等等。
![[image-170.png]]

秒杀的场景来说，不同QPS量级下瓶颈也会不一样，**10w级别可能瓶颈就在数据读取上**，通过增加缓存一般就能解决，**如果要到100w那么，可能服务端的网络可能都是瓶颈**，所以要把大部分的静态数据放到cdn上甚至缓存在浏览器里
**其实越到后面需要定制的地方越多，也就是越“不通用”**。例如，把秒杀商品缓存在每台机器的内存中，这种方式显然不适合太多的商品同时进行秒杀的情况，因为单机的内存始终有限。所以要取得极致的性能，就要在其他地方（比如，通用性、易用性、成本等方面）有所牺牲。

## 2.4 一些问题
- 通过什么方式往本地cache 写数据呢？
用订阅的方式，在系统初始化时加载到内存

- 秒杀系统的及时性非常高，把库存写进cache ，怎么及时更新呢？
有两种方法，一是定时更新取3秒；二是主动更新，数据库字段更新后发消息更新缓存，这个需要用到一个组件阿里叫metaq，就是数据库字段更新会产生一条消息，集群的环境下通过消息通知所有机器去更新缓存。
另外cache里库存不需要100%和数据库一致。缓存没有必要极致追求数据的准确性，只要保证最终一致性。缓存本身为了减少数据库的压力。

- 我对秒杀系统有个最大的疑惑，就是从页面发出的请求用同步还是异步？如果用同步的话：1，后端服务必然是分布式的，需要经过多个节点，时间可能会被拉的很长，同时失败的可能性也会增大；2，基于1的情况，会有一个长连接长时间存在，这样随着请求的增多，连接资源越来越少，系统吞吐量会是瓶颈。如果用异步的话：不断的轮询必然会增加系统的请求量，对连接资源也是一种浪费。所以，这应该怎么选择呢？
可以异步处理完后websocket推动前端

- 秒杀系统压测工具哪个比较好？
Apache ab就很好

# 3 动静分离
## 3.1 定义
所谓“动静分离”，其实就是把用户请求的数据（如 HTML 页面）划分为“动态数据”和“静态数据”。
**“动态数据”和“静态数据”的主要区别就是看页面中输出的数据是否和 URL、浏览者、时间、地域相关，以及是否含有 Cookie 等私密数据**。比如说：
1. 很多媒体类的网站，某一篇文章的内容不管是你访问还是我访问，它都是一样的。所以它就是一个典型的静态数据
2. 如果现在访问淘宝的首页，每个人看到的页面可能都是不一样的，淘宝首页中包含了很多根据访问者特征推荐的信息，而这些个性化的数据就可以理解为动态数据了。
**简单来说就是数据中是否含有和访问者相关的个性化数据**。

## 3.2 怎样对静态数据做缓存
怎样对静态数据做缓存呢？我在这里总结了几个重点。
**第一，你应该把静态数据缓存到离用户最近的地方**。常见的就三种，用户浏览器里、CDN 上或者在服务端的 Cache 中。你应该根据情况，把它们尽量缓存到离用户最近的地方。
**第二，静态化改造就是要直接缓存 HTTP 连接**。相较于普通的数据缓存而言，你肯定还听过系统的静态化改造（Nginx的proxy_cache_key、CDN 都算）。静态化改造是直接缓存 HTTP 连接而不是仅仅缓存数据，Web 代理服务器根据请求 URL，直接取出对应的 HTTP 响应头和响应体然后直接返回，这个响应过程简单得连 HTTP 协议都不用重新组装，甚至连 HTTP 请求头也不需要解析。
**第三，让谁来缓存静态数据也很重要**。因为 Java 系统本身也有其弱点（比如不擅长处理大量连接请求，每个连接消耗的内存较多，Servlet 容器解析 HTTP 协议较慢），所以你可以不在 Java 层做缓存，而是直接在 Web 服务器层上做。Web 服务器（如 Nginx、Apache、Varnish）也更擅长处理大并发的静态文件请求。

## 3.3 如何做动静分离的改造
理解了动静态数据的“why”和“what”，接下来我们就要看“how”了。我们从以下 5 个方面来分离出动态内容。
1. **URL 唯一化**。商品详情系统天然地就可以做到 URL 唯一化，比如每个商品都由 ID 来标识，那么 http://item.xxx.com/item.htm?id=xxxx 就可以作为唯一的 URL 标识。就以 URL 作为缓存的 Key。
2. **分离浏览者相关的因素**。浏览者相关的因素包括是否已登录，以及登录身份等，这些相关因素我们可以单独拆分出来，通过动态请求来获取。
3. **分离时间因素**。服务端输出的时间也通过动态请求获取。
4. **异步化地域因素**。详情页面上与地域相关的因素做成异步方式获取，当然你也可以通过动态请求方式获取，只是这里通过异步获取更合适。
5. **缓存中去掉 Cookie**。服务端输出的页面包含的 Cookie 可以通过代码软件来删除，如 Web 服务器 Varnish 可以通过 unset req.http.cookie 命令去掉 Cookie。注意，这里说的去掉 Cookie 并不是用户端收到的页面就不含 Cookie 了，而是说，在缓存的静态数据中不含有 Cookie。

前面我们介绍里用缓存的方式来处理静态数据。而动态内容的处理通常有两种方案：ESI（Edge Side Includes）方案和 CSI（Client Side Include）方案。
1. **ESI 方案（或者 SSI）**：即在 Web 代理服务器上做动态内容请求，并将请求插入到静态页面中，当用户拿到页面时已经是一个完整的页面了。这种方式对服务端性能有些影响，但是用户体验较好。
2. **CSI 方案**。即单独发起一个异步 JavaScript 请求，以向服务端获取动态内容。这种方式服务端性能更佳，但是用户端页面可能会延时，体验稍差。

## 3.4 动静分离的几种架构方案
如何在系统架构上进一步对这些动态和静态数据重新组合，再完整地输出给用户呢？根据架构上的复杂度，有 3 种方案可选：
1. 实体机单机部署；
2. 统一 Cache 层；
3. 上 CDN。

### 3.4.1 方案 1：实体机单机部署
这种方案是将虚拟机改为实体机，以增大 Cache 的容量，并且采用了**一致性 Hash 分组**的方式来提升命中率。这里将 Cache 分成若干组，是希望能达到命中率和访问热点的平衡。Hash 分组越少，缓存的命中率肯定就会越高，但短板是也会使单个商品集中在一个分组中，容易导致 Cache 被击穿，所以我们应该适当增加多个相同的分组，来平衡访问热点和命中率的问题。
![[image-171.png]]

实体机单机部署有以下几个优点：
1. 没有网络瓶颈，而且能使用大内存；
2. 既能提升命中率，又能减少 Gzip 压缩；
3. 减少 Cache 失效压力，因为采用定时失效方式，例如只缓存 3 秒钟，过期即自动失效。

这个方案中，虽然把通常只需要虚拟机或者容器运行的 Java 应用换成实体机，优势很明显，它会增加单机的内存容量，但是一定程度上也造成了 CPU 的浪费，因为单个的 Java 进程很难用完整个实体机的 CPU。
另外就是，一个实体机上部署了 Java 应用又作为 Cache 来使用，这造成了运维上的高复杂度，所以这是一个折中的方案。如果你的公司里，没有更多的系统有类似需求，那么这样做也比较合适，如果你们有多个业务系统都有静态化改造的需求，那还是建议把 Cache 层单独抽出来公用比较合理。

---
# 4 引用
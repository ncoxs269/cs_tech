2025-04-30 15:27
Status: #idea
Tags: [[Redis]]


# 1 Redis 持久化
Redis 的持久化主要有两大机制，即 **AOF（Append Only File）日志和 RDB 快照**。
它们保证了高可靠的一个方面：数据尽量少丢失。

## 1.1 AOF 日志
### 1.1.1 基础知识
我们比较熟悉的是数据库的**写前日志（Write Ahead Log, WAL）**，也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，**AOF 日志正好相反，它是写后日志**，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。
传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 **AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的**（这相当于 MySql binlog 中的 statement 格式）。

为了避免额外的检查开销，**Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查**。Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。
除此之外，AOF 还有一个好处：**它是在命令执行后才记录日志，所以不会阻塞当前的写操作**。

### 1.1.2 风险
AOF 也有两个潜在的风险：
1. 如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就**有丢失的风险**。
2. AOF 虽然避免了对当前命令的阻塞，但**可能会给下一个操作带来阻塞风险**。这是因为，**AOF 日志也是在主线程中执行的**，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。

### 1.1.3 三种写回策略
AOF 机制给我们提供了三个选择，也就是 AOF 配置项 `appendfsync` 的三个可选值：
1. **Always**，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
2. **Everysec**，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
3. **No**，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。（用 write 写到文件系统缓存，操作系统觉决定何时调用 fsync）

### 1.1.4 AOF 重写
AOF 重写机制指的是，对过大的 AOF 文件进行重写，以此来压缩 AOF 文件的大小。 具体的实现是：检查当前键值数据库中的键值对，记录键值对的最终状态，从而实现**对某个键值对重复操作后产生的多条操作记录压缩成一条的效果**。

和 AOF 日志由主线程写回不同，重写过程是由后台子进程 `bgrewriteaof` 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。我把重写的过程总结为**一个拷贝，两处日志**。
**“一个拷贝”就是指**，每次执行重写时，主线程 fork 出后台的 `bgrewriteaof` 子进程。此时，fork 会把父进程的页表——即虚实映射关系——拷贝给子进程（而不会拷贝物理内存）。子进程复制了父进程页表，也能共享访问父进程的内存数据了，类似于有了父进程的所有内存数据。然后，`bgrewriteaof` 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。
**“两处日志”又是什么呢**？因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个旧 AOF 日志的操作仍然是齐全（相对来说）的，可以用于恢复。

另外主进程还会写一个新的aof缓冲文件(这个文件存储fork子进程之后产生的新数据，就是一行行命令)。等到新的aof文件重写完之后，会把新的aof缓冲区数据合并到新的aof文件里(这一步很快)。
然后合并完之后就把主线程写的老aof文件切换成新的，这样就完成了一次aof的重写。

#### 1.1.4.1 重写时机
1. `auto-aof-rewrite-min-size`: 表示运行 AOF 重写时文件的最小大小，默认为 64MB
2. `auto-aof-rewrite-percentage`: 这个值的计算方法是：当前 AOF 文件大小和上一次重写后 AOF 文件大小的差值，再除以上一次重写后 AOF 文件大小。也就是当前 AOF 文件比上一次重写后 AOF 文件的增量大小，和上一次重写后 AOF 文件大小的比值。

AOF 文件大小同时超出上面这两个配置项时，会触发 AOF 重写。

#### 1.1.4.2 重写风险
Redis 采用 fork 子进程重写 AOF 文件时，潜在的阻塞风险包括：fork 子进程和 AOF 重写过程中父进程产生写入的场景，下面依次介绍。
1. **fork 子进程，fork 这个瞬间一定是会阻塞主线程的**。fork 采用操作系统提供的**写时复制(Copy On Write)机制**，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题。
    但 fork 子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝**内存页表（虚拟内存和物理内存的映射索引表）**，这个拷贝过程会消耗大量 CPU 资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork 阻塞时间越久。
    
    拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写时复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。
2. fork 出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行 AOF 重写，把内存中的所有数据写入到 AOF 文件中。
    但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的 key，那么这个时候父进程就会真正拷贝这个 key 对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。
    
    因为内存分配是以页为单位进行分配的，默认 4k，如果父进程此时操作的是一个 bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。
    
    另外，如果操作系统开启了内存**大页机制(Huge Page，页面大小 2M)**，那么父进程申请内存时阻塞的概率将会大大提高，所以在 Redis 机器上需要关闭 Huge Page 机制。
    
    Redis 每次 fork 生成 RDB 或 AOF 重写完成后，都可以在 Redis log 中看到父进程重新申请了多大的内存空间。

## 1.2 RDB 内存快照
RDB 就是 Redis DataBase 的缩写。和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复。

### 1.2.1 基础知识
Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是**全量快照**。
Redis 提供了两个命令来生成 RDB 文件，分别是 `save` 和 `bgsave`。
1. `save`：在主线程中执行，会导致阻塞；
2. `bgsave`：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。

Redis 就会借助操作系统提供的**写时复制技术（Copy-On-Write, COW）**，在执行快照的同时，正常处理写操作。

### 1.2.2 增量快照
所谓增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。
在第一次做完全量快照后，T1 和 T2 时刻如果再做快照，我们只需要将被修改的数据写入快照文件就行。但是，这么做的前提是，**我们需要记住哪些数据被修改了**。你可不要小瞧这个“记住”功能，它需要我们使用额外的元数据信息去记录哪些数据被修改了，**这会带来额外的空间开销问题**。

### 1.2.3 RDB 和 AOF 混合使用
Redis 4.0 中提出了一个**混合使用 AOF 日志和内存快照**的方法（设置的参数是：`aof-use-rdb-preamble yes`）。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。
这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，**AOF 日志也只用记录两次快照间的操作，只需要记录增量记录即可**，记录量就小了，因此，就不会出现文件过大的情况了，也可以避免重写开销。

最后，关于 AOF 和 RDB 的选择问题，我想再给你提三点建议：
1. 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；
2. 如果允许分钟级别的数据丢失，可以只使用 RDB；
3. 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。

# 2 Redis 监控
## 2.1 慢查询日志
在使用慢查询日志前，我们需要设置两个参数：
- `slowlog-log-slower-than`：这个参数表示，慢查询日志对执行时间大于多少微秒的命令进行记录。
- `slowlog-max-len`：这个参数表示，慢查询日志最多能记录多少条命令记录。慢查询日志的底层实现是一个具有预定大小的先进先出队列，一旦记录的命令数量超过了队列长度，最先记录的命令操作就会被删除。这个值默认是 128。但是，如果慢查询命令较多的话，日志里就存不下了；如果这个值太大了，又会占用一定的内存空间。所以，一般建议设置为 1000 左右，这样既可以多记录些慢查询命令，方便排查，也可以避免内存开销。

我们可以使用 `SLOWLOG GET` 命令，来查看慢查询日志中记录的命令操作，例如，我们执行如下命令，可以查看最近的一条慢查询的日志信息：
```redis
$ SLOWLOG GET 1
1) 1) (integer) 33           //每条日志的唯一ID编号
   2) (integer) 1600990583   //命令执行时的时间戳
   3) (integer) 20906        //命令执行的时长，单位是微秒
   4) 1) "keys"               //具体的执行命令和参数
      2) "abc*"
   5) "127.0.0.1:54793"      //客户端的IP和端口号
   6) ""                     //客户端的名称，此处为空
```

## 2.2 latency monitor
Redis 从 2.8.13 版本开始，还提供了 latency monitor 监控工具，这个工具可以用来监控 Redis 运行过程中的峰值延迟情况。
和慢查询日志的设置相类似，要使用 latency monitor，首先要设置命令执行时长的阈值。当一个命令的实际执行时长超过该阈值时，就会被 latency monitor 监控到。比如，我们可以把 latency monitor 监控的命令执行时长阈值设为 1000 微秒，如下所示：
```bash
$ config set latency-monitor-threshold 1000
```
设置好了 latency monitor 的参数后，我们可以使用 `latency latest` 命令，查看最新和最大的超过阈值的延迟情况，如下所示：
```bash
$ latency latest
1) 1) "command"
   2) (integer) 1600991500    //命令执行的时间戳
   3) (integer) 2500           //最近的超过阈值的延迟
   4) (integer) 10100          //最大的超过阈值的延迟
```

## 2.3 如何排查 Redis 的 bigkey？
### 2.3.1 Redis 自带 bigkey 查询
Redis 可以在执行 redis-cli 命令时带上 `--bigkeys` 选项，进而对整个数据库中的键值对大小情况进行统计分析，比如说，统计每种数据类型的键值对个数以及平均大小。
此外，这个命令执行后，会输出每种数据类型中最大的 bigkey 的信息，对于 String 类型来说，会输出最大 bigkey 的字节长度，对于集合类型来说，会输出最大 bigkey 的元素个数，如下所示：
```bash
$ ./redis-cli  --bigkeys

-------- summary -------
Sampled 32 keys in the keyspace!
Total key length in bytes is 184 (avg len 5.75)

//统计每种数据类型中元素个数最多的bigkey
Biggest   list found 'product1' has 8 items
Biggest   hash found 'dtemp' has 5 fields
Biggest string found 'page2' has 28 bytes
Biggest stream found 'mqstream' has 4 entries
Biggest    set found 'userid' has 5 members
Biggest   zset found 'device:temperature' has 6 members

//统计每种数据类型的总键值个数，占所有键值个数的比例，以及平均大小
4 lists with 15 items (12.50% of keys, avg size 3.75)
5 hashs with 14 fields (15.62% of keys, avg size 2.80)
10 strings with 68 bytes (31.25% of keys, avg size 6.80)
1 streams with 4 entries (03.12% of keys, avg size 4.00)
7 sets with 19 members (21.88% of keys, avg size 2.71)
5 zsets with 17 members (15.62% of keys, avg size 3.40)
```

这个工具是通过扫描数据库来查找 bigkey 的，所以，在执行的过程中，会对 Redis 实例的性能产生影响。如果你在使用主从集群，我建议你在从节点上执行该命令。
我给你两个小建议：第一个建议是，在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；第二个建议是，可以使用 `-i` 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能。例如，我们执行如下命令时，redis-cli 会每扫描 100 次暂停 100 毫秒（0.1 秒）。
```bash
$ ./redis-cli  --bigkeys -i 0.1
```

### 2.3.2 手动统计前 N 个 bigkey 和内存占用
当然，使用 Redis 自带的 `--bigkeys` 选项排查 bigkey，有两个不足的地方：
- 这个方法只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的 bigkey；
- 对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。但是，一个集合中的元素个数多，并不一定占用的内存就多。因为，有可能每个元素占用的内存很小，这样的话，即使元素个数有很多，总内存开销也不大。

如果我们想统计每个数据类型中占用内存最多的前 N 个 bigkey，可以自己开发一个程序，来进行统计。我给你提供一个基本的开发思路：使用 `SCAN` 命令对数据库扫描，然后用 `TYPE` 命令获取返回的每一个 key 的类型。接下来，对于 String 类型，可以直接使用 `STRLEN` 命令获取字符串的长度，也就是占用的内存空间字节数。
对于集合类型来说，有两种方法可以获得它占用的内存大小。如果你能够预先从业务层知道集合元素的平均大小，那么，可以使用下面的命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小了。
- List 类型：`LLEN` 命令；
- Hash 类型：`HLEN` 命令；
- Set 类型：`SCARD` 命令；
- Sorted Set 类型：`ZCARD` 命令；

如果你不能提前知道写入集合的元素大小，可以使用 `MEMORY USAGE` 命令（需要 Redis 4.0 及以上版本），查询一个键值对占用的内存空间。例如，执行以下命令，可以获得 key 为 user:info 这个集合类型占用的内存空间大小：
```bash
$ MEMORY USAGE user:info
(integer) 315663239
```

此外，关于 bigkey 排查，rdb-tools 是很好的工具。

---
# 3 引用
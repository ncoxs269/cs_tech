2025-04-27 09:35
Status: #idea
Tags: [[MySQL]]


# 1 全局锁
## 1.1 概念和用法
全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock` (FTWRL)。之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。（使用 `unlock tables` 命令可以解除）
**全局锁的典型使用场景是，做全库逻辑备份**。也就是把整库每个表都 `select` 出来存成文本。

但是让整库都只读，听上去就很危险：
- 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
- 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。如果是读写分离，从库负责 Read，binlog 不能停止且要保持实时性。

## 1.2 备份时必须加全局锁的原因
假设你现在要维护“极客时间”的购买系统，关注的是用户账户余额表和用户课程表。现在发起一个逻辑备份。
假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。如果时间顺序上是先备份账户余额表 (`u_account`)，然后用户购买，然后备份用户课程表 (`u_course`)，会怎么样呢？
![[image-41.png]]
可以看到，这个备份结果里，用户 A 的数据状态是“账户余额没扣，但是用户课程表里面已经多了一门课”。如果后面用这个备份来恢复数据的话，用户 A 就发现，自己赚了。

作为用户可别觉得这样可真好啊，你可以试想一下：如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，又可能会出现什么结果？也就是说，不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。

## 1.3 与 mysqldump 的对比
官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数 `–single-transaction` 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而**由于 MVCC 的支持，这个过程中数据是可以正常更新的**。
你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？**一致性读是好，但前提是引擎要支持这个隔离级别**。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。
所以，**single-transaction 方法只适用于所有的表使用事务引擎的库**。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。

## 1.4 与 readonly 的对比
你也许会问，既然要全库只读，为什么不使用 `set global readonly=true` 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：
1. 一是，在有些系统中，**readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库**。因此，修改 global 变量的方式影响面更大，我不建议你使用。
2. 二是，**在异常处理机制上有差异**。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。

# 2 表级锁
MySQL 里面表级别的锁有两种：一种是**表锁**，一种是**元数据锁（meta data lock，MDL)**。表锁的语法是 `lock tables … read/write`。与 FTWRL 类似，可以用 `unlock tables` 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，`lock tables` 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

## 2.1 表锁
**表锁是读写锁**。对表加读锁后（`lock table t2 read`），自己也不能对其进行修改，自己和其他线程只能读取该表； 当对某个表执加上写锁后（`lock table t2 write`），该线程可以对这个表进行读写，其他线程对该表的读和写都受到阻塞。

## 2.2 元数据锁
**另一类表级的锁是 MDL（metadata lock)**。**MDL 不需要显式使用，在访问一个表的时候会被自动加上**。MDL 的作用是，保证读写的正确性。
你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。元数据锁是 server 层的表级锁，主要用于隔离 DML 和 DDL 操作之间的干扰。

因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁：
- 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
- 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

### 2.2.1 坑
虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：*给一个小表加个字段，导致整个库挂了*。

**给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据**。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。
而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 `t` 是一个小表。
> 备注：这里的实验环境是 MySQL 5.6。

![[image-43.png]]
我们可以看到 session A 先启动（注意 session A 上的 begin），这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。
如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。因为申请MDL锁的操作会形成一个队列，队列中**写锁获取优先级高于读锁**。一旦出现写锁等待，不但当前操作会被阻塞，同时还会阻塞后续该表的所有操作。更多情况参见：https://blog.csdn.net/q2878948/article/details/96430129
等于这个表现在完全不可读写了。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。

你现在应该知道了，**事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放**。有未提交的事务时无法修改表字段，而且在存在长事务时执行修改表字段命令是一个危险的操作，可能阻塞其它增删改查请求，或导致线程爆满。

### 2.2.2 安全地给小表加字段
**首先我们要解决长事务**，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 `information_schema` 库的 `innodb_trx` 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。

但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？
**比较理想的机制是，在 `alter table` 语句里面设定等待时间**，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。
MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL `NOWAIT/WAIT n` 这个语法：
```sql
ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ... 
```

### 2.2.3 问题：备库备份，主库DDL
当备库用 `–single-transaction` 做逻辑备份的时候，如果从主库的 binlog 传来一个 DDL 语句会怎么样？
假设这个 DDL 是针对表 `t1` 的， 这里我把备份过程中几个关键的语句列出来：
```sql
# 在备份开始的时候，为了确保 RR（可重复读）隔离级别，再设置一次 RR 隔离级别 (Q1);
Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
# 启动事务，这里用 WITH CONSISTENT SNAPSHOT 确保这个语句执行完就可以得到一个一致性视图（Q2)；
Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；
/* other tables */
Q3:SAVEPOINT sp;				# 设置一个保存点，这个很重要（Q3）；
/* 时刻 1 */
Q4:show create table `t1`;		# show create 是为了拿到表结构 (Q4)
/* 时刻 2 */
Q5:SELECT * FROM `t1`;			# 然后正式导数据 （Q5）
/* 时刻 3 */
Q6:ROLLBACK TO SAVEPOINT sp;	# 回滚到 SAVEPOINT sp，在这里的作用是释放 t1 的 MDL 锁 （Q6）。
/* 时刻 4 */
/* other tables */
```

DDL 从主库传过来的时间按照效果不同，我打了四个时刻。题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成。参考答案如下：
1. 如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。
2. 如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止；
3. 如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。
4. 从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构。

# 3 行锁
**MySQL 的行锁是在引擎层由各个引擎自己实现的**。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。
顾名思义，**行锁就是针对数据表中行记录的锁**。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。

## 3.1 从两阶段锁说起
我先给你举个例子。在下面的操作序列中，事务 B 的 `update` 语句执行时会是什么现象呢？假设字段 `id` 是表 `t` 的主键：
![[image-44.png]]
实际上事务 B 的 `update` 语句会被阻塞，直到事务 A 执行 `commit` 之后，事务 B 才能继续执行。**在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议**。

**如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放**。

### 3.1.1 读提交的锁优化
在读提交隔离级别下还有一个优化，即：**语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交**。
例如对非索引字段更新，有个锁全表记录的过程，不符合条件的会及时释放行锁，不必等事务结束时释放。

## 3.2 死锁和死锁检测
### 3.2.1 死锁及解决策略
[[并发#4.1 死锁]]
这里我用数据库中的行锁举个例子：
![[image-45.png]]
这时候，事务 A 在等待事务 B 释放 `id=2` 的行锁，而事务 B 在等待事务 A 释放 `id=1` 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。

当出现死锁以后，有两种策略：
- 一种策略是，**直接进入等待，直到超时**。这个超时时间可以通过参数 `innodb_lock_wait_timeout` 来设置。
- 另一种策略是，**发起死锁检测**，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 `on`，表示开启这个逻辑。需要注意，死锁检测会消耗大量的 CPU 资源。

在 InnoDB 中，`innodb_lock_wait_timeout` 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。
但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。

所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 `innodb_deadlock_detect` 的默认值本身就是 `on`。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。**死锁检测其实就是环的检测，不必每次遍历一遍所有事务，只需要判断事务链表中，每加入一个新事务后是否有环的生成，有就形成死锁**。
例如：新来的线程 A，被锁了后就要检查锁住 A 的线程（假设为 B）是否被锁。如果没有被锁，则没有死锁，如果被锁了，还要查看锁住线程 B 的是谁，如果是 A，那么肯定死锁了，如果不是 A（假设为 C），那么就要继续判断锁住线程 C 的是谁，一直走知道发现线程没有被锁（无死锁）或者被 A 锁住（死锁）才会终止。

### 3.2.2 热点行更新
每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n^2) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。**因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务**。

问题的症结在于，死锁检测要耗费大量的 CPU 资源：
1. **一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉**。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而**关掉死锁检测意味着可能会出现大量的超时，这是业务有损的**。
2. **另一个思路是控制并发度**。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。
3. 因此，**这个并发控制要做在数据库服务端**。如果你有**中间件**，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。**基本思路就是，对于相同行的更新，在进入引擎之前排队**。这样在 InnoDB 内部就不会有大量的死锁检测工作了。
4. 可能你会问，如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？
	**你可以考虑通过将一行改成逻辑上的多行来减少锁冲突**。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。
	这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。

# 4 幻读和间隙锁
## 4.1 幻读
假设有如下表：
```sql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);
```
下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？
```sql
begin;
select * from t where d=5 for update;
commit;
```
比较好理解的是，这个语句会命中 `d=5` 的这一行，对应的主键 `id=5`，因此在 `select` 语句执行完成后，`id=5` 这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 `commit` 语句的时候释放。
由于字段 `d` 上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的 5 行记录上，会不会被加锁呢？
InnoDB 的默认事务隔离级别是可重复读，所以本文接下来没有特殊说明的部分，都是设定在可重复读隔离级别下。

我们就来分析一下，如果只在 `id=5` 这一行加锁，而其他行的不加锁的话，会怎么样。下面先来看一下这个场景：
![[image-63.png]]
可以看到，Q2的读取出现了不可重复读问题，Q3的读取出现了幻读的问题。
当前读的规则，就是要能读到所有已经提交的记录的最新值，这跟事务的可见性规则并不矛盾。但是，这是不是真的没问题呢？不，这里还真就有问题。

## 4.2 幻读有什么问题？
### 4.2.1 首先是语义上的
session A 在 T1 时刻就声明了，“我要把所有 `d=5` 的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。如果现在这样看感觉还不明显的话，我再往 session B 和 session C 里面分别加一条 SQL 语句，你再看看会出现什么现象。
![[image-64.png]]
session B 的第二条语句 `update t set c=5 where id=0`，语义是“我把 `id=0`、`d=5` 这一行的 `c` 值，改成了 5”。
由于在 T1 时刻，session A 还只是给 `id=5` 这一行加了行锁， 并没有给 `id=0` 这行加上锁。因此，session B 在 T2 时刻，是可以执行这两条 `update` 语句的。这样，就破坏了 session A 里 Q1 语句要锁住所有 `d=5` 的行的加锁声明。
session C 也是一样的道理，对 `id=1` 这一行的修改，也是破坏了 Q1 的加锁声明。

### 4.2.2 其次是数据一致性的问题
锁的设计是为了保证数据的一致性。而**这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性**。为了说明这个问题，我给 session A 在 T1 时刻再加一个更新语句，即：`update t set d=100 where d=5`。
![[image-65.png]]

现在，我们来分析一下图 3 执行完成后，数据库里会是什么结果。
1. 经过 T1 时刻，`id=5` 这一行变成 (5,5,100)，当然这个结果最终是在 T6 时刻正式提交的 ;
2. 经过 T2 时刻，`id=0` 这一行变成 (0,5,5);
3. 经过 T4 时刻，表里面多了一行 (1,5,5);
4. 其他行跟这个执行序列无关，保持不变。

这样看，这些数据也没啥问题，但是我们再来看看这时候 binlog 里面的内容。
1. T2 时刻，session B 事务提交，写入了两条语句；
2. T4 时刻，session C 事务提交，写入了两条语句；
3. T6 时刻，session A 事务提交，写入了 `update t set d=100 where d=5` 这条语句。
我统一放到一起的话，就是这样的：
```sql
update t set d=5 where id=0; /*(0,0,5)*/
update t set c=5 where id=0; /*(0,5,5)*/

insert into t values(1,1,5); /*(1,1,5)*/
update t set c=5 where id=1; /*(1,5,5)*/

update t set d=100 where d=5;/*所有d=5的行，d改成100*/
```
好，你应该看出问题了。这个语句序列，不论是拿到备库去执行，还是以后用 binlog 来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100) 和 (5,5,100)。

**这个数据不一致到底是怎么引入的**？我们分析一下可以知道，这是我们假设 `select * from t where d=5 for update` 这条语句只给 `d=5` 这一行，也就是 `id=5` 的这一行加锁”导致的。所以我们认为，上面的设定不合理，要改。那怎么改呢？**我们把扫描过程中碰到的行，也都加上写锁，再来看看执行效果。**
![[image-66.png]]
在 binlog 里面，执行序列是这样的：
```sql
insert into t values(1,1,5); /*(1,1,5)*/
update t set c=5 where id=1; /*(1,5,5)*/

update t set d=100 where d=5;/*所有d=5的行，d改成100*/

update t set d=5 where id=0; /*(0,0,5)*/
update t set c=5 where id=0; /*(0,5,5)*/
```
`id=0` 这一行的问题解决了。但同时你也可以看到，`id=1` 这一行，在数据库里面的结果是 (1,5,5)，而根据 binlog 的执行结果是 (1,5,100)，也就是说幻读的问题还是没有解决。
原因很简单。在 T3 时刻，我们给所有行加锁的时候，`id=1` 这一行还不存在，不存在也就加不上锁。也就是说，**即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因**。

## 4.3 如何解决幻读？
### 4.3.1 间隙锁
现在你知道了，**产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”**。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是**间隙锁 (Gap Lock)**。
顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 `t`，初始化插入了 6 个记录，这就产生了 7 个间隙。
![[image-67.png]]
当你执行 `select * from t where d=5 for update` 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。

间隙锁跟我们之前碰到过的锁都不太一样。**跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系**。例如：
![[image-68.png]]
这里 session B 并不会被堵住。因为表 t 里并没有 `c=7` 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。但如果 `c=5`，也就是有值的话，会存在行锁，行锁直接是读写是互相排斥的。

**间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间**。也就是说，我们的表 `t` 初始化以后，如果用 `select * from t for update` 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。
备注：这篇文章中，如果没有特别说明，我们把间隙锁记为开区间，把 next-key lock 记为前开后闭区间。
你可能会问说，这个 supremum 从哪儿来的呢？这是因为 +∞ 是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 supremum，这样才符合我们前面说的“都是前开后闭区间”。

### 4.3.2 间隙锁的问题
**间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”**。例如：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：
```sql
begin;
select * from t where id=N for update;

/*如果行不存在*/
insert into t values(N,N,N);
/*如果行存在*/
update t set d=N set id=N;

commit;
```
可能你会说，这个不是 `insert … on duplicate key update` 就能解决吗？但其实在有多个唯一键的时候，这个方法是不能满足这位提问同学的需求的。至于为什么，我会在后面的文章中再展开说明。

这个同学碰到的现象是，这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每次操作前用 `for update` 锁起来，已经是最严格的模式了，怎么还会有死锁呢？这里，我用两个 session 来模拟并发，并假设 N=9。
![[image-69.png]]
其实都不需要用到后面的 `update` 语句，就已经形成死锁了。我们按语句执行顺序来分析一下：
1. session A 执行 `select … for update` 语句，由于 `id=9` 这一行并不存在，因此会加上间隙锁 (5,10);
2. session B 执行 `select … for update` 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；
3. session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；
4. session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。
至此，两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 `insert` 语句报错返回了。你现在知道了，**间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的**。

### 4.3.3 最终解决方法
间隙锁是在可重复读隔离级别下才会生效的。所以，**你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row**。这，也是现在不少公司使用的配置组合。
比方说，删除 statement 格式记录的是这个删除的语句，例如： `delete from t where age>10 and modified_time<='2020-03-04' limit 1`。而 row 格式记录的是实际受影响的数据是真实删除行的主键`id`，例如： `delete from t where id=3 and age=12 and modified_time='2020-03-05'`。**row 格式精确到具体被影响的行，而 statement 格式影响的可能是一个范围。**

**在READ COMMITTED级别下，MySQL在某些特殊情况下仍可能使用间隙锁**：
- 外键约束检查时
- 唯一性约束检查时（duplicate-key检查）

如果读提交隔离级别够用，也就是说，业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。如果是需要可重复读来保证的业务场景，例如逻辑备份，就需要可重复读。

### 4.3.4 幻读被完全解决了吗？
**可重复读隔离级别下虽然很大程度上避免了幻读，但是还是没有能完全解决幻读**。
以这张表作为例子：
![[image-72.png|364x184]]
事务执行次序：
![[image-73.png]]
因为这种特殊现象的存在，所以我们认为 **MySQL Innodb 中的 MVCC 并不能完全避免幻读现象**。

## 4.4 间隙锁详解
**我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”**。
1. 原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。
2. 原则 2：查找过程中访问到的索引才会加锁。
3. 优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
4. 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。
5. 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

我还是以之前表 `t` 为例（[[#4.1 幻读]]），和你解释一下这些规则。

### 4.4.1 案例一：等值查询间隙锁
第一个例子是关于等值条件操作间隙：
![[image-70.png]]
由于表 `t` 中没有 `id=7` 的记录，所以用我们上面提到的加锁规则判断一下的话：
1. 根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；
2. 同时根据优化 2，这是一个等值查询 (`id=7`)，而 `id=10` 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。
所以，session B 要往这个间隙里面插入 `id=8` 的记录会被锁住，但是 session C 修改 `id=10` 这行是可以的。

### 4.4.2 案例二：非唯一索引等值锁
第二个例子是关于覆盖索引上的锁：
![[image-71.png]]
这里 session A 要给索引 `c` 上 `c=5` 的这一行加上读锁。
1. 根据原则 1，加锁单位是 next-key lock，因此会给 (0,5] 加上 next-key lock。
2. 要注意 c 是普通索引，因此仅访问 `c=5` 这一条记录是不能马上停下来的，需要向右遍历，查到 `c=10` 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10] 加 next-key lock。
3. 但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 `c=5` 这个等值条件，因此退化成间隙锁 (5,10)。
4. 根据原则 2 ，**只有访问到的对象才会加锁**，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 `update` 语句可以执行完成。

需要注意，在这个例子中，lock in share mode 只锁覆盖索引，但是如果是 `for update` 就不一样了。 执行 `for update` 时，系统会认为你接下来要更新数据，则会回表查询，访问到主键索引，因此会顺便给主键索引上满足条件的行加上**行锁**（注意是行锁而不是 next-key 锁）。

### 4.4.3 案例三：唯一索引范围锁和等值锁
举例之前，你可以先思考一下这个问题：对于我们这个表 `t`，下面这两条查询语句，加锁范围相同吗？
```sql
mysql> select * from t where id=10 for update;
mysql> select * from t where id>=10 and id<11 for update;
```
在逻辑上，这两条查语句肯定是等价的，但是它们的加锁规则不太一样。现在，我们就让 session A 执行第二个查询语句，来看看加锁效果：
![[image-74.png]]
1. 开始执行的时候，要找到第一个 `id=10` 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 `id` 上的等值条件，退化成行锁，只加了 `id=10` 这一行的行锁。
2. 范围查找就往后继续找，找到 `id=15` 这一行停下来，根据 bug，因此需要加 next-key lock(10,15]（注意，MySQL 8.0.18 及之后的版本修复了这个 bug，会退化成间隙锁 (10, 15)）。

### 4.4.4 案例四：非唯一索引范围锁
接下来，我们再看两个范围查询加锁的例子，你可以对照着案例三来看。需要注意的是，与案例三不同的是，案例四中查询语句的 `where` 部分用的是字段 `c`。
![[image-75.png]]
加锁规则跟案例三唯一的不同是：在第一次用 `c=10` 定位记录的时候，索引 c 上加了 (5,10] 这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。
注意只有第一次 c=10 定位的时候是等值查询，后面是范围查询，所以 (10,15] 不会退化成间隙锁（先只能这么理解，后面再做测试 [[TODO]]）。

### 4.4.5 案例五：非唯一索引间隙锁还需要考虑主键的排序
假如开启了下面的事务：
```sql
begin;
delete from t where c=10;
```
如果session b插入(4,5,50)，不会被锁，如果插入（6,5,50） 会被锁住。因为6,5,50根据主键来排的话，是在5,5,10后面的，在间隙锁范围内。

### 4.4.6 案例六：limit 语句加锁
先插入一条数据：
```sql
mysql> insert into t values(30,10,30);
```

场景如下所示：
![[image-76.png]]
你知道表 `t` 里 `c=10` 的记录其实只有两条，因此加不加 `limit 2`，删除的效果都是一样的，但是加锁的效果却不同。可以看到，session B 的 `insert` 语句执行通过了。
索引 `c` 上的加锁范围就变成了从 `(c=5,id=5)` 到 `(c=10,id=30)` 这个前开后闭区间，如下图所示：
![[image-77.png]]
这个例子对我们实践的指导意义就是，**在删除数据的时候尽量加 `limit`**。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。

### 4.4.7 案例七：间隙锁和行锁是分开加的
最后我们再看一个案例，目的是说明：next-key lock 实际上是间隙锁和行锁加起来的结果。
![[image-78.png]]
我们按时间顺序来分析一下为什么是这样的结果。
1. session A 启动事务后执行查询语句加 `lock in share mode`，在索引 `c` 上加了 next-key lock(5,10] 和间隙锁 (10,15)；
2. session B 的 `update` 语句也要在索引 `c` 上加 next-key lock(5,10] ，进入锁等待；
3. 然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。
session B 的“加 next-key lock(5,10] ”操作，实际上分成了两步，先是加 (5,10) 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。

也就是说，**我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的**。

### 4.4.8 案例八：倒序时的间隙锁
下图的语句序列中，为什么 session B 的 insert 操作，会被锁住呢？
![[image-79.png]]
1. 由于是 order by c desc，第一个要定位的是索引 c 上“最右边的”c=20 的行，所以会加上间隙锁 (20,25) 和 next-key lock (15,20]。
2. 在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock 会加到 (5,10]，这正是阻塞 session B 的 insert 语句的原因。
3. 在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select \*，所以会在主键 id 上加三个行锁。

### 4.4.9 案例九：不等号范围查询中的等值查询
等值查询和“遍历”有什么区别？为什么我们文章的例子里面，`where` 条件是不等号，这个过程里也有等值查询？我们一起来看下这个例子，分析一下这条查询语句的加锁范围：
```sql
begin;
select * from t where id>9 and id<12 order by id desc for update;
```
这个语句的加锁范围是主键索引上的 (0,5]、(5,10]和 (10, 15)。也就是说，id=15 这一行，并没有被加上行锁。为什么呢？
我们说加锁单位是 next-key lock，都是前开后闭区间，但是这里用到了优化 2，即索引上的等值查询，向右遍历的时候 id=15 不满足条件，所以 next-key lock 退化为了间隙锁 (10, 15)。

但是，我们的查询语句中 `where` 条件是大于号和小于号，这里的“等值查询”又是从哪里来的呢？要知道，加锁动作是发生在语句执行过程中的，所以你在分析加锁行为的时候，要从索引上的数据结构开始。
这里，我再把这个过程拆解一下。如图 1 所示，是这个表的索引 id 的示意图。
![[image-104.png]]
1. 首先这个查询语句的语义是 `order by id desc`，要拿到满足条件的所有行，优化器必须先找到“第一个 `id<12` 的值”。
2. 这个过程是通过索引树的搜索过程得到的，在引擎内部，其实是要找到 `id=12` 的这个值，只是最终没找到，但找到了 (10,15) 这个间隙。
3. 然后向左遍历，在遍历过程中，就不是等值查询了，会扫描到 `id=5` 这一行，所以会加一个 next-key lock (0,5]。

也就是说，**在执行过程中，通过树搜索的方式定位记录的时候，用的是“等值查询”的方法**。

### 4.4.10 案例十：in 的加锁
下面这个语句的加锁范围是什么？
```sql
begin;
select id from t where c in(5,20,10) lock in share mode;
```
在查找 c=5 的时候，先锁住了 (0,5]。但是因为 c 不是唯一索引，为了确认还有没有别的记录 c=5，就要向右遍历，找到 c=10 才确认没有了，这个过程满足优化 2，所以加了间隙锁 (5,10)。
同样的，执行 c=10 这个逻辑的时候，加锁的范围是 (5,10] 和 (10,15)；执行 c=20 这个逻辑的时候，加锁的范围是 (15,20] 和 (20,25)。

你可能会说，这个加锁范围，不就是从 (5,25) 中去掉 c=15 的行锁吗？为什么这么麻烦地分段说呢？因为我要跟你强调这个过程：**这些锁是“在执行过程中一个一个加的”，而不是一次性加上去的**。
理解了这个加锁过程之后，我们就可以来分析下面例子中的死锁问题了。如果同时有另外一个语句，是这么写的：
```sql
select id from t where c in(5,20,10) order by c desc for update;
```
我们现在都知道间隙锁是不互锁的，但是这两条语句都会在索引 c 上的 c=5、10、20 这三行记录上加记录锁。
这里你需要注意一下，由于语句里面是 `order by c desc`， 这三个记录锁的加锁顺序，是先锁 c=20，然后 c=10，最后是 c=5。也就是说，这两条语句要加锁相同的资源，但是加锁顺序相反。当这两条语句并发执行的时候，就可能出现死锁。

### 4.4.11 怎么看死锁？
图 3 是在出现死锁后，执行 `show engine innodb status` 命令得到的部分输出。这个命令会输出很多信息，有一节 `LATESTDETECTED DEADLOCK`，就是记录的最后一次死锁信息：
![[image-105.png]]
我们来看看这图中的几个关键信息。
1. 这个结果分成三部分：
    1. `(1) TRANSACTION`，是第一个事务的信息；
    2. `(2) TRANSACTION`，是第二个事务的信息；
    3. `WE ROLL BACK TRANSACTION (1)`，是最终的处理结果，表示回滚了第一个事务。
2. 第一个事务的信息中：
    1. `WAITING FOR THIS LOCK TO BE GRANTED`，表示的是这个事务在等待的锁信息；
    2. `index c of table test.t`，说明在等的是表 t 的索引 c 上面的锁；
    3. `lock mode S waiting` 表示这个语句要自己加一个读锁，当前的状态是等待中；
    4. `Record lock` 说明这是一个记录锁；
    5. `n_fields 2` 表示这个记录是两列，也就是字段 c 和主键字段 id；
    6. `0: len 4; hex 0000000a; asc ;;` 是第一个字段，也就是 c。值是十六进制 a，也就是 10；
    7. `1: len 4; hex 0000000a; asc ;;` 是第二个字段，也就是主键 id，值也是 10；
    8. 这两行里面的 `asc` 表示的是，接下来要打印出值里面的“可打印字符”，但 10 不是可打印字符，因此就显示空格。
    9. 第一个事务信息就只显示出了等锁的状态，在等待 `(c=10,id=10)` 这一行的锁。
    10. 当然你是知道的，既然出现死锁了，就表示这个事务也占有别的锁，但是没有显示出来。别着急，我们从第二个事务的信息中推导出来。
3. 第二个事务显示的信息要多一些：
    1. `HOLDS THE LOCK(S)` 用来显示这个事务持有哪些锁；
    2. `index c of table test.t` 表示锁是在表 t 的索引 c 上；
    3. `hex 0000000a` 和 `hex 00000014` 表示这个事务持有 c=10 和 c=20 这两个记录锁；
    4. `WAITING FOR THIS LOCK TO BE GRANTED`，表示在等 `(c=5,id=5)` 这个记录锁。

从上面这些信息中，我们就知道：
1. “lock in share mode”的这条语句，持有 c=5 的记录锁，在等 c=10 的锁；
2. “for update”这个语句，持有 c=20 和 c=10 的记录锁，在等 c=5 的记录锁。
3. 在发生死锁的时刻，`for update` 这条语句占有的资源更多，回滚成本更大，所以 InnoDB 选择了回滚成本更小的 `lock in share mode` 语句，来回滚。

### 4.4.12 怎么看锁等待
看完死锁，我们再来看一个锁等待的例子：
![[image-106.png]]
可以看到，由于 session A 并没有锁住 c=10 这个记录，所以 session B 删除 id=10 这一行是可以的。但是之后，session B 再想 insert id=10 这一行回去就不行了。

现在我们一起看一下此时 `show engine innodb status` 的结果，看看能不能给我们一些提示。锁信息是在这个命令输出结果的 `TRANSACTIONS` 这一节：
![[image-107.png]]
我们来看几个关键信息。
1. `index PRIMARY of table test.t` ，表示这个语句被锁住是因为表 t 主键上的某个锁。
2. `lock_mode X locks gap before rec insert intention waiting` 这里有几个信息：
    - `insert intention` 表示当前线程准备插入一个记录，这是一个插入意向锁。为了便于理解，你可以认为它就是这个插入动作本身。
    - `gap before rec` 表示这是一个间隙锁，而不是记录锁。
3. 那么这个 gap 是在哪个记录之前的呢？接下来的 0~4 这 5 行的内容就是这个记录的信息。
4. `n_fields 5` 也表示了，这一个记录有 5 列：
    - `0: len 4; hex 0000000f; asc ;;` 第一列是主键 id 字段，十六进制 f 就是 id=15。所以，这时我们就知道了，这个间隙就是 id=15 之前的，因为 id=10 已经不存在了，它表示的就是 (5,15)。
    - `1: len 6; hex 000000000513; asc ;;` 第二列是长度为 6 字节的事务 id，表示最后修改这一行的是 trx id 为 1299 的事务。
    - `2: len 7; hex b0000001250134; asc % 4;;` 第三列长度为 7 字节的回滚段信息。可以看到，这里的 acs 后面有显示内容 (% 和 4)，这是因为刚好这个字节是可打印字符。
    - 后面两列是 c 和 d 的值，都是 15。
因此，我们就知道了，由于 `delete` 操作把 id=10 这一行删掉了，间隙锁由 (10,15）变成了 (5,15)。
**所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的**。

### 4.4.13 update 的例子
[[TODO]]

# 5 意向锁
意向锁（Intention Lock）是 MySQL InnoDB 存储引擎中的 **表级锁**，核心作用是 **提高 “表锁与行锁” 之间的冲突检查效率**，避免全表扫描判断行锁存在性。它本身不直接阻塞行级操作，仅用于 “声明意图”，让后续表级锁请求快速判断是否存在冲突。
如果没有意向锁，表锁事务要遍历表中所有行，检查是否存在行锁—— 这在大表中是灾难级的效率问题。
意向锁的解决方案是：**在加行锁前，先给表加 “意向锁”，声明 “我要对表中的某行加锁”**。后续表级锁请求只需检查 “表上是否有意向锁”，无需遍历行，直接判断冲突，效率极大提升。

意向锁的类型：

| 意向锁类型 | 英文缩写 | 声明意图                       | 触发场景（InnoDB 自动执行）                                               |
| ----- | ---- | -------------------------- | --------------------------------------------------------------- |
| 意向共享锁 | IS 锁 | 我即将对表中的某一行加 **行级共享锁（S 锁）** | `SELECT ... FOR SHARE`                                          |
| 意向排他锁 | IX 锁 | 我即将对表中的某一行加 **行级排他锁（X 锁）** | 执行行级写操作（如 `UPDATE`、`DELETE`、`INSERT`，或 `SELECT ... FOR UPDATE`） |

通俗解读冲突规则：
- 表级读锁（S 锁）：允许其他事务加 IS 锁（因为 IS 锁对应行级读，不冲突），但不允许加 IX 锁（对应行级写，冲突）；
- 表级写锁（X 锁）：不允许任何意向锁（IS/IX），因为写表需要独占全表；
- 意向锁之间（IS 与 IX、IS 与 IS、IX 与 IX）：完全兼容，因为它们只是 “声明意图”，实际行锁的冲突由行锁本身控制。

# 6 悲观锁和乐观锁
## 6.1 悲观锁：行级排他锁
- **原理**：通过`SELECT ... FOR UPDATE`语句锁定主单记录，同一时刻只有一个事务能获取该记录的锁，其他事务需等待锁释放后才能操作，从而实现串行化处理。
- **适用场景**：主单数据存储在支持行级锁的数据库（如 InnoDB 引擎的 MySQL），且主单 ID（`main_order_id`）是主键或有唯一索引（确保锁能精准定位到单行）。
- **非阻塞悲观锁**：主流数据库（如 MySQL、PostgreSQL）支持**带超时的行级锁**或**非阻塞锁定语法**，允许线程尝试获取锁时，若无法立即获取则直接返回失败，而非阻塞等待。可通过`SELECT ... FOR UPDATE SKIP LOCKED`（MySQL 8.0+）或Oracle`SELECT ... FOR UPDATE NOWAIT`实现非阻塞锁定
- **性能**：锁范围精准（行级），但长事务会阻塞，适用于短事务。
	- 而Redis 分布式锁则更适合高并发场景、跨服务场景，也不会造成长事务，数据库又好。但是依赖 Redis，且需要处理锁超时、误删等问题

## 6.2 乐观锁
- **原理**：不主动加锁，而是通过版本号（`version`字段）控制并发。每次更新时检查版本号是否匹配，匹配则更新并递增版本号，不匹配则说明有并发修改，需重试。
- **注意**：**乐观锁的 “版本号更新成功” 并不等同于 “获取锁”，后续还需再次校验状态**。乐观锁的正确用法需要配合 **“操作前再次校验状态”**，确保当前处理的前提条件仍成立。
- **适用场景**：并发冲突频率较低的场景（避免频繁重试），或不希望长时间持有锁阻塞其他操作的场景。

# 7 总结
- 全局锁：`Flush tables with read lock`，给整库加读锁，会阻塞DML、DDL。使用 `unlock tables` 命令可以解除。
	- 使用 `mysqldump –single-transaction` 命令给数据库做备份，它通过MVVC一致性视图避免其他事务的干扰，也不会阻塞其他事务。比用全局锁做备份要好
- 表锁
	- 显示地加表锁：有读锁（`lock table t2 read`）、写锁（`lock table t2 write`）
	- 元数据锁 MDL（metadata lock)：DML会加MDL读锁，DDL会加 MDL 写锁。因此DDL会阻塞数据库正常事务
		- 在 `alter table` 语句里面设定等待时间：`NOWAIT/WAIT n`。
		- **TODO**：DDL阻塞问题参见：https://blog.csdn.net/q2878948/article/details/96430129
	- 备库备份，主库DDL：
		- 如果DDL是在备份前、备份完成后提交，那么没任何问题
		- 如果DDL是在备库拿到表结构后，读取数据前到了，那么备份会报错
		- 如果DDL是在读取数据中到了，那么mysqldump会占着表的 MDL 读锁，binlog中的DDL会被阻塞，导致主从延迟
- 

---
# 8 引用
2025-12-06 17:23
Status: #idea
Tags:

# 1 Hive
## 1.1 hive SQL 和 mysql 有什么区别？它比mysql有什么优势？
sql 层面的不同：
- MySQL：支持标准 SQL，侧重事务型功能（索引、存储过程、触发器），靠索引提升单条记录查询效率。
- Hive：HiveSQL 是类 SQL，扩展了大数据适配功能（比如自定义函数 UDF）。
	- hive sql很适合做覆写一个表的整个分区或追加操作，但是像mysql那样修改某一条记录则很低效。
	- 但是它能处理多表关联、复杂聚合这类 MySQL 扛不住的计算。

hive难以细粒度的修改数据，不是它的缺陷，而是它和mysql的应用场景不同。

核心定位与场景（最根本）：
- MySQL 是**联机事务处理（OLTP）** 数据库，它面向实时处理场景
- Hive不是数据库，而是**基于 Hadoop 的 SQL 解析引擎和定义数据的存储格式**，属于联机分析处理（OLAP）。面向大数据离线分析场景，适合低频次、TB/PB 级海量数据的批量分析和计算
	- **离线分析场景本就不需要频繁改单条数据**。

底层存储与计算（差异的根源）：
- MySQL：**数据存在本地文件系统** / 共享存储（如 SAN），**计算依赖单机** / 小集群，能力受单节点 CPU / 内存限制；用 InnoDB 等引擎做**行式存储**，行式存储适合随机读写单条记录，所以能支持细粒度更新。
- Hive：本身不存数据，数据全靠 **HDFS（Hadoop 分布式文件系统）** 存储 ——HDFS 是分布式、高容错的，能**横向扩容到成百上千节点，天生适配海量数据**。计算则把 Hive SQL 翻译成 Spark/MapReduce 分布式任务，分散到集群节点并行执行。Hive 默认用 ORC/Parquet **列式存储**，只读取分析需要的列（比如算成本只读价格、数量列，不用读全表），批量分析效率远高于行式存储。

数据操作与事务：
- MySQL：支持细粒度增删改查、完整 ACID 事务、行锁 / 表锁，这是为了满足交易场景的一致性（比如改一笔订单的价格）。
- Hive：早期不支持细粒度更新和事务，不是 “缺陷”，而是**适配 HDFS 特性** ——HDFS 文件写入后难以修改（追加可行，修改成本极高），所以核心操作是 “覆盖 / 追加分区”（比如按日期分区计算每日成本，直接写入当天分区）。
	- Hive 3.0 后虽支持 ACID，但仅用于缓慢变化维度等小众场景，并非核心设计目标，因为**离线分析场景本就不需要频繁改单条数据**（成本算价只需要批量计算全量数据，不需要改某一条物料的价格）。

扩展性与性能：
- MySQL：垂直扩展为主（升级服务器配置），水平扩展（分库分表）复杂度高，能处理 GB 级数据，毫秒级响应。
- Hive：水平扩展简单（加集群节点即可），能线性提升存储 / 计算能力，处理 TB/PB 级数据，高吞吐但延迟高（符合离线分析的节奏）。

## 1.2 Hive的底层结构是什么呢？
### 1.2.1 Hive 的存储底层：先明确 “Hive 不存数据，只映射数据”
Hive 本身不是数据库，没有自己的存储引擎 —— 它的 “存储” 分为两层：
1. **元数据层**：表结构、分区信息、数据存储路径、文件格式等（存在 Metastore，通常用 MySQL 托管）；
2. **实际数据层**：所有数据都以文件形式存在 HDFS 上（分布式存储，数据分散在集群多个节点），Hive 只是通过 SQL 解析，映射到 HDFS 的文件。

而 Hive 的核心优化，就体现在 “HDFS 上的文件格式”—— 日常用的 ORC/Parquet 是**列式存储**，这是和 MySQL 行式存储的核心差异，也是 Hive 能高效处理批量分析的关键。

### 1.2.2 核心重点：Hive 列式存储（ORC/Parquet）的底层工作机制
#### 1.2.2.1 列式存储的 “数据组织方式”（核心：按列分块，而非按行）
假设成本算价表有 4 列：`order_id（订单ID）、price（单价）、quantity（数量）、date（日期）`，共 100 万行数据：
- **MySQL 行式存储**：把每一行的所有字段存在一起（比如一行是「1001, 50.0, 2, 20251001」），100 万行就是 100 万个 “行数据块”，读的时候要么读整行，要么通过 B + 树找某一行；
- **Hive ORC 列式存储**：（Parquet 逻辑类似，只是分块 / 压缩细节不同）把所有列的数据单独聚合，拆成 “列块 + 元数据” 的分层结构，最终存在 HDFS 的一个 / 多个ORC文件里，每个ORC文件包含一些行，它的结构如下（从大到小）：
	- 文件头（File Header）：存列数、压缩方式、文件创建时间等全局元数据
	- 多个Stripe（数据块，默认250MB/个）：ORC的核心数据单元，每个Stripe又分别包含ORC的一些行。Stripe里面对每列分别作为列块存储，列块内部会做 “编码 + 压缩”。分布式计算按Stripe并行处理。
		- Index Data（列索引）：每列的轻量索引，存该 Stripe 内每列的 min/max、取值范围
		- Row Data（行数据）：按列存储的实际数据（所有order_id放一个块，所有price放一个块，以此类推）
		- Stripe Footer：存该Stripe的列偏移量、统计信息等
	- 文件尾（File Footer）：存文件内所有列的统计信息（比如`payer_id`的 min/max、`goods`的取值范围、null 数等）、数据偏移量等

所以说是叫列式存储，其实是先按行划分文件，文件内部再按行划分Stripe，Stripe内部最后按列划分。

注意，列式存储不是 “把列完全孤立存储”，ORC 文件的每个 Stripe 内会存储 N 行数据（比如 100 万行），这些行在 Stripe 内有**连续的行号（0、1、2...999999）** —— 每一列的列块数据，都是按这个行号顺序存储的。因此，通过行号能把不同的列关联起来。
ORC/Parquet 会在 Stripe 的「Index Data」里记录「行号→列数据偏移量」的映射关系，哪怕列数据做了压缩 / 编码，读取时也能通过偏移量快速定位到同一行的列值，不会错位。

#### 1.2.2.2 为什么列式存储批量分析更快？
比如：`select sum (price*quantity) from order where date='20251001' and payer_id=200003 and goods='ECS'`。
Hive读流程：
1. **元数据查询**：Hive 先查 Metastore，拿到表的存储路径（HDFS 路径）、文件格式（ORC）、分区信息（比如按 date 分区）；
2. **谓词下推**（核心优化）：
	1. **分区级下推**：最粗粒度，直接排除 99% 无效数据
	2. **ORC 文件级下推**（过滤整个无效文件）：分区下会有多个 ORC 文件，Hive 不会直接读文件内容，而是先读每个 ORC 文件的「文件尾（File Footer）」—— 这里存了该文件所有列的全局统计信息（比如`payer_id`的 min/max、`goods`的取值范围、null 数等）：
		- 比如某 ORC 文件的`payer_id`全局统计是`min=200000，max=200002`，而你要的是`payer_id=200003` → 直接跳过这个文件，不用读里面任何数据；
		- 再比如某文件的`goods`全局统计只有`RDS、SLB、OSS`，没有`ECS` → 也直接跳过这个文件；
		- 只有文件尾的统计显示：`payer_id`包含 200003、`goods`包含 ECS → 才会处理这个文件。
	3. **Stripe 级下推**（过滤无效数据块）：每个 Stripe 都有「Index Data（列索引）」—— 存该 Stripe 内每列的 min/max、取值范围：
		- 比如某 Stripe 的`payer_id`索引是`min=200003，max=200003`，但`goods`索引只有`RDS` → 跳过这个 Stripe；
		- 再比如某 Stripe 的`payer_id=200003`且`goods=ECS` → 才会读取这个 Stripe 的实际数据；
		- 这一步又过滤掉了文件内的无效数据块，只留下需要处理的 Stripe。
	4. **行级下推**（最终过滤）：读取符合条件的 Stripe 后，Hive 会在列数据块内对每行做最终过滤：
		- 比如某行的`payer_id=200003`但`goods='RDS'` → 直接过滤掉这一行，不读取它的`price/quantity`；
		- 只有同时满足`payer_id=200003`且`goods='ECS'`的行 → 才会读取对应的`price`和`quantity`。
3. **列裁剪**（核心优化）：只读取需要的列；
4. **分布式读取**：HDFS 把不同 Stripe 分布在集群不同节点，Spark/Hive 同时读取多个 Stripe 的 price/quantity 列块，解压后计算 sum (price\*quantity)。

如果用 MySQL 做这个计算，需要：
1. 遍历 B + 树找到所有 202510 的行（随机 IO，慢）；
2. 每找到一行，必须读取整行数据（包括 order_id 等无关列，IO 浪费）；
3. 单节点计算（无法分布式），100 万行可能还能撑，1 亿行直接卡死。

---
# 2 引用
2025-10-28 11:08
Status: #idea
Tags: [[分布式]]

# 1 分布式事务总览
![[image-157.png]]

## 1.1 名词解释
1. 事务：事务是由一组操作构成的可靠的独立的工作单元，事务具备ACID的特性，即原子性、一致性、隔离性和持久性。
2. 本地事务：当事务由资源管理器本地管理时被称作本地事务。本地事务的优点就是支持严格的ACID特性。
3. 全局事务：当事务由全局事务管理器进行全局管理时成为全局事务，事务管理器负责管理全局的事务状态和参与的资源，协同资源的一致提交回滚。
4. TX协议：应用与事务管理器的接口。
5. XA协议：全局事务管理器与资源管理器的接口。XA是由X/Open组织提出的分布式事务规范。该规范主要定义了全局事务管理器和局部资源管理器之间的接口。主流的数据库产品都实现了XA接口。
6. AP：应用程序。
7. RM：资源管理器，这里可以是一个DBMS或者消息服务器管理系统，必须实现XA定义的接口。资源管理器负责控制和管理实际的资源。
8. TM：事务管理器，负责协调和管理事务，提供给AP编程接口以及管理资源管理器。事务管理器控制着全局事务，管理事务的生命周期，并且协调资源。

## 1.2 分布式事务与分布式锁的区别
**分布式锁解决的是分布式资源抢占的问题；分布式事务是解决流程化提交问题**。

# 2 分布式事务的基本概念
## 2.1 什么是分布式事务？
简单的说，**在分布式系统上一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务节点上，分布式事务需要保证这些小操作要么全部成功，要么全部失败**。
举个例子：在电商网站中，用户对商品进行下单，需要在订单系统中创建一条订单数据，同时需要在库存系统中修改当前商品的剩余库存数量，我们一定要保证这两步操作一定同时操作成功或失败，否则业务就会出现问题。

#### 2.1.1.1 跨库事务
跨库事务指的是，一个应用某个功能需要操作多个库，不同的库中存储不同的业务数据。笔者见过一个相对比较复杂的业务，一个业务中同时操作了9个库。

#### 2.1.1.2 分库分表
通常一个库数据量比较大或者预期未来的数据量比较大，都会进行水平拆分，也就是分库分表。如下图，将数据库B拆分成了2个库：
![[image-158.png]]
对于分库分表的情况，一般开发人员都会使用一些数据库中间件来降低 sql 操作的复杂性。
如，对于 `insert into user(id,name) values (1,"tianshouzhi"),(2,"wangxiaoxiao")`。这条 sql 是操作单库的语法，单库情况下，可以保证事务的一致性。
但是由于现在进行了分库分表，开发人员希望将1号记录插入分库1，2号记录插入分库2。所以数据库中间件要将其改写为2条sql，分别插入两个不同的分库，此时要保证两个库要不都成功，要不都失败，因此**基本上所有的数据库中间件都面临着分布式事务的问题**。

#### 2.1.1.3 微服务化
下图演示了一个3个服务之间彼此调用的架构：
![[image-159.png]]

## 2.2 分布式事务分类：柔性事务和刚性事务
分布式一致性问题的解决思路有两种，**一种是分布式事务，一种是尽量通过业务流程避免分布式事务**。分布式事务是直接解决问题，而业务规避其实通过解决出问题的地方(解决提问题的人)。
其实在真实业务场景中，如果业务规避不是很麻烦，最优雅的解决方案就是业务规避。

分布式事务实现方案从类型上去分刚性事务、柔型事务：
- 刚性事务满足CAP的CP理论
- 柔性事务满足BASE理论（基本可用，最终一致）

### 2.2.1 刚性事务
刚性事务：通常无业务改造，强一致性，原生支持回滚/隔离性；低并发，适合短事务。刚性事务满足CAP的CP理论。
由于同步阻塞，处理效率低，不适合大型网站分布式场景。

刚性事务：XA 协议（2PC、JTA、JTS）、3PC。
### 2.2.2 柔性事务
柔性事务指的是，不要求强一致性，而是要求最终一致性，允许有中间状态，也就是Base理论，换句话说，就是AP状态。
与刚性事务相比，柔性事务的特点为：有业务改造，最终一致性；高并发，适合长事务。

柔性事务分为：
- 补偿型
- 异步确保型
- 最大努力通知型。
柔型事务：TCC/FMT、Saga（状态机模式、Aop模式）、本地事务消息、消息事务（半消息）

# 3 刚性事务：XA模型
## 3.1 XA模型
X/Open国际联盟有限公司是一个欧洲基金会，它的建立是为了向UNIX环境提供标准。
X/Open DTP(Distributed Transaction Process) 是一个分布式事务模型。这个模型主要使用了**两段提交(2PC - Two-Phase-Commit)** 来保证分布式事务的完整性。
在X/Open DTP(Distributed Transaction Process)模型里面，有三个角色：
- **AP**: Application，应用程序。也就是业务层。哪些操作属于一个事务，就是AP定义的。
- **RM**：Resource Manager，资源管理器。一般是数据库，也可以是其他的资源管理器，如消息队列(如JMS数据源)，文件系统等。
- **TM**: Transaction Manager，事务管理器。接收AP的事务请求，对全局事务进行管理，协调RM的处理。这个也是整个事务调度模型的核心部分。

**XA规范主要定义了TM和RM之间的接口**，在TM和RM之间形成通信桥梁。

XA之所以需要引入事务管理器是因为：**在分布式系统中，从理论上讲两台机器无法达到一致的状态，需要引入一个单点进行协调**（参考Fischer等的论文）。
![[image-160.png]]

## 3.2 XA协议
目前知名的数据库，如Oracle, DB2,mysql等，都是实现了XA接口的，都可以作为RM。
XA是数据库的分布式事务，强一致性。在整个过程中，数据一直处于锁住状态，存在长事务风险。
XA 的主要限制是：
- 必须要拿到所有数据源，要把所有涉及到的数据都要锁定，会产生长事务。
- 数据源要支持XA协议。目前MySQL中只有InnoDB存储引擎支持XA协议，nosql基本不支持

以下函数是TM可以对RM进行的操作：
- xa_open,xa_close：建立和关闭与RM的连接。
- xa_start,xa_end：开始和结束一个本地事务。
- xa_prepare,xa_commit,xa_rollback：预提交、提交和回滚一个本地事务。
- ~~xa_recover：回滚一个已进行预提交的事务。~~
- ax_reg,ax_unreg；允许一个RM在一个TM中注册或撤消注册。

下面是XA各个阶段的处理流程：
![[image-161.png]]

## 3.3 XA协议的分类
![[image-162.png]]

### 3.3.1 2PC/3PC协议
两阶段提交（2PC）协议是XA规范定义的 数据一致性协议。
三阶段提交（3PC）协议对 2PC协议的一种扩展。

### 3.3.2 JTA和JTS规范
作为java平台上事务规范 JTA（Java Transaction API）也定义了对XA事务的支持。JTA定义了一套接口，其中约定了几种主要的角色：`TransactionManager`、`UserTransaction`、`Transaction`、`XAResource`。
JTA定义了这些角色之间需要遵守的规范，如 `Transaction` 委托给`TransactionManager` 等，并通过JTS（Java Transaction Service）实现。
JTS也是一组规范，上面提到JTA中需要角色之间的交互，那应该如何交互？JTS就是约定了交互细节的规范。总体上来说JTA更多的是从框架的角度来约定程序角色的接口，而JTS则是从具体实现的角度来约定程序角色之间的接口，两者各司其职。

像很多其他的java规范一样，JTA仅仅定义了接口，具体的实现则是由供应商(如J2EE厂商)负责提供，目前JTA的实现主要由以下几种：
1. J2EE容器所提供的JTA实现(JBoss)
2. 独立的JTA实现:如JOTM，Atomikos.

## 3.4 XA协议的实现
### 3.4.1 2PC（标准XA模型）
绝大部分关系型数据库，都是基于2PC完成分布式的事务处理。
顾名思义，2PC分为两个阶段处理：
1. 阶段一：提交事务请求
2. 阶段二：
	1. 阶段一正常，则执行事务提交
	2. 如果阶段一超时或者出现异常，则中断事务

#### 3.4.1.1 执行流程
##### 3.4.1.1.1 阶段一：提交事务请求
1. 事务问询：协调者向所有参与者发送事务内容，询问是否可以执行提交操作，并开始等待各参与者进行响应；
2. 执行事务：各参与者节点，执行事务操作，并将Undo和Redo操作计入本机事务日志；
3. 反馈问询：各参与者向协调者反馈事务问询的响应。成功执行返回Yes，否则返回No。

##### 3.4.1.1.2 阶段二：执行事务提交
协调者在阶段二决定是否最终执行事务提交操作。这一阶段包含两种情形：
1. **执行事务提交：所有参与者reply Yes，那么执行事务提交。**
	1. 发送提交请求：协调者向所有参与者发送Commit请求；
	2. 事务提交：参与者收到Commit请求后，会正式执行事务提交操作，并在完成提交操作之后，释放在整个事务执行期间占用的资源；
	3. 反馈提交结果：参与者在完成事务提交后，写协调者发送Ack消息确认；
	4. 完成事务：协调者在收到所有参与者的Ack后，完成事务。
![[image-164.png]]

2. **中断事务：事情总会出现意外，当存在某一参与者向协调者发送No响应，或者等待超时，协调者只要无法收到所有参与者的Yes响应，就会中断事务。**
	1. 发送回滚请求：协调者向所有参与者发送Rollback请求；
	2. 回滚：参与者收到请求后，利用本机Undo信息，执行Rollback操作。并在回滚结束后释放该事务所占用的系统资源；
	3. 反馈回滚结果：参与者在完成回滚操作后，向协调者发送Ack消息；
	4. 中断事务：协调者收到所有参与者的回滚Ack消息后，完成事务中断。
![[image-165.png]]
#### 3.4.1.2 2PC 二阶段提交的特点和优缺点
2PC 方案比较适合单体应用里，跨多个库的分布式事务。因为严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景。

2PC 的优点在于优点主要体现在实现原理简单，缺点则比较多：
- 性能问题：2PC的提交在执行过程中，所有参与事务操作的逻辑都处于阻塞状态。也就是说，各个参与者都在等待其他参与者响应，无法进行其他操作；
- 单点故障：协调者是个单点，一旦出现问题，其他参与者将无法释放事务资源，也无法完成事务操作；
- 数据不一致：如果协调者向所有参与者发送Commit/Rollback请求后发生局部网络异常，最终导致只有部分参与者收到、执行请求，整个系统将会出现数据不一致的情形；
- 2PC没有完善的容错机制：当参与者出现故障时，协调者无法快速得知这一失败，只能严格依赖超时设置来决定是否进一步的执行提交还是中断事务。

### 3.4.2 3PC
针对2PC的缺点，研究者提出了3PC，即 Three-Phase Commit。3PC将原有的两阶段过程，重新划分为 **CanCommit、PreCommit 和 do Commit 三个阶段**。

#### 3.4.2.1 执行流程
![[image-166.png]]

##### 3.4.2.1.1 阶段一：CanCommit
1. 事务询问：协调者向所有参与者发送包含事务内容的canCommit的请求，询问是否可以执行事务提交，并等待应答；
2. 反馈询问：正常情况下，如果参与者认为可以顺利执行事务，则返回Yes，否则返回No。

##### 3.4.2.1.2 阶段二：PreCommit
在本阶段，协调者会根据上一阶段的反馈情况来决定是否可以执行事务的PreCommit操作。有以下两种可能：
1. **执行事务预提交**
    1. 发送预提交请求：协调者向所有节点发出PreCommit请求，并进入prepared阶段；
    2. 事务预提交：参与者收到PreCommit请求后，会执行事务操作，并将Undo和Redo日志写入本机事务日志；
    3. 反馈与提交结果：各参与者成功执行事务操作，同时将反馈以Ack响应形式发送给协调者，同事等待最终的Commit或Abort指令。
2. **中断事务**：假如任意一个参与者向协调者发送No响应，或者等待超时，协调者在没有得到所有参与者响应时，即可以中断事务：
    1. 发送中断请求：协调者向所有参与者发送Abort请求；
    2. 中断事务：收到协调者的Abort请求，**或者等待协调者请求过程中出现超时**，参与者都会中断事务；

##### 3.4.2.1.3 阶段三：doCommit
在这个阶段，会真正的进行事务提交，同样存在两种可能。
1. **执行提交**：
    1. 发送提交请求：假如协调者收到了所有参与者的Ack响应，那么将从预提交转换到提交状态，并向所有参与者，发送doCommit请求；
    2. 事务提交。参与者收到doCommit请求后，会正式执行事务提交操作，并在完成提交操作后释放占用资源；
    3. 反馈事务提交结果。参与者将在完成事务提交后，向协调者发送Ack消息；
    4. 完成事务。协调者接收到所有参与者的Ack消息后，完成事务。
2. **中断事务**：在该阶段，假设正常状态的协调者接收到任一个参与者发送的No响应，或在超时时间内，仍旧没收到反馈消息，就会中断事务。
    1. 发送中断请求。协调者向所有的参与者发送abort请求；
    2. 事务回滚。参与者收到abort请求后，会利用阶段二中的Undo消息执行事务回滚，并在完成回滚后释放占用资源；
    3. 反馈事务回滚结果。参与者在完成回滚后向协调者发送Ack消息；
    4. 中断事务。协调者接收到所有参与者反馈的Ack消息后，完成事务中断。

#### 3.4.2.2 2PC和3PC的区别
**三阶段提交协议在协调者和参与者中都引入超时机制，并且把两阶段提交协议的第一个阶段拆分成了两步：询问，然后再执行**。
**在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者abort请求时，会在等待超时之后，继续进行事务的提交**。其实这个是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了。所以，一句话概括就是，当进入第三阶段时， 由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。

相对于2PC，3PC主要解决了单点故障问题，并减少阻塞， **因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态**。
但是这种机制也会导致数据一致性问题。因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。
总结：3PC相对于2PC缓解了单点故障和数据不一致问题，但是依然没有完全解决数据不一致的问题。

## 3.5 XA相关产品
### 3.5.1 Seata
Seata 是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式。
在 Seata 开源之前，Seata 对应的内部版本在阿里经济体内部一直扮演着分布式一致性中间件的角色，帮助经济体平稳的度过历年的双11，对各BU业务进行了有力的支撑。商业化产品GTS 先后在阿里云、金融云进行售卖。

Seata AT 模式是增强型2pc模式：两阶段提交协议的演变，没有一直锁表
- 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源
- 二阶段：提交异步化，非常快速地完成。回滚通过一阶段的回滚日志进行反向补偿

### 3.5.2 Atomikos 分布式事务实现
Atomikos公司旗下有两款著名的分布事务产品：
- TransactionEssentials：开源的免费产品
- ExtremeTransactions：商业版，需要收费
![[image-163.png]]
可以看到，在开源版本中支持JTA/XA、JDBC、JMS的事务。

# 4 柔性事务
在电商领域等互联网场景下，刚性事务在数据库性能和处理能力上都暴露出了瓶颈。
**柔性事务有两个特性：基本可用和柔性状态**。
- 基本可用是指分布式系统出现故障的时候允许损失一部分的可用性。
- 柔性状态是指允许系统存在中间状态，这个中间状态不会影响系统整体的可用性，比如数据库读写分离的主从同步延迟等。柔性事务的一致性指的是最终一致性。

柔性事务主要分为**补偿型**和**通知型**。
- 补偿型事务又分：TCC、Saga。
- 通知型事务分：MQ事务消息、最大努力通知型。

**补偿型事务都是同步的，通知型事务都是异步的**。

## 4.1 通知型
通知型事务的主流实现是通过 MQ（消息队列）来通知其他事务参与者自己的执行状态。
引入MQ组件，有效的将事务参与者进行解耦，各参与者都可以异步执行，所以**通知型事务又被称为异步事务**。
**通知型事务主要适用于那些需要异步更新数据，并且对数据的实时性要求较低的场景**。

通知型事务主要包含: **异步确保型事务**和**最大努力通知事务**两种。
- **异步确保型事务**：主要适用于内部系统的数据最终一致性保障，因为内部相对比较可控，如订单和购物车、收货与清算、支付与结算等等场景；
- **最大努力通知**：主要用于外部系统，因为外部的网络环境更加复杂和不可信，所以只能尽最大努力去通知实现数据最终一致性，比如充值平台与运营商、支付对接等等跨网络系统级别对接；
![[image-167.png]]

### 4.1.1 异步确保型事务
#### 4.1.1.1 MQ 事务消息方案
基于MQ的事务消息方案主要依靠MQ的**半消息机制**来实现投递消息和参与者自身本地事务的一致性保障。
半消息机制实现原理其实借鉴的2PC的思路，是二阶段提交的广义拓展。
![[image-168.png]]

流程：
1. 事务发起方首先发送半消息到MQ；
2. MQ通知发送方消息发送成功；
3. 在发送半消息成功后执行本地事务；
	- **反查机制**：如果执行本地事务过程中，执行端挂掉、或者超时，MQ服务器端将不停的询问执行端来获取事务状态；
4. 根据本地事务执行结果返回commit或者是rollback；
5. 如果消息是rollback, MQ将丢弃该消息不投递；如果是commit，MQ将会消息发送给消息订阅方；
6. 订阅方根据消息执行本地事务；
7. 订阅方执行本地事务成功后再从MQ中将该消息标记为已消费

你可能会问，发送方执行完事务之后再发一条普通消息，事务执行失败就不发，不也行吗？
原因在于，上面的事务和消息发送是两步操作，**不能保证原子性**。所以要用两阶段提交和MQ反查机制，来保证两步操作的原子性

##### 4.1.1.1.1 基于RocketMQ实现MQ异步确保型事务
有一些第三方的MQ是支持事务消息的，这些消息队列，支持半消息机制，比如RocketMQ，ActiveMQ。但是有一些常用的MQ也不支持事务消息，比如 RabbitMQ 和 Kafka 都不支持。
以阿里的 RocketMQ 中间件为例，其思路大致为：
1. producer(本例中指A系统)发送半消息到broker
2. broker存储半消息，半消息存储逻辑与普通消息一致，只是属性有所不同，topic是固定的`RMQ_SYS_TRANS_HALF_TOPIC`，queueId也是固定为0，这个topic中的消息对消费者是不可见的，所以里面的消息永远不会被消费。**这就保证了在半消息提交成功之前，消费者是消费不到这个半消息的**
3. broker端半消息存储成功并返回后，A系统执行本地事务，并根据本地事务的执行结果来决定半消息的提交状态为提交或者回滚
4. A系统发送结束半消息的请求，并带上提交状态(提交 or 回滚)
5. broker端收到请求后，首先从`RMQ_SYS_TRANS_HALF_TOPIC`的queue中查出该消息，设置为完成状态。如果消息状态为提交，则把半消息从`RMQ_SYS_TRANS_HALF_TOPIC`队列中复制到这个消息原始topic的queue中去(之后这条消息就能被正常消费了)；如果消息状态为回滚，则什么也不做。
6. rocketMq提供了一个兜底方案，这个方案叫消息**反查机制**，Broker启动时，会启动一个`TransactionalMessageCheckService` 任务，该任务会定时从半消息队列中读出所有超时未完成的半消息，针对每条未完成的消息，Broker会给对应的Producer发送一个消息反查请求，根据反查结果来决定这个半消息是需要提交还是回滚，或者后面继续来反查
7. consumer(本例中指B系统)消费消息，执行本地数据变更(至于B是否能消费成功，消费失败是否重试，这属于正常消息消费需要考虑的问题)

#### 4.1.1.2 本地消息表方案
有时候我们目前的MQ组件并不支持事务消息，或者我们想尽量少的侵入业务方。这时我们需要另外一种方案“基于DB本地消息表“。
本地消息表最初由eBay 提出来解决分布式事务的问题。是目前业界使用的比较多的方案之一，**它的核心思想就是将分布式事务拆分成本地事务进行处理**。
![[image-172.png]]
发送消息方：
1. 需要有一个消息表，记录着消息的相关信息。消息的状态有待发送、已发送、已消费、失败。
2. 业务数据和消息表在同一个数据库，要保证它俩在同一个本地事务。直接利用本地事务，将业务数据和事务消息直接写入数据库。
3. 在本地事务中处理完业务数据和写消息表操作后，通过写消息到 MQ，写完之后把状态改成“已发送”。
4. 注意兜底，使用定时任务将状态是“待发送”的消息重新发送并更新状态。

消息消费方：
1. 处理消息队列中的消息，完成自己的业务逻辑。注意幂等处理。
2. 如果本地事务处理成功，则表明已经处理成功了。那么就通过RPC或MQ告知发送方处理成功，把消息状态改成“已消费”。
	- “已消费”是为了标记事务最终完成，让发送方能释放中间状态资源、便于后续对账或监控。其核心目的是**让分布式事务的发起方（生产者）掌握整个流程的最终状态，从而实现 “最终一致性”**。
3. 可选操作：如果处理失败，那么把消息状态改成“失败”，同时发送方做补偿措施，例如回滚。

本地消息表优缺点：
1. 优点：
    - 本地消息表建设成本比较低，实现了可靠消息的传递，确保了分布式事务的最终一致性。
    - 无需提供回查方法，进一步减少的业务的侵入。
2. 缺点：
    - 本地消息表与业务耦合在一起，难于做成通用性，不可独立伸缩。
    - 本地消息表是基于数据库来做的，而数据库是要读写磁盘IO的，因此在高并发下是有性能瓶颈的

#### 4.1.1.3 MQ事务消息 VS 本地消息表
**二者的共性**：
1. 事务消息都依赖MQ进行事务通知，所以都是异步的。
**二者的区别：**
MQ事务消息：
- 需要MQ支持半消息机制或者类似特性；
- 具有比较大的业务侵入性，需要业务方进行改造，提供对应的本地操作成功的回查功能；
DB本地消息表：
- 使用了数据库来存储事务消息，降低了对MQ的要求，但是增加了存储成本；
- 事务消息使用了异步投递，增大了消息重复投递的可能性；

### 4.1.2 最大努力通知
最大努力通知方案的目标，就是最大努力将业务处理结果通知到接收方。
**最大努力通知事务**主要用于**外部系统**，因为外部的网络环境更加复杂和不可信，所以只能尽最大努力去通知实现数据最终一致性，比如充值平台与运营商、支付对接、商户通知等等跨平台、跨企业的系统间业务交互场景。

要实现最大努力通知，可以采用定期检查本地消息表的机制。例如支付网关和商户系统：
1. 发起方执行本地事务（核心事务，必须优先成功）
	- 支付网关接收用户支付请求，执行“扣减用户余额”的本地数据库事务；
	- 事务提交成功（仅当支付成功时才触发后续通知），**同时在本地创建“通知记录”**（关键：通知记录与本地事务同库同事务，确保原子性）；
	  - 通知记录字段：通知ID（唯一标识）、商户ID、订单号、通知状态（待发送/发送中/已成功/已失败）、重试次数、下次重试时间、创建时间等。
2. 发起方首次发送通知（实时推送）
	- 支付网关通过HTTP/HTTPS/MQ向商户系统发送“支付成功”通知（携带订单号、支付金额等关键信息）；
	- 核心要求：接收方（商户系统）处理完成后，**必须返回“明确的ACK响应”**（如HTTP 200 OK + 约定的成功标识），无ACK或非200均视为通知失败。
3. 重试机制（处理通知失败场景）：若发起方未收到ACK（如网络中断、商户系统宕机），或收到非成功响应，将通知记录标记为“发送失败”，并触发重试
	- 重试策略：**采用“指数退避策略”**（避免高频重试压垮接收方），例如：首次重试间隔1分钟，第二次3分钟，第三次5分钟，最大重试次数5次（可配置）；
	- 重试触发：通过“定时任务”扫描本地消息表中“待发送”或“发送失败”且“未达最大重试次数”的记录，按“下次重试时间”排序批量发送；
	- 重试上限：达到最大重试次数后，将通知状态改为“已失败”，停止自动重试。
4. 接收方处理通知（需保证幂等性）
	- 商户系统接收通知后，首先校验通知的合法性（如签名验证，防止伪造通知）；
	- 校验通过后，执行本地事务（如将订单状态从“待支付”改为“已支付”）；
	- 关键：**必须实现幂等性**（因为重试会导致同一通知多次到达），实现方式：
		- 基于订单号做唯一约束（数据库唯一索引），重复通知直接返回成功；
		- 基于通知ID做Redis缓存去重（收到通知后先查Redis，存在则直接返回ACK）。
5. 兜底处理（解决最终失败场景）对于达到最大重试次数仍失败的通知，发起方提供“兜底方案”：
	- **人工干预**：生成失败通知报表，运营人员手动核对支付结果并通知商户；
	- **接收方主动查询**：商户系统通过定时任务主动调用支付网关的“订单支付状态查询接口”，兜底获取结果（双向保障）。

### 4.1.3 通知型事务的问题
基于消息实现的事务并不能解决所有的业务场景，例如以下场景：某笔订单完成时，同时扣掉用户的现金。这里事务发起方是管理订单库的服务，但对整个事务是否提交并不能只由订单服务决定，因为还要确保用户有足够的钱，才能完成这笔交易，而这个信息在管理现金的服务里。

## 4.2 补偿型
针对通知型事务的问题，这里我们可以引入基于补偿实现的事务，其流程如下：
1. 创建订单数据，但暂不提交本地事务
2. 订单服务发送远程调用到现金服务，以扣除对应的金额
3. 上述步骤成功后提交订单库的事务
以上这个是正常成功的流程，异常流程需要回滚的话，将额外发送远程调用到现金服务以加上之前扣掉的金额。

可以看到，该事务流程更为复杂，需要额外开发相关的业务回滚方法，也失去了服务间流量削峰填谷的功能。

### 4.2.1 什么是补偿模式？
补偿模式使用一个额外的**协调服务**来协调各个需要保证一致性的业务服务，协调服务按顺序调用各个业务微服务。如果某个业务服务调用异常，就取消之前所有已经调用成功的业务服务。
**补偿是一个独立的支持ACID特性的本地事务，用于在逻辑上取消服务提供者上一个ACID事务造成的影响**。对于一个长事务(long-running transaction)，与其实现一个巨大的分布式ACID事务，不如使用基于补偿性的方案，把每一次服务调用当做一个较短的本地ACID事务来处理，执行完就立即提交。

补偿模式大致有TCC、Saga 两种细分的方案。

### 4.2.2 TCC 事务模型
#### 4.2.2.1 TCC 概念
**TCC（Try-Confirm-Cancel）** 的概念来源于 Pat Helland 发表的一篇名为“Life beyond Distributed Transactions:an Apostate’s Opinion”的论文。TCC 分布式事务模型包括三部分：
1. **事务发起者**：事务发起者为整个业务活动的发起方，服务的编排者，负责发起并完成整个业务活动。
2. **事务参与者**：事务参与者是整个业务活动的参与方，负责提供 TCC 业务操作，实现初步操作(Try)、确认操作(Confirm)、取消操作(Cancel)三个接口，供事务发起者调用。
3. **事务协调器**：事务协调器管理控制整个业务活动，包括记录维护 TCC 全局事务的事务状态和每个从业务服务的子事务状态，并在业务活动提交时调用所有从业务服务的 Confirm 操作，在业务活动取消时调用所有从业务服务的 Cancel 操作。

TCC 基于业务层面的事务定义，锁粒度完全由业务自己控制，目的是解决复杂业务中，跨表跨库等大颗粒度资源锁定的问题。
TCC它会弱化每个步骤中对于资源的锁定，以达到一个能承受高并发的目的（基于最终一致性）。

#### 4.2.2.2 TCC 工作流程
TCC分布式事务模型相对于 XA 等传统模型，其特征在于**它不依赖资源管理器(RM)对分布式事务的支持，而是通过对业务逻辑的分解来实现分布式事务**。
TCC 模型认为对于业务系统中一个特定的业务逻辑，其对外提供服务时，必须接受一些不确定性，即对业务逻辑初步操作的调用仅是一个临时性操作，调用它的主业务服务保留了后续的取消权。每一个初步操作，最终都会被确认或取消。

TCC 工作流程如下：
![[image-176.png]]
1. Try阶段：资源检查与预留，实现准隔离性。“试探性操作”，不实际提交业务，仅确保后续操作可行）；
2. Confirm阶段：基于 Try 阶段的预留资源，完成最终业务提交，幂等执行。
3. Cancel阶段：补偿回滚操作。若 Try 阶段失败或整体事务中断，释放 Try 阶段预留的资源，恢复初始状态，幂等执行。

#### 4.2.2.3 TCC 事务模型的要求
1. **强一致性**：最终所有参与者要么全部成功（Confirm），要么全部失败（Cancel），无中间状态；
2. **业务侵入式**：需改造业务代码，为每个分布式事务参与者编写 Try/Confirm/Cancel 方法；
3. **短事务优先**：适合执行时间短的事务（Try 阶段预留的资源需尽快释放，避免资源占用过久）。
4. **无锁设计**：Try 阶段仅预留资源，不持有锁，并发性能优于 2PC/3PC。注意**TCC 的 “无锁” 是 “分布式层面的无长锁”，而非 “本地层面的无锁”**
	1. 无 **分布式长事务锁**：不会像 2PC 那样，在 “准备阶段” 就让所有参与者持有数据库锁，直到 “提交 / 回滚” 阶段才释放（导致跨系统阻塞）；
	2. 无 **跨系统阻塞锁**：各参与者的锁仅在本地事务中持有，不会因其他系统的执行状态（如订单服务未完成）而长时间持有锁；
	3. 本地事务仍可能有 **短锁**：比如库存服务 Try 阶段扣减预留库存时，本地数据库会加行锁（如 MySQL 的行锁），但本地事务执行极快（仅更新库存和预留库存字段），事务提交后锁立即释放，不会阻塞其他事务。
5. **幂等性要求**：TCC 中会添加**事务日志**，如果 Confirm 或 Cancel 阶段出错，则会进行**重试**，所以这两个阶段需要支持**幂等**；如果重试失败，则需要**人工介入进行恢复和处理**等。Try 阶段也需要支持重试，例如一些非业务失败（网络波动），所以也要考虑幂等
	- 全局唯一事务 ID（TID）+ 本地状态表（或者缓存）
6. **防悬挂**：Cancel和Try的后发先至问题
	- 实现方式：
	    - 参与者本地维护 “事务状态表”，记录 Try 和 Cancel 的执行状态
	    - Try 方法执行前，先查状态表：若已执行 Cancel，直接返回失败；若未执行 Cancel，再执行 Try 逻辑。
	    - Cancel 调用时，先查状态表：若 Try 未执行（无记录或状态为 “Try 失败”），直接返回成功（无需补偿）；若 Try 已执行，再执行 Cancel 逻辑。
7. **协调器防单点故障**：参加下文

##### 4.2.2.3.1 无锁设计和2PC的对比
以 “电商下单” 的库存服务为例，对比 TCC 和 2PC 的锁机制，就能清晰看到差异：
**TCC 的库存操作（无分布式长锁）**
```sql
# Try阶段（本地事务，耗时10ms）
BEGIN;
-- 检查库存充足（库存≥10），并扣减预留库存（实际库存100→90，预留库存0→10）
UPDATE inventory 
SET stock = stock - 10, reserved_stock = reserved_stock + 10 
WHERE product_id = 123 AND stock ≥ 10;
COMMIT; -- 事务提交，本地行锁释放（仅持有10ms）

# 后续阶段（Confirm/Cancel，无分布式阻塞）
-- 若全局Confirm：将预留库存转为实际扣减（reserved_stock 10→0），本地事务耗时5ms，锁立即释放；
-- 若全局Cancel：释放预留库存（stock 90→100，reserved_stock 10→0），本地事务耗时5ms，锁立即释放。
```

**2PC 的库存操作（分布式长锁）**
```sql
# 准备阶段（2PC的第一阶段）
BEGIN;
-- 扣减库存（实际库存100→90），但不提交事务
UPDATE inventory SET stock = stock - 10 WHERE product_id = 123 AND stock ≥ 10;
-- 告知协调器“准备完成”，但事务不提交，本地行锁持续持有！

# 等待全局决策（可能耗时1秒→10秒，取决于其他参与者）
-- 若其他参与者（如支付服务）执行缓慢，库存服务的事务一直处于“未提交”状态，行锁持续持有，其他事务无法操作该商品库存，导致并发阻塞。

# 提交/回滚阶段（2PC的第二阶段）
COMMIT; -- 或ROLLBACK; 事务提交后，锁才释放。
```

##### 4.2.2.3.2 TCC对单点故障的解决
###### 4.2.2.3.2.1 和2PC的区别
2PC 的锁阻塞完全绑定事务管理器（协调器），根源有 2 个：
1. **锁持有周期 = 全局事务周期**：2PC 准备阶段，所有参与者执行本地操作后不提交事务，持有的行锁 / 表锁会一直保留，必须等协调器下达「commit/rollback」指令，才会提交 / 回滚事务、释放锁；
2. **参与者依赖协调器决策**：参与者没有自主决策能力，协调器挂了后，参与者不知道该 commit 还是 rollback，只能一直持有锁等待，直到协调器恢复或人工介入，锁可能阻塞几分钟甚至几小时。

而TCC 的 Try/Confirm/Cancel 三个阶段，所有操作都是「本地独立事务」，锁持有仅在本地事务执行期间（毫秒级），且**参与者无需等待协调器决策就能释放锁**，协调器单点故障仅影响 “事务推进”，不影响 “锁释放”。

###### 4.2.2.3.2.2 单点故障解决方案
虽然 TCC 协调器挂了不导致锁阻塞，但会中断事务推进（如订单处于 “待确认” 状态、库存处于 “预留” 状态），实际项目中需通过「**集群部署 + 状态持久化**」解决协调器单点问题。
状态持久化：协调器需将事务状态（如 TID、参与者列表、当前阶段：Try 成功 / 待 Confirm / 待 Cancel）持久化到可靠存储中，确保故障后可恢复。类似实例系统的交付单
还需要加上**定时任务兜底**：
- 协调器集群部署定时任务，扫描持久化存储中「长时间处于中间状态」的事务（如 Try 成功后 10 分钟未 Confirm）；
- 触发告警，同时自动重试对应阶段（Confirm/Cancel），避免事务长期卡壳。

#### 4.2.2.4 完整三阶段流程（以 “电商下单” 为例）
假设分布式事务包含 3 个参与者：**订单服务（创建订单）、库存服务（扣减库存）、支付服务（扣减用户余额）**，整体流程如下：

##### 4.2.2.4.1 Try 阶段：资源检查与预留（核心目标：“可执行性验证 + 资源锁定”）
- 订单服务（Try）：
    - 检查订单参数合法性（如商品是否存在、用户是否正常）；
    - 创建 “待确认” 状态的订单（预留订单资源，不对外暴露 “已创建” 状态）；
    - 本地事务提交（确保订单预留成功）。
- 库存服务（Try）：
    - 检查商品库存是否充足（如用户购买 10 件，库存≥10）；
    - 扣减 “预留库存”（而非实际库存，如库存从 100→90，预留库存从 0→10）；
    - 本地事务提交（确保库存预留成功）。
- 支付服务（Try）：
    - 检查用户余额是否充足（如用户余额≥订单金额 100 元）；
    - 冻结用户余额（如余额从 500→400，冻结金额从 0→100）；
    - 本地事务提交（确保余额冻结成功）。

**关键要求**：Try 阶段必须是 “幂等、可重试” 的，且预留的资源必须是 “排他性” 的（避免其他事务重复占用）。

##### 4.2.2.4.2 Confirm 阶段：确认执行业务（核心目标：“无锁提交，不可回滚”）
- 协调器判断：仅当所有参与者的 Try 方法都返回 “成功”，才触发全局 Confirm；
- 订单服务（Confirm）：
    - 将订单状态从 “待确认” 更新为 “已创建”（对外暴露最终状态）；
    - 本地事务提交（无异常则成功，不允许回滚）。
- 库存服务（Confirm）：
    - 将 “预留库存” 转为实际扣减（如预留库存从 10→0，实际库存从 90→90，最终库存 = 初始库存 - 预留库存）；
    - 本地事务提交。
- 支付服务（Confirm）：
    - 将 “冻结余额” 转为实际扣减（如冻结金额从 100→0，实际余额从 400→400，最终余额 = 初始余额 - 冻结金额）；
    - 本地事务提交。

**关键要求**：Confirm 方法必须是 “幂等、不可中断” 的，一旦执行成功，无法回滚，需确保业务逻辑无副作用。

##### 4.2.2.4.3 Cancel 阶段：补偿回滚（核心目标：“释放预留资源，恢复初始状态”）
- 协调器判断：若任一参与者的 Try 方法返回 “失败” 或 “超时”，则触发全局 Cancel；
- 订单服务（Cancel）：
    - 删除 “待确认” 状态的订单（释放订单资源）；
    - 本地事务提交。
- 库存服务（Cancel）：
    - 释放 “预留库存”（如预留库存从 10→0，实际库存从 90→100，恢复初始库存）；
    - 本地事务提交。
- 支付服务（Cancel）：
    - 解冻 “冻结余额”（如冻结金额从 100→0，实际余额从 400→500，恢复初始余额）；
    - 本地事务提交。

**关键要求**：Cancel 方法必须是 “幂等、可重试” 的，确保即使重复调用，也能正确释放资源，恢复初始状态。

#### 4.2.2.5 TCC VS 2PC
![[image-177.png]]
这两张图看起来差别较大，实际上很多地方是类似的：
1. TCC模型中的主业务服务相当于 DTP模型中的AP，TCC模型中的从业务服务相当于 DTP模型中的RM
    - 不同的是DTP模型中的资源提供者是类似于Mysql这种关系型数据库，而TCC模型中资源的提供者是其他业务服务。
2. TCC模型中，从业务服务提供的try、confirm、cancel 接口相当于 DTP模型中RM提供的prepare、commit、rollback接口

TCC和2PC不同的是：
- TCC位于业务服务层而不是资源层
- 一致性和锁粒度不同：
	- XA是资源层面的分布式事务，强一致性。在两阶段提交的整个过程中，一直会持有资源的数据库锁，一般高并发性能会比较差
	- TCC是业务层面的分布式事务，最终一致性，不会一直持有资源的锁，性能较好。
- 开发量不同
	- XA事务中的两阶段提交内部过程是对开发者屏蔽的，开发者从代码层面是感知不到这个过程的。
	- TCC中的两阶段提交对微服务的侵入性强，微服务的每个事务都必须实现try、confirm、cancel等3个方法，开发成本高，今后维护改造的成本也高。
		- 为了达到事务的一致性要求，try、confirm、cancel接口必须实现幂等性操作。

#### 4.2.2.6 TCC 的使用场景
TCC 适合**核心业务、强一致性要求、短事务、并发性能要求高**的场景，比如说**跟钱打交道的，支付、交易相关的场景**，大家会用 TCC方案，严格保证资金的正确性。
但是，它的一个问题在于，需要每个参与者都分别实现Try，Confirm和Cancel接口及逻辑，这对于业务的侵入性是巨大的。以下场景不适合：
- 非核心业务（如短信通知、数据同步）：无需强一致性，用最大努力通知或 MQ 事务消息更高效；
- 长事务场景（如跨天的订单处理）：Try 阶段预留资源过久，导致资源浪费，适合 SAGA；
- 业务逻辑无明确补偿机制的场景（如第三方接口调用，无法回滚）：TCC 依赖 Cancel 方法，无补偿逻辑则无法使用；
- 高并发写冲突场景（如秒杀商品，库存频繁被预留）：Try 阶段可能出现大量冲突，需结合分布式锁优化。

TCC实际上是最为复杂的一种情况，但无论出于性能上的考虑，还是开发复杂度上的考虑，都应该尽量避免该类事务。

### 4.2.3 SAGA 长事务模型
1987年普林斯顿大学的Hector Garcia-Molina和Kenneth Salem发表了一篇Paper Sagas，讲述的是如何处理long lived transaction（长活事务）。
SAGA 是分布式事务中**针对长事务、跨多系统场景**的最终一致性方案，核心思想是 “将长事务拆分为多个短事务序列，每个短事务对应一个补偿事务，正常执行正向流程，异常时执行补偿流程回滚状态”。它解决了 TCC 业务侵入性高、2PC 阻塞的问题，同时适配跨多系统、执行时间长的复杂业务场景。

#### 4.2.3.1 SAGA 概念
Saga 模型是把一个分布式事务拆分为多个本地事务，每个本地事务都有相应的执行模块和补偿模块（对应TCC中的Confirm和Cancel），当Saga事务中任意一个本地事务出错时，可以通过调用相关的补偿方法恢复之前的事务，达到事务最终一致性。
这样的SAGA事务模型，是牺牲了一定的隔离性和一致性的，但是提高了长事务的可用性。

Saga 模型由三部分组成：
1. LLT（Long Live Transaction）：由一个个本地事务组成的事务链。
2. 本地事务：事务链由一个个子事务（本地事务）组成，LLT = T1+T2+T3+...+Ti。
3. 补偿：每个本地事务 Ti 有对应的补偿 Ci。

Saga的执行顺序有两种：
- 正常执行：T1, T2, T3, ..., Tn
- 异常回滚：T1, T2, ..., Tj, Cj,..., C2, C1，其中0 < j < n

Saga 两种恢复策略：
- **向后恢复（Backward Recovery）**：撤销掉之前所有成功子事务。如果任意本地子事务失败，则补偿已完成的事务。如异常情况的执行顺序T1,T2,T3,..Ti,Ci,...C3,C2,C1。
- **向前恢复（Forward Recovery）**：即重试失败的事务，适用于必须要成功的场景，该情况下不需要Ci。执行顺序：T1,T2,...,Tj（失败）,Tj（重试）,...,Ti。

理论上补偿事务永不失败，然而，在分布式世界中，服务器可能会宕机，网络可能会失败，甚至数据中心也可能会停电。在这种情况下我们能做些什么？ **最后的手段是提供回退措施，比如人工干预**。

#### 4.2.3.2 核心特点
1. **最终一致性**：不保证强一致性，允许中间状态存在，通过补偿流程确保最终所有系统要么全部成功，要么全部回滚；
2. **无锁设计**：每个短事务都是本地事务，执行完立即提交，无分布式锁，并发性能高；
3. **低业务侵入性**：无需像 TCC 那样编写 Try/Confirm/Cancel 三个方法，仅需为每个短事务编写正向逻辑和补偿逻辑，适配现有业务改造；
4. **支持长事务**：短事务独立执行，无锁阻塞，适合跨多系统、执行时间长的场景（如跨天的供应链审批）；
5. **补偿依赖性**：补偿事务需能正确回滚正向事务的结果，要求正向事务的操作可补偿（如转账可通过反向转账补偿，订单创建可通过订单删除补偿）。有些事务不能撤销，例如导弹发射

#### 4.2.3.3 实现机制
SAGA 有两种核心实现模式：去中心化和中心化。两种模式的架构、复杂度、适用场景不同，需分别掌握。

##### 4.2.3.3.1 模式一：去中心化，无协调器
无集中式协调器，每个短事务的参与者（系统）自主通信，通过消息队列（如 RocketMQ、Kafka）触发下一个短事务，异常时由失败的参与者触发逆序补偿。

完整流程（以 “跨系统下单” 为例：T1 = 创建订单→T2 = 扣减库存→T3 = 扣减支付余额→T4 = 创建物流单）
- 正常流程（正向执行）
	1. 订单系统执行T1（创建订单），本地事务提交；
	2. 订单系统发送“订单创建成功”消息到MQ；
	3. 库存系统消费消息，执行T2（扣减库存），本地事务提交；
	4. 库存系统发送“库存扣减成功”消息到MQ；
	5. 支付系统消费消息，执行T3（扣减余额），本地事务提交；
	6. 支付系统发送“余额扣减成功”消息到MQ；
	7. 物流系统消费消息，执行T4（创建物流单），本地事务提交；
	8. 事务完成，所有系统状态一致。
- 异常流程（T3执行失败，触发补偿）
	1. T1、T2执行成功，T3（扣减余额）执行失败（如余额不足）；
	2. 支付系统发送“余额扣减失败”消息到MQ；
	3. 库存系统消费消息，执行C2（补偿T2：恢复库存），本地事务提交；
	4. 库存系统发送“库存恢复成功”消息到MQ；
	5. 订单系统消费消息，执行C1（补偿T1：删除订单），本地事务提交；
	6. 事务回滚，所有系统恢复初始状态。

关键特点：
- 优点：架构简单，无单点故障（无协调器），各系统解耦，适合短事务数量少（3 个以内）的场景；
- 缺点：耦合度高（每个系统需知道下一个系统的逻辑和消息格式），异常处理复杂（需手动维护补偿顺序），难以扩展（新增短事务需修改所有相关系统）。

##### 4.2.3.3.2 模式二：中心化，有协调器
引入集中式协调器，协调器负责管理 SAGA 的整体流程（正向执行顺序、补偿顺序），通过调用各参与者的接口触发短事务或补偿事务，各参与者无需知道其他参与者的存在，仅与协调器交互。
- 正常流程（正向执行）
	1. 客户端发起分布式事务请求，协调器启动SAGA实例；
	2. 协调器调用订单系统接口，执行T1（创建订单），返回成功；
	3. 协调器调用库存系统接口，执行T2（扣减库存），返回成功；
	4. 协调器调用支付系统接口，执行T3（扣减余额），返回成功；
	5. 协调器调用物流系统接口，执行T4（创建物流单），返回成功；
	6. 协调器标记SAGA状态为“成功”，事务结束。

- 异常流程（T3执行失败，触发补偿）
	1. 协调器执行T1、T2成功，调用T3（扣减余额）返回失败；
	2. 协调器标记SAGA状态为“执行失败”，触发补偿流程；
	3. 协调器调用支付系统接口，执行C3（补偿T3：恢复余额），返回成功；
	4. 协调器调用库存系统接口，执行C2（补偿T2：恢复库存），返回成功；
	5. 协调器调用订单系统接口，执行C1（补偿T1：删除订单），返回成功；
	6. 协调器标记SAGA状态为“回滚成功”，事务结束。

关键特点：
- 优点：耦合度低（各参与者仅与协调器交互），流程清晰（协调器统一管理正向 / 补偿顺序），易于扩展（新增短事务仅需修改协调器逻辑），适合短事务数量多（3 个以上）、复杂流程场景；
- 缺点：协调器是单点风险（需集群部署），增加了系统复杂度（需开发 / 维护协调器）。

#### 4.2.3.4 SAGA 的适用场景
SAGA 适合**长事务、跨多系统、可容忍中间状态、正向事务可补偿**的场景。例如供应链管理（跨企业 + 长流程）、金融信贷审批（多环节 + 长周期）

#### 4.2.3.5 SAGA VS TCC
1. 一致性：TCC 是强一致，SAGA 是最终一致；
2. 业务侵入性：TCC 需写 Try/Confirm/Cancel 三个方法，侵入性更高；SAGA 需写正向和补偿方法，侵入性中等；
3. 适用场景：TCC 适合短事务、核心业务（如转账、秒杀），要求强一致和高并发；SAGA 适合长事务、跨多系统业务（如供应链、信贷审批），可容忍中间状态，无需强一致。
4. 总结：如果业务是核心且强一致，选 TCC；如果是长流程且跨多系统，选 SAGA。

##### 4.2.3.5.1 为什么TCC是强一致性
问题：假设库存服务执行了Try，它的实际库存移了一些到预留库存，而此时支付服务还没有执行Try冻结余额，这不就是暂时出现了数据不一致吗？

注意：**强一致性≠无中间状态，而是 “中间状态不对外暴露、业务无感知，最终所有节点状态完全一致”；最终一致性则是 “允许中间状态对外暴露、业务可能感知到不一致，但经过一段时间后会自动恢复一致”**。

“库存服务执行 Try（预留库存），支付服务未执行 Try（未冻结余额）”，确实是 TCC 的中间状态，但这个状态**对业务是不可见、不可用的**，不会导致业务层面的不一致，因此 TCC 仍属于强一致性。
TCC 的 Try 阶段核心是 “资源检查 + 预留”，预留的资源会被标记为 “不可用”，其他业务操作无法访问。最终只有 “全部 Confirm” 或 “全部 Cancel” 两种结果，无中间业务状态。

而**SAGA 的中间状态是 “业务已提交态”，会对外暴露**，导致业务层面的不一致，只是通过补偿流程最终修复，因此属于最终一致性。
1. SAGA 的每个短事务执行后立即提交，状态对外暴露，其他业务操作可访问：
	- 正常流程中间态：订单系统执行 T1（创建订单，状态 “已创建”）→库存系统执行 T2（扣减库存，状态 “已扣减”）→支付系统未执行 T3（余额 “未扣减”）；
	- 业务感知：此时用户看到 “订单已创建”，库存统计显示 “已扣减”，但支付余额仍 “未扣减”—— 业务上出现 “有订单、扣了库存但没支付” 的不一致，其他业务可能基于此做错误决策（如库存已扣减导致其他用户无法下单，但该订单未支付）。
2. 异常时需通过补偿修复不一致，存在 “不一致窗口”：若支付系统 T3 执行失败（余额不足），SAGA 需执行补偿流程（C3→C2→C1）：
	- 补偿流程：恢复支付余额（无操作，因未扣减）→恢复库存→删除订单；
	- 关键：从 “T2 执行成功” 到 “C2 执行成功” 的这段时间（可能是秒级、分钟级），业务上存在不一致（订单已创建、库存已扣减），这个 “不一致窗口” 是 SAGA 最终一致性的核心特征 —— 它允许中间不一致，但最终会修复。

对比 TCC：SAGA 的中间状态是 “业务可见的不一致”：TCC 的中间状态是 “技术层面的预留态”，业务不可见；SAGA 的中间状态是 “业务层面的已提交态”，业务可见 —— 这是两者一致性类别的本质区别。

# 5 总结
- 分布式事务定义：一个大的操作，包含很多小操作，这些小操作分布在不同的节点上。这些小操作要么全成功，要么全失败。
- 分布式事务常见于几类操作：跨库事务、分库分表、多个微服务的操作
- 分布式事务分为两类：
	- 刚性事务：满足CP，强一致性。适合低并发、单体应用里跨多个库的分布式事务。
	- 柔性事务：满足BASE，最终一致性。适合高并发。
- 刚性事务：XA模型，是由X/Open基金会指定的分布式事务规范。它主要采用两阶段提交来实现分布式事务，并且定义了AP(业务层)、RM(资源管理器)、TM(事务管理器)三个角色。
	- 2PC：标准XA模型
		- 流程：
			1. 预提交阶段：TM向所有RM发送prepare请求，RM收到后执行事务操作，根据结果返回yes或no
			2. 提交阶段：
				- TM收到所有RM的yes响应，然后向所有RM发送commit请求，确认事务的提交，释放占用的资源。
				- TM收到部分的RM的no响应、或部分RM响应超时，就会向所有RM发送rollback请求，回滚事务。
		- 缺点：
			- 性能较差：在 “准备阶段” 就需要持有所有RM的锁，直到 “提交 / 回滚” 阶段才释放，有长事务风险
			- 单点故障：如果TM崩溃，那么RM将长期得不到释放
			- 一致性问题：如果commit/rollback请求只有部分RM收到，那么数据将会不一致
			- 没有完善的容错机制：RM故障时，TM没有办法快速得知这一情况，只能依赖超时机制进行回滚
	- 3PC：是对2PC的改进
		- 流程
			1. 询问提交阶段：TM向所有RM发送CanCommit请求，RM根据是否能执行事务操作，返回yes或no
			2. 预提交阶段：
				- TM收到所有RM的yes响应，然后向所有RM发送PreCommit请求，RM执行具体的事务提交操作，根据结果返回yes或no
				- TM收到部分的RM的no响应、或部分RM响应超时，就会向所有RM发送Abort请求，中断事务。
					- 此外，如果RM接受TM的请求超时，也会自行终断事务
			3. 提交阶段：
				- TM收到所有RM的yes响应，向所有RM发送doCommit请求，确认事务的提交，释放占用的资源。
					- 此外，如果RM接受TM的请求超时，也会自行提交事务
				- TM收到部分的RM的no响应、或部分RM响应超时，就会向所有RM发送Abort请求，回滚事务。
		- 特点：
			- 3PC在TM和RM中都引入超时机制，并且把2PC的第一个阶段拆分成了两步：询问，然后再执行
			- 超时机制是为了避免TM的单点故障问题，让RM不用一直等待；并且进入第三阶段后，RM知道TM向所有RM发送了PreCommit请求，经过第一阶段大家的同意，大概率操作不会失败，因此自己可以自行提交，这样也缓解了2PC的数据不一致问题
			- 但是3PC只是缓解了部分问题，如果RM没收到abort请求而自行提交了，那么就和其他RM出现数据不一致
- 柔性事务：分为通知型和补偿型两种。通知型是异步的，补偿型是同步的
	- 通知型事务主流实现是通过MQ通知其他事务参与者，它适合需要异步更新数据，并且对数据的实时性要求较低的场景
		- 异步确保型
			- MQ事务消息方案：对于支持半消息机制的MQ，可以用这个方案，它保证了本地事务和发消息两步操作的原子性。例如订单系统和邮件系统
				1. 订单系统先向MQ发送一个半消息
				2. 然后订单系统执行本地事务
					1. 如果执行成功，向MQ发送commit，MQ真正投递消息，对消费者可见
					2. 执行失败，向MQ发送rollback，消息被丢弃
				3. MQ还有反查机制，不断查询订单系统的事务执行状态，避免订单系统挂掉等问题
				4. 邮件系统收到消息后，执行自己的事务，完成后向MQ发送ACK
			- 本地消息表方案：对于不支持半消息机制的MQ，就需要这个方案。
				1. 订单系统在执行本地事务时，往本地消息表插入一条待发送的记录。
				2. 事务执行成功，则发送消息，发送成功把本地消息表状态改成已发送。
				3. 如果发消息失败，也没关系，有一个兜底定时任务，不断捞起本地消息表待发送的消息，重新发送。
				4. 邮件系统收到消息后（需要幂等处理），执行自己的事务。
					- 可选：成功后，可以用订单系统的接口把消息状态改成已消费。
					- 可选：如果失败，可以用订单系统的接口把消息状态改成失败，订单系统定时任务发现后做回滚操作。
			- 对比：本地消息表方案相比于MQ事务消息方案，不需要实现反查逻辑，减少了业务侵入。但是它需要额外的数据库操作，有一定的性能损耗，定时任务也加大了实现复杂度、和重复消息的可能性。
		- 最大努力通知：应用于跨企业对接场景，例如支付平台和外部运营商。它也类似于本地消息表方案：
			1. 发起方执行本地事务，并写入本地消息表
			2. 向接收方（HTTP/RPC/MQ）发送请求，得到明确的成功响应后，将本地消息表置为成功，流程结束
				- 没有得到明确成功或超时，将本地消息表置为失败，进入重试流程
				- 用一个定时任务，把失败的消息捞起来，按照退避策略进行重试，达到最大次数后把状态改成重试失败，不再重试。
			3. 接收方收到请求后，执行本地事务，成功后向接收方返回成功。接收方需要处理幂等问题
			4. 兜底策略：
				- 重试失败的消息，需要人工介入
				- 发送方也需要提供查询接口，让接收方能够主动查询，双向保证
	- 补偿型事务：通知型事务不能解决如支付+库存这种两个都成功或两个都失败的场景。而补偿型事务通过引入协调者作为事务的发起方和其他服务的调用者；当事务出现问题时，协调者调用其他服务的补偿操作（即回滚）从逻辑上取消上一个操作的影响。它将长事务分解成一个个短事务，以应对高并发需求。
		- TCC：适合核心业务、短事务、高并发。实现比较复杂，业务侵入性高
			- 它有三个角色：发起人，参与者，事务协调器
			- 它有三个阶段：
				1. Try阶段：协调器调用参与者的Try接口，参与者预留资源，先不执行实际操作
				2. Confirm阶段：当所有参与者Try都成功时，协调器调用参与者的Confirm接口执行实际的业务。如果调用失败，会一直重试直到人工介入
				3. Cancel阶段：当有参与者Try失败或超过重试次数时，协调器调用已完成Try的参与者的Cancel接口回滚资源。如果调用失败，会一直重试直到人工介入
			- 核心要点：
				- 强一致性：要么都成功，要么都失败
				- 无锁设计：无分布式层面的长锁（例如2PC），非无本地事务锁
				- 幂等性
				- 防悬挂
				- 防单点故障：事务日志、协调器集群部署、定时任务兜底
				- 业务侵入性强
				- 适合短事务：长事务场景（如跨天的订单处理）则会导致预留资源浪费
		- SAGA：
			- 它把一个分布式事务拆分为多个本地事务，每个本地事务都有相应的执行和补偿方法（对应TCC中的Confirm和Cancel）。当Saga事务中任意一个本地事务出错时，可以通过调用相关的补偿方法恢复之前的事务，达到最终一致性。
			- 实现方案：
				- 去中心化：依赖MQ。
					- 优点：架构简单，无协调器单点故障，各系统解耦，适合短事务数量少（3 个以内）的场景。
					- 缺点：耦合度高，每个参与者需要知道下一个参与者的执行消息格式，和上一个参与者的补偿消息格式 优点；难以扩展。
				- 中心化：类似于TCC，有一个协调器作为发起人和调用者
			- 它相比于TCC更适合长流程（如跨天的供应链审批）的事务，并且业务入侵度低，不需要实现Try接口。
				- 但是它要求事务是可以补偿的；并且它是最终一致性，有中间状态，不适合强一致性场景
				- 强一致性说明：注意，TCC的强一致性是业务层面的强一致性，它的中间状态是技术层面的预留态；而SAGA的中间状态是业务层面的已提交态，对业务可见，所以它是最终一致性。

---
# 6 引用
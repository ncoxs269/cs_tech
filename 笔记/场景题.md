2025-05-11 16:49
Status: #idea
Tags:

# 1 海量数据处理
## 1.1 TOP K 问题
### 1.1.1 10亿个数据中找出最大的10000个
#### 1.1.1.1 最小堆法
1. 先拿10000个数建堆
2. 然后逐个添加剩余元素
3. 如果大于堆顶的数（10000中最小的），将这个数替换堆顶，并调整结构使之仍然是一个最小堆
4. 遍历完后，堆中的10000个数就是所需的最大的10000个。

复杂度分析：时间复杂度是 O(nlogk)，空间复杂度 O(k)。

#### 1.1.1.2 优化
##### 1.1.1.2.1 并行计算
可以通过并行计算（多线程或者分布式运算）的方式进一步提高算法效率：
1. 通过Hash方法将n个数据随机切分成m份，需要的时间复杂度为 O(n)
2. 对于m份数据并行使用小顶堆选出最大的k个数据，需要的时间复杂度为 O(n/m\*logk) （因为是并行的），运算完后得到m组长度为k的小顶堆
3. 最后在合并节点上，同样使用大小为k的最小堆，将所有候选数依次插入堆中。最终堆中的k个数就是全局前k大的数

由于第二步和第三步可以并行计算，因此总的时间复杂度为：
$$
O(n + \frac{n}{m}\log_2k + mk\log_2k)
$$
对比没有并行的小顶堆算法，可以发现算法得到了常数级别的优化。

##### 1.1.1.2.2 数据倾斜
该方法存在一个瓶颈会明显影响效率，即数据倾斜。每个线程的处理速度可能不同，快的线程需要等待慢的线程，最终的处理速度取决于慢的线程。
解决的方法是，将数据划分成c×n个partition（c>1），每个线程处理完当前partition后主动取下一个partition继续处理，直到所有数据处理完毕。

### 1.1.2 有几台机器存储着几亿淘宝搜索日志，你只有一台 2g 的电脑，怎么选出搜索热度最高的十个？
针对top k类文本问题，通常比较好的方案是【**分治+trie树/hash+小顶堆**】，即
1. 先将数据集按照hash方法分解成多个小数据集
2. 然后使用trie树或者hash统计每个小数据集中的query词频
3. 之后用小顶堆求出每个数据集中出频率最高的前K个数
4. 最后用小顶堆在所有top K中求出最终的top K。

注意，如果总的不重复key比较少，并且key长度不长（1G约为10.7亿字节），那么就不用拆分，直接一个hash表就能装下。
可以看到，这个是 topK 问题的变种。只需要先预处理一下，求出每个key的频率，然后针对频率求 topK 即可。

### 1.1.3 100GB日志文件，存储滴滴下单的记录，每条记录包含司机ID和订单ID。求下单数量前10的司机
也是 topK 的变种。预处理如下：
1. 先将数据集按照hash方法（hash司机ID）分解成多个小数据集
2. 统计小数据集中，每个司机的订单数
3. 然后就是 topK问题了

### 1.1.4 从十亿数据中找到升序的第七亿个数
#### 1.1.4.1 快排
1. 随机挑一个元素作为基准值，将数据partition为`[left,mid-1]`和`[mid,right]`两个区间，其中`[left,mid-1]`的数都小于base值，`[mid,right]`都大于等于base值
2. 计算`[mid, right]`数组长度L：  
	- 如果L等于三亿，那么`[left,mid-1]`中的七亿个数字小于`[mid,right]`中的三亿个数字，只需要在`[left,mid-1]`中找到最大值即可
	- 如果L大于三亿，则将问题转化为在`[mid, right]`中找到第（L-三亿）个数
	- 如果L小于三亿则问题还是在`[left,mid-1]`中找到第七亿大的数

#### 1.1.4.2 桶排序
假如数据的范围是有限的（有最大值和最小值）且较均匀分布，那么使用桶排序可以进一步提升效率：
1. 获取数据的max和min
2. 将所有的n份数据分到m个文件中，同时记录每份子文件中的数据量
3. 从小到大累加文件数据量，找到第七亿个数所在的文件，记录前面文件的总数据量count
4. 将问题转化为在第七亿个数所在的文件中寻找第（七亿-count）个数

## 1.2 海量数据排序、去重问题
### 1.2.1 对十亿数据进行排序
使用多路归并排序：
1. 分割文件和小文件排序：将大文件中的n个数据分散到k个小文件中，对每一个小文件进行内存排序。时间复杂度 O(n + n/k\*log(n/k))
2. 多路归并排序，时间复杂度 O(nlogk)
	1. 读取每个有序文件中的第一个数（即该文件的最小数）及其文件索引，存放在大小为k的小根堆中。
	2. 取出小根堆中的根节点写入缓冲区（缓冲区满自动写入目标文件），同时读取根节点索引对应的小文件下一个数作为新的根节点，调整小根堆
	3. 重复step2，如果某个小文件为空则小根堆长度减一，直到取出所有的小文件中的数

### 1.2.2 对10亿数进行去重
#### 1.2.2.1 分片哈希去重
1. 使用均匀分布的哈希函数（如MD5、SHA-1或自定义哈希），将每条数据映射到固定数量的分片中。确保每个分片都能装入内存
2. 每个分片，使用hash表去重，结果写入最终输出文件

#### 1.2.2.2 位图
如果数字非负，并且范围不大，可以用bitmap。

#### 1.2.2.3 simhash
https://cloud.tencent.com/developer/article/1379302?from=14588

# 2 并发
## 2.1 如果一个外卖配送单子要发布，现在有200个骑手都想要接这一单，如何保证只有一个骑手接到单子？
- redis分布式锁
- mysql悲观锁、乐观锁

## 2.2 1000个任务分给10个人做
全局队列，每一个人都从一个队列中取一部分任务。
同时每个人自己有个队列。

# 3 中间件
### 3.1.1 如何用redis存储统计1亿用户一年的登陆情况，并快速检索任意时间窗口内的活跃用户数量
redis单独对bitmap提供了一套命令。可以对任意一位进行设置和读取。所以可以在位图中使用1表示活跃。
- `SETBIT`：设置某位为1
- `GETBIT`：获取某位的值
- 其他命令还有`bitcount，bitpos，bitop`等

因此问题可以拆解为：
1. 获取某一天id为88000的用户是否活跃：`getbit 2020-01-01 88000`。时间复杂度为O(1)
2. 统计某一天的所有的活跃用户数：`bitcount 2019-01-01`。时间复杂度为O(N)
3. 统计某一段时间内的活跃用户数，需要用到 `bitop` 命令。这个命令提供四种位运算，AND(与)，(OR)或，XOR(亦或)，NOT(非)。我们可以对某一段时间内的所有key进行OR(或)操作，或操作出来的位图是0的就代表这段时间内一次都没有登陆的用户。那只要我们求出1的个数就可以了

以下例子求出了2019-01-01到2019-01-05这段时间内的活跃用户数：
```bash
bitop or result 2019-01-01 2019-01-02 2019-01-03 2019-01-04 2019-01-05
bitcount result
```

# 4 做事思路
## 4.1 指标下降排查思路
假设你接手一个项目，它是用深度学习算法和人工规则去巡检各个垂类（鞋、服装等）下是否有重复的商品。去年已经达到标准了，算法没有迭代，经过一年发现指标下降了，很多重复商品没发现，导致运营工作量大增。那么你立即会怎么做，然后再怎么安排呢？
面试官说，首先要收集bad case，例如最近错判的几千条数据，分析有哪些问题
- 我讲的是排查有什么问题，但面试官关注的是我怎么做事的流程

面试官的核心考察点是：
1. 问题解决的 **结构化思维**（是否分优先级、分阶段）；
2. **落地能力**（是否有可执行的动作，而非空泛理论）；
3. **全链路视角**（是否覆盖数据、算法、规则、工程、运营协同）；
4. **风险意识**（是否先缓解紧急压力，再根治问题）。

因此，需要 **“紧急止血→根因定位→迭代优化→长期保障” 四阶段闭环流程**，每个阶段都有具体落地动作和逻辑拆解。

### 4.1.1 第一阶段：紧急止血（0-3 天）—— 先缓解运营压力，避免问题扩大
核心目标：**快速降低漏判率，减少运营重复工作量**，同时同步收集 bad case，为后续分析打基础。
具体动作：
1. **定向收集 bad case，建立临时标注库**
	- 例如最近错判的几千条数据，分析有哪些问题
	- 来源：运营反馈的漏判商品列表、系统日志中 “疑似重复但未命中” 的记录、用户投诉 / 退货数据中关联的重复商品；
	- 标注：组织运营 / 数据团队快速标注（3 天内完成至少 3000 条），标注维度包括：
	    - 重复类型（同图同款、同款不同图、相似设计、文本描述一致但图片不同等）；
	    - 垂类（鞋、服装、箱包等，明确是否集中在某类）；
	    - 漏判场景（是否是新商品类型、促销活动商品、跨境商品等）；
	- 用途：临时筛选高频漏判模式，为快速调整规则提供依据。
2. **临时强化人工规则，快速补漏**
	- 基于 bad case 的高频模式，紧急新增 / 修改人工规则（见效最快）：
		- 例：若发现 “服装类同款不同色号” 漏判，新增规则 “商品标题包含同款色号关键词 + 主图特征相似度≥90%→判定重复”；
		- 例：若发现 “跨境商品 SKU 格式变化导致规则失效”，修改规则 “SKU 去除地域后缀后匹配→触发重复校验”；
	- 规则优先级调整：将临时规则设为最高优先级，绕过部分深度学习模型的低置信度结果（避免模型漏判）。
3. **扩容人工审核资源，分流压力**
	- 协调运营团队临时扩容审核人员，或启用外包资源，聚焦 “高风险场景”（如近期新增的垂类、促销商品池）；
	- 搭建临时反馈通道：运营审核时可一键标记 “漏判 / 误判”，实时同步到标注库，形成数据回流。
4. **临时关闭低质量数据输入**
    - 若发现漏判集中在 “非官方渠道商品”“图片模糊商品”，临时限制这类商品的上架速度，或强制要求补充清晰信息后再进入巡检流程，减少无效漏判。

### 4.1.2 第二阶段：根因定位（3-7 天）—— 基于 bad case 深析，找到指标下降的核心原因
核心目标：**不局限于 “表面漏判”，挖掘 “为什么算法 / 规则会失效”**，避免 “头痛医头”。需结合 “深度学习 + 人工规则” 的混合架构，从「数据、算法、规则、工程」四个维度拆解（面试官要的 “分析问题”，本质是 “分类归因”）。
具体动作：
1. **数据层分析：是否是输入数据分布发生变化？（最常见原因）**
	- 对比去年 vs 今年的商品数据分布：
	    - 垂类结构：是否新增了新垂类（如去年无 “露营装备”，今年新增且漏判集中）；
	    - 特征分布：图片（是否更多 AI 生成图、模糊图）、文本（标题 / 描述是否新增大量网络热词、缩写）、属性（SKU 格式、规格参数是否变化）；
	    - 重复模式：是否出现新的重复手段（如商家刻意修改 SKU 后缀、更换主图但细节图一致）；
	- 结论：若数据分布漂移（如新增垂类占比达 20% 且未被模型 / 规则覆盖），则是 “数据适配问题”。
2. **算法层分析：是否是模型泛化能力不足？**
	- 用 bad case 测试模型：看模型对漏判商品的预测置信度（若置信度低于阈值，说明模型没学到这类模式；若置信度高但判断错误，可能是标注噪声）；
	- 对比模型版本：去年达标后是否有间接改动（如特征工程代码重构、模型部署时参数调整）；
	- 模型局限性：是否是模型本身缺陷（如原模型基于图片特征，对 “同款不同图” 的文本相似商品漏判）；
	- 结论：若模型在旧数据上仍达标，但新 bad case 上表现差，则是 “模型泛化能力不足”。
3. **规则层分析：是否是人工规则失效或冲突？**
	- 校验规则执行日志：看是否有规则被绕过、执行顺序变化（如原 “SKU 匹配优先” 改为 “图片匹配优先”，导致部分重复商品漏判）；
	- 规则覆盖度：用 bad case 反向验证规则（如 1000 条漏判中，800 条未命中任何人工规则，说明规则覆盖不足）；
	- 规则冲突：是否存在 “规则 A 判定重复，规则 B 判定不重复” 的矛盾场景（如跨境商品的地域规则与同款规则冲突）；
	- 结论：若规则未覆盖新重复模式或存在冲突，则是 “规则失效问题”。
4. **工程层分析：是否是系统执行链路出问题？**
    - 检查数据输入：是否有数据传输错误（如商品图片未同步、文本特征提取失败）；
    - 检查执行逻辑：是否有代码 bug（如规则引擎版本升级导致部分规则不生效、模型推理接口超时未重试）；
    - 检查监控告警：为什么指标下降一年才发现？是否缺乏实时监控（如召回率、漏判率的日报 / 周报）；
    - 结论：若数据输入异常或执行逻辑 bug，则是 “工程落地问题”。
5. **跨团队确认：是否是业务规则变化？**
    - 与运营确认：是否调整了 “重复商品” 的定义（如去年 “同款不同色” 算重复，今年不算；或反之）；
    - 与产品确认：是否新增了业务逻辑（如允许 “官方店 + 经销商店” 同时上架同款，导致原规则误判）。

最终输出：**根因归因报告**（如 “70% 漏判源于新垂类数据分布漂移，20% 源于规则未覆盖‘同款不同图’场景，10% 源于模型对 AI 生成图特征提取不足”）。

### 4.1.3 第三阶段：迭代优化（2-4 周）—— 按优先级解决，快速见效 + 长期优化
核心目标：**先解决高频问题（快速降本），再优化深层问题（稳定指标）**，结合 “规则 + 算法” 协同优化（避免单一依赖）。
具体动作（按优先级排序）：
1. **优先级 1：修复规则层问题（1 周内完成）**
    - 新增规则：基于 bad case 的高频漏判模式，补充 “新垂类规则”“AI 生成图规则”“文本相似规则” 等；
    - 优化规则：合并冲突规则，调整执行顺序（如 “先文本 + 属性匹配，再图片匹配”）；
    - 灰度发布：新规则先在小流量（10% 商品池）验证，监控漏判率 / 误判率，无问题后全量上线。
2. **优先级 2：数据层修复与补充（1-2 周）**
    - 数据清洗：过滤低质量数据（如模糊图、缺失关键属性的商品），补充新垂类的标注数据；
    - 特征增强：针对新数据分布，新增特征（如 AI 生成图的纹理特征、跨境商品的地域特征、文本的语义向量特征）。
3. **优先级 3：算法模型迭代（2-4 周）**
    - 增量训练：用新补充的标注数据（bad case + 新垂类数据）对原模型进行增量训练（避免全量训练的成本和风险）；
    - 模型微调：若原模型是深度学习模型（如 CNN+Transformer），可冻结底层参数，只微调顶层分类器（适配新数据分布）；
    - 混合架构优化：将规则判定为 “疑似重复” 的商品，送入模型二次校验（提升召回率）；将模型高置信度的重复商品，直接判定（减少规则冗余）。
4. **优先级 4：工程层优化（同步进行）**
    - 修复 bug：解决数据传输、规则执行逻辑中的问题；
    - 优化性能：确保模型推理、规则匹配的响应时间（避免影响商品上架效率）；
    - 完善监控：新增 “漏判率、误判率、规则命中数、模型置信度分布” 的实时监控看板，设置阈值告警（如漏判率 > 5% 立即通知）。
5. **验证效果：**
    - 离线验证：用标注好的 bad case 和测试集验证，确保漏判率降至目标水平（恢复 80%+）；
    - 在线灰度：全量上线前，在 30% 商品池试运行 1-2 天，收集运营反馈，确认无明显问题后全量发布。

### 4.1.4 第四阶段：长期保障（持续进行）—— 避免指标再次退化
核心目标：**建立 “监控 - 反馈 - 迭代” 的闭环，让系统具备自适应性**，不再出现 “一年后才发现指标下降” 的情况。
具体动作：
1. **建立常态化监控体系**
    - 核心指标：召回率、精确率、漏判率、误判率（按垂类、商品类型拆分）；
    - 辅助指标：规则命中数、模型置信度分布、数据分布漂移度（如特征均值变化率）；
    - 告警机制：指标异常（如漏判率突升 5%）、数据漂移超阈值（如新增垂类占比超 10%）、规则失效（某规则命中数骤降 90%）时，实时通知负责人。
2. **数据回流与迭代机制**
    - 每日收集运营反馈的 bad case，自动同步到标注库；
    - 每月进行一次小迭代：用新增标注数据微调模型、补充规则；
    - 每季度进行一次大复盘：分析数据分布变化、业务规则调整，评估模型 / 规则的适配性，必要时进行模型重构或规则体系升级。
3. **业务协同机制**
    - 与运营 / 产品建立月度沟通会：提前同步新业务规划（如新增垂类、调整重复定义），预留优化时间；
    - 建立规则 / 模型文档库：记录规则逻辑、模型版本、迭代历史，避免人员变动导致知识断层。
4. **容灾与备份**
    - 保存历史模型版本和规则配置：若新迭代出现问题，可快速回滚；
    - 定期进行压力测试：确保系统在商品量激增（如大促）时，指标不退化。

### 4.1.5 面试回答总结（结构化表述，突出逻辑和落地性）
首先，我会做一些止损的操作：
1. 我会先拉bad case，例如收集几千条漏判的商品，看看它们都有什么特征。例如属于什么垂类、是不是新商品促销商品、图片文本有什么特点之类的。
2. 然后基于上面分析的特征，紧急新增、调整人工规则，先把高风险、指标下降地很多的给解决了
3. 还有看看能不能扩容运营的资源，尤其是对一些高风险、高优的商品垂类

当止损差不多后，就要抽出人力进行根因定位了。因为这是个深度学习和人工规则结合的系统，所以要结合着止损收集的信息、从很多方面去看一下：
1. 数据层面：对比去年 vs 今年的商品特征分布，看看是不是新的重复模式的问题；
2. 算法层面：用 bad case 测试模型，看看它是不是能力下降了，还是有什么别的缺陷（例如对图片识别比较好）
3. 人工规则层面：结合bad case，看看哪里有缺失或者bug

根因定位后，最后做个总结，看看问题的分布情况，例如算法层面占比多少。根据占比的情况决定修复的优先级。

最后，就是针对一年都没发现的情况，需要建立监控和迭代的机制。及时发现指标下降的问题，第一时间解决；每月每季度复盘bad case，针对性地做优化。

### 4.1.6 面试官可能追问的延伸点（提前准备）
1. 若 bad case 标注量不足，怎么快速优化？
    - 用 “弱监督学习”：基于现有规则和模型高置信度结果，自动标注部分数据；
    - 优先处理高频场景：比如先解决服装类的漏判，再逐步覆盖其他垂类。
2. 怎么平衡召回率和精确率？（比如提升召回率后，误判率上升怎么办？）
    - 分场景设置阈值：核心垂类（如品牌旗舰店商品）优先保证召回率，长尾商品优先控制精确率；
    - 二次校验：模型 / 规则判定为重复的商品，高置信度直接通过，低置信度送入人工审核。
3. 若团队没有算法资源，怎么优化？
    - 重点强化规则体系：通过 “规则模板 + 正则匹配 + 特征组合” 覆盖大部分场景；
    - 引入第三方工具：如调用成熟的图片相似度接口、文本语义匹配接口，补充规则能力。
4. 为什么指标下降了一年才发现？怎么避免？
    - 核心问题是缺乏实时监控和定期复盘；
    - 长期解决方案是建立 “指标看板 + 阈值告警 + 季度复盘” 机制，让问题早发现、早处理。

# 5 常用代码技术点
## 5.1 怎么实现接口的延迟调用
注意是**延迟**，不是**延时**。
在 Golang 中实现接口的延迟调用，核心是将接口方法的调用逻辑封装起来（不立即执行），待后续指定时机（如异步处理、条件满足、批量执行时）再触发执行。

一个方案是闭包，适合已知接口 / 方法的场景，编译期就能做类型检查，无运行时风险，性能也更高。
```go
package main

import "fmt"

// 1. 定义示例接口
type Calculator interface {
	Add(a, b int) int
	Multiply(a, b int) int
}

// 2. 实现接口的结构体
type BasicCalculator struct{}

func (bc BasicCalculator) Add(a, b int) int {
	fmt.Println("执行Add方法（闭包版）")
	return a + b
}

func (bc BasicCalculator) Multiply(a, b int) int {
	fmt.Println("执行Multiply方法（闭包版）")
	return a * b
}

// 3. 定义延迟调用函数类型（按需封装返回值）
type DelayCallFunc func() int

func main() {
	// 初始化接口实例
	calc := BasicCalculator{}

	// 4. 封装延迟调用逻辑（闭包捕获参数和实例，不立即执行）
	var delayAdd DelayCallFunc = func() int {
		return calc.Add(3, 5) // 绑定参数：3和5
	}

	// 模拟「延迟」：先执行其他业务逻辑
	fmt.Println("执行前置业务逻辑...")

	// 5. 触发延迟调用（真正执行Add方法）
	result := delayAdd()
	fmt.Println("Add调用结果：", result)

	// 同理封装Multiply的延迟调用
	var delayMultiply DelayCallFunc = func() int {
		return calc.Multiply(4, 6)
	}
	fmt.Println("执行更多前置逻辑...")
	result2 := delayMultiply()
	fmt.Println("Multiply调用结果：", result2)
}
```

另一种是反射实现，适合通用化的延迟调用组件（如框架、中间件），但有运行时类型检查和性能开销（大概是10-100倍）。
```go
package main

import (
	"fmt"
	"reflect"
)

// 1. 复用上述Calculator接口和BasicCalculator实现

// 2. 定义延迟调用上下文结构体：保存接口实例、方法名、参数
type DelayCall struct {
	instance reflect.Value  // 接口实例的反射值
	method   string         // 要调用的方法名
	args     []reflect.Value // 方法参数的反射值切片
}

// 3. 构造延迟调用实例（入参：接口实例、方法名、方法参数）
func NewDelayCall(instance interface{}, method string, args ...interface{}) *DelayCall {
	// 将普通参数转换为reflect.Value切片
	argValues := make([]reflect.Value, len(args))
	for i, arg := range args {
		argValues[i] = reflect.ValueOf(arg)
	}

	return &DelayCall{
		instance: reflect.ValueOf(instance),
		method:   method,
		args:     argValues,
	}
}

// 4. 执行延迟调用（返回方法结果和错误）
func (dc *DelayCall) Call() (interface{}, error) {
	// 获取接口方法的反射值
	method := dc.instance.MethodByName(dc.method)
	if !method.IsValid() {
		return nil, fmt.Errorf("方法 %s 不存在或未导出（首字母需大写）", dc.method)
	}

	// 检查参数数量匹配
	if method.Type().NumIn() != len(dc.args) {
		return nil, fmt.Errorf("参数数量不匹配：期望 %d 个，实际 %d 个", method.Type().NumIn(), len(dc.args))
	}

	// 执行方法调用
	results := method.Call(dc.args)
	if len(results) == 0 {
		return nil, nil // 无返回值
	}

	// 返回方法的第一个返回值（示例中方法仅一个返回值）
	return results[0].Interface(), nil
}

func main() {
	// 初始化接口实例
	calc := BasicCalculator{}

	// 构造延迟调用：Add(3,5)
	delayAdd := NewDelayCall(calc, "Add", 3, 5)

	// 模拟延迟：执行其他逻辑
	fmt.Println("执行前置业务逻辑（反射版）...")

	// 触发延迟调用
	result, err := delayAdd.Call()
	if err != nil {
		fmt.Println("调用失败：", err)
		return
	}
	fmt.Println("Add调用结果（反射）：", result)

	// 构造Multiply的延迟调用
	delayMultiply := NewDelayCall(calc, "Multiply", 4, 6)
	fmt.Println("执行更多前置逻辑（反射版）...")
	result2, err := delayMultiply.Call()
	if err != nil {
		fmt.Println("调用失败：", err)
		return
	}
	fmt.Println("Multiply调用结果（反射）：", result2)
}
```

## 5.2 A服务调B服务，给B服务的处理时间只有200ms，怎么实现？
可以用context的取消，并且取消操作写在 B 里。
超时的 “触发” 在 A 侧，但超时的 “响应与终止” 必须在 B 侧。因为若仅 A 侧超时后放弃结果，B 侧会继续执行耗时操作（如数据库查询、复杂计算），高并发下会导致 B 服务资源耗尽（CPU / 内存飙升）。

## 5.3 用户请求量突增，如果无脑开协程处理请求，会有什么问题？怎么限制并发数？
无脑创建 goroutine 会导致：
1. 内存溢出（每个 goroutine 默认栈 2KB，大量 goroutine 会吃光内存）；
2. 协程调度压力会很大，服务响应延迟飙升甚至 OOM。

可以用协程池，下面是极简 goroutine 池，面试可手写：
```go
package main

import (
	"fmt"
	"sync"
	"time"
)

// 任务结构体
type Task struct {
	ID  int
	Do  func()
}

// Goroutine池
type GoroutinePool struct {
	taskChan chan Task
	wg       sync.WaitGroup
}

// 初始化池：workerNum是并发数，taskCap是任务队列容量
func NewGoroutinePool(workerNum, taskCap int) *GoroutinePool {
	pool := &GoroutinePool{
		taskChan: make(chan Task, taskCap),
	}
	// 启动固定数量的worker
	for i := 0; i < workerNum; i++ {
		pool.wg.Add(1)
		go func(workerID int) {
			defer pool.wg.Done()
			for task := range pool.taskChan {
				fmt.Printf("worker%d处理任务%d\n", workerID, task.ID)
				task.Do()
			}
		}(i)
	}
	return pool
}

// 提交任务
func (p *GoroutinePool) Submit(task Task) {
	p.taskChan <- task
}

// 关闭池
func (p *GoroutinePool) Close() {
	close(p.taskChan)
	p.wg.Wait()
}

func main() {
	// ToC场景：限制并发数为10（根据服务器配置调整）
	pool := NewGoroutinePool(10, 100) // 10个worker，队列容量100
	defer pool.Close()

	// 模拟100个用户请求（任务）
	for i := 0; i < 100; i++ {
		pool.Submit(Task{
			ID: i,
			Do: func() {
				time.Sleep(100 * time.Millisecond) // 模拟业务处理
			},
		})
	}
}
```

## 5.4 调用第三方服务偶尔失败，怎么处理？重试会不会导致重试风暴？
重试注意最大重试次数和指数退避（2^i * 100ms，加随机值避免重试风暴）。之所以用指数退避，是因为它能应对 “瞬时网络抖动” 和 “服务重度故障” 两种场景。
- 瞬时网络抖动：重试一两次马上能成功
- 服务重度故障：若服务需要 1 秒甚至更久恢复，固定间隔的重试会持续 “轰炸” 故障服务，不仅成功率极低（无效重试），还会占用本地资源

下面是代码实现：
```go
package main

import (
	"context"
	"fmt"
	"math/rand"
	"time"
)

// 重试函数：带context控制超时，指数退避避免风暴
func retryWithBackoff(ctx context.Context, maxRetry int, fn func() error) error {
	var err error
	for i := 0; i < maxRetry; i++ {
		select {
		case <-ctx.Done():
			return fmt.Errorf("重试超时: %w", ctx.Err())
		default:
			err = fn()
			if err == nil {
				return nil // 成功则返回
			}
			// 指数退避：2^i * 100ms，加随机值避免重试风暴
			backoff := time.Duration(1<<i)*100*time.Millisecond + time.Duration(rand.Intn(100))*time.Millisecond
			fmt.Printf("第%d次重试失败，等待%v后重试，错误：%v\n", i+1, backoff, err)
			time.Sleep(backoff)
		}
	}
	return fmt.Errorf("重试%d次后仍失败：%w", maxRetry, err)
}

// 模拟调用第三方短信服务
func sendSms() error {
	// 模拟10%的失败率
	if rand.Float64() < 0.1 {
		return fmt.Errorf("短信服务瞬时不可用")
	}
	fmt.Println("短信发送成功")
	return nil
}

func main() {
	rand.Seed(time.Now().UnixNano())
	// ToC场景：重试3次，总超时3秒（用户可接受）
	ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
	defer cancel()

	err := retryWithBackoff(ctx, 3, sendSms)
	if err != nil {
		fmt.Println("最终失败：", err)
		// ToC降级：记录日志，给用户推送站内信
	}
}
```

# 6 其他知识
## 6.1 499状态码是什么
499是nginx记录的状态码。499产生的核心原因是**客户端在nginx完成响应之前断开了连接**。
- 可以不太严谨的概括就是**nginx完成的响应时间超过了客户端的超时时间。** 
- 如果客户端在nginx处理请求这个区间内，断开了连接，那么nginx就会返回499


---
# 7 引用
[499状态码](https://blog.csdn.net/weixin_40619578/article/details/133646797)
[redis库存设计](https://www.cnblogs.com/JavaEdge/p/18381724)
[秒杀系统设计](https://cloud.tencent.com/developer/article/1863530)
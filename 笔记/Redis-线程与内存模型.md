2025-04-30 11:39
Status: #idea
Tags: [[Redis]]


# 1 Redis 单线程
“为什么单线程的 Redis 能那么快？”
我们通常说，**Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程**。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。
所以，严格来说，Redis 并不是单线程，但是我们一般把 Redis 称为单线程高性能，这样显得“酷”些。

## 1.1 Redis 为什么用单线程？
一个关键的瓶颈在于，**系统中通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构**。这就是多线程编程模式面临的共享资源的并发访问控制问题。
为了避免这些问题，Redis 直接采用了单线程模式。

## 1.2 单线程 Redis 为什么那么快？
一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。另一方面，就是 Redis 采用了**多路复用机制**，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。

### 1.2.1 基本 IO 模型与阻塞点
以 Get 请求为例，为了处理一个 Get 请求，需要监听客户端请求（`bind/listen`），和客户端建立连接（`accept`），从 socket 中读取请求（`recv`），解析客户端发送请求（`parse`），根据请求类型读取键值数据（`get`），最后给客户端返回结果，即向 socket 中写回数据（`send`）。
其中，`bind/listen`、`accept`、`recv`、`parse` 和 `send` 属于网络 IO 处理，而 `get` 属于键值数据操作。既然 Redis 是单线程，那么，最基本的一种实现是在一个线程中依次执行上面说的这些操作。

**在这里的网络 IO 操作中，有潜在的阻塞点，分别是 `accept()` 和 `recv()`**。当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 `accept()` 函数这里，导致其他客户端无法和 Redis 建立连接。类似的，当 Redis 通过 `recv()` 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 `recv()`。

### 1.2.2 非阻塞模式
在 socket 模型中，不同操作调用后会返回不同的套接字类型：
1. `socket()` 方法会返回主动套接字；
2. 然后调用 `listen()` 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。
3. 最后，调用 `accept()` 方法接收到达的客户端连接，并返回已连接套接字。

针对监听套接字，我们可以设置非阻塞模式：当 Redis 调用 `accept()` 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。
类似的，我们也可以针对已连接套接字设置非阻塞模式：Redis 调用 `recv()` 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。

虽然 Redis 线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知 Redis。

### 1.2.3 基于多路复用的高性能 I/O 模型
Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 **`select/epoll` 机制**。
该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。
![[image-119.png]]

为了在请求到达时能通知到 Redis 线程，**`select/epoll` 提供了基于事件的回调机制**，一旦监测到 FD 上有请求到达时，就会触发相应的事件，调用相应的处理函数。
这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。

# 2 性能瓶颈和解决
Redis单线程处理IO请求性能瓶颈主要包括2个方面：
1. **耗时操作**：任意一个请求在 server 中一旦发生耗时，都会影响整个 server 的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：
    1. **操作 bigkey**：写入一个 bigkey 在分配内存时需要消耗更多的时间，同样，删除 bigkey 释放内存同样会产生耗时；
    2. **使用复杂度过高的命令**：例如 `SORT/SUNION/ZUNIONSTORE`，或者O(N)命令，但是 N 很大，例如`lrange key` 0 -1一次查询全量数据；
    3. **大量 key 集中过期**：Redis 的过期机制也是在主线程中执行的，大量 key 集中过期会导致处理一个请求时，耗时都在删除过期 key，耗时变长；
    4. **淘汰策略**：淘汰策略也是在主线程执行的，当内存超过 Redis 内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；
    5. **AOF 刷盘开启 always 机制**：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；
    6. **主从全量同步生成 RDB**：虽然采用 fork 子进程生成数据快照，但 fork 这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；
2. **并发量非常大时**，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。
    
针对问题 1，一方面需要业务人员去规避，一方面 Redis 在 4.0 推出了 lazy-free 机制，把 bigkey 释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。
针对问题 2，Redis 在 6.0 推出了多线程，可以在高并发场景下利用 CPU 多核多线程读写客户端数据，进一步提升 server 性能，当然，**只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的**。

## 2.1 惰性删除
Redis 主线程启动后，会使用操作系统提供的 `pthread_create` 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。
主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。
等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。因此，我们把这种异步删除也称为**惰性删除（lazy free）**。

这里有个地方需要你注意一下，异步的键值对删除和数据库清空操作（例如 `FLUSHDB` 和 `FLUSHALL` 操作）是 Redis 4.0 后提供的功能，Redis 也提供了新的命令来执行这两个操作。
- 键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使用 `UNLINK` 命令。
	- Redis 6.0又提供一个选项：lazyfree-lazy-user-del。 打开这个选项后，使用DEL和UNLINK就没有区别了。
- 清空数据库：可以在 `FLUSHDB` 和 `FLUSHALL` 命令后加上 `ASYNC` 选项，这样就可以让后台子线程异步地清空数据库。

手动开启lazy-free时，有4个选项可以控制，分别对应不同场景下，要不要开启异步释放内存机制：
1. lazyfree-lazy-expire：key在过期删除时尝试异步释放内存
2. lazyfree-lazy-eviction：内存达到maxmemory并设置了淘汰策略时尝试异步释放内存
3. lazyfree-lazy-server-del：执行RENAME/MOVE等命令或需要覆盖一个key时，删除旧key尝试异步释放内存
4. replica-lazy-flush：主从全量同步，从库清空数据库时异步释放内存

需要注意的是，**开启lazy-free的场景，除了replica-lazy-flush之外，其他情况都只是可能去异步释放key的内存，并不是每次必定异步释放内存的**。开启lazy-free后，Redis在释放一个key的内存时，首先会评估代价，如果释放内存的代价很小，那么就直接在主线程中操作了，没必要放到异步线程中执行（不同线程传递数据也会有性能消耗）。
什么情况才会真正异步释放内存？这和key的类型、编码方式、元素数量都有关系：
- 当Hash/Set底层采用哈希表存储（非ziplist/int编码存储）时，并且元素数量超过64个
- 当ZSet底层采用跳表存储（非ziplist编码存储）时，并且元素数量超过64个
- 当List链表节点数量超过64个（注意，不是元素数量，而是链表节点的数量，List的实现是在每个节点包含了若干个元素的数据，这些元素采用ziplist存储）
也就是说String（不管内存占用多大）、List（少量元素）、Set（int编码存储）、Hash/ZSet（ziplist编码存储）这些情况下的key在释放内存时，依旧在主线程中操作。 可见，即使开启了lazy-free，String类型的bigkey，在删除时依旧有阻塞主线程的风险。

# 3 内存淘汰策略
你就可以使用下面这个命令来设定缓存的大小了：
```bash
$ CONFIG SET maxmemory 4gb
```

## 3.1 基础知识
Redis 4.0 之前一共实现了 6 种内存淘汰策略，在 4.0 之后，又增加了 2 种策略。
不进行数据淘汰的策略，只有 noeviction 这一种。会进行淘汰的 7 种策略，我们可以再进一步根据淘汰候选数据集的范围把它们分成两类：
- 在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis 4.0 后新增）四种。
- 在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）三种。

我们再分析下 volatile-random、volatile-ttl、volatile-lru 和 volatile-lfu 这四种淘汰策略：
- volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。
- volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。
- volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对。
- volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对。

allkeys-lru、allkeys-random、allkeys-lfu 这三种淘汰策略的备选淘汰数据范围，就扩大到了所有键值对，无论这些键值对是否设置了过期时间。

## 3.2 LRU 算法
LRU 算法的全称是 Least Recently Used，从名字上就可以看出，这是按照最近最少使用的原则来筛选数据，最不常用的数据会被筛选出来，而最近频繁使用的数据会留在缓存中。

LRU 会把所有的数据组织成一个链表，链表的头和尾分别表示 MRU 端和 LRU 端，分别代表最近最常使用的数据和最近最不常用的数据。
LRU 算法背后的想法非常朴素：它认为刚刚被访问的数据，肯定还会被再次访问，所以就把它放在 MRU 端；长久不访问的数据，肯定就不会再被访问了，所以就让它逐渐后移到 LRU 端，在缓存满时，就优先删除它。

在 Redis 中，LRU 算法被做了简化，以减轻数据淘汰对缓存性能的影响。具体来说，Redis 默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构 `RedisObject` 中的 lru 字段记录）。然后，Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。
Redis 提供了一个配置参数 `maxmemory-samples`，这个参数就是 Redis 选出的数据个数 N。例如，我们执行如下命令，可以让 Redis 选出 100 个数据作为候选数据集：
```bash
$ CONFIG SET maxmemory-samples 100
```
当需要再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是：**能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值**。当有新数据进入候选数据集后，如果候选数据集中的数据个数达到了 `maxmemory-samples`，Redis 就把候选数据集中 lru 字段值最小的数据淘汰出去。

需要注意，在实际运行时，每次往候选集中插入的数据可能不止一个，而在淘汰数据时，也是会根据使用内存量超过maxmemory的情况，来决定要淘汰的数据量，所以可能也不止一个数据被淘汰。当候选集中已经没有空位置时，候选集链表头的数据会被移出候选集，把位置空出来，给新进入的数据。
候选集的作用是先把符合条件（lru值小）的数据准备好。候选集本身是会按照lru值大小排序的，等待要淘汰时，会根据要淘汰的量，从候选集中淘汰数据。
这样一来，Redis 缓存不用为所有的数据维护一个大链表，也不用在每次数据访问时都移动链表项，提升了缓存的性能。

## 3.3 LFU 算法
什么是**缓存污染**呢？在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。
**因为只看数据的访问时间，使用 LRU 策略在处理扫描式单次查询操作时，无法解决缓存污染**。所谓的扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 lru 字段值都很大。

Redis 从 4.0 版本开始增加了 LFU 淘汰策略。与 LRU 策略相比，LFU 策略中会从两个维度来筛选并淘汰数据：一是，数据访问的时效性（访问时间离当前时间的远近）；二是，数据的被访问次数。

### 3.3.1 缓存策略
LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。
和那些被频繁访问的数据相比，扫描式单次查询的数据因为不会被再次访问，所以它们的访问次数不会再增加。因此，LFU 策略会优先把这些访问次数低的数据淘汰出缓存。

Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分。
- ldt 值：lru 字段的前 16bit，表示数据的访问时间戳；
- counter 值：lru 字段的后 8bit，表示数据的访问次数。

### 3.3.2 访问次数统计
Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255，这样可以吗？因此在实现 LFU 策略时，Redis 并没有采用数据每被访问一次，就给对应的 counter 值加 1 的计数规则，而是采用了一个更优化的计数规则。
简单来说，LFU 策略实现的计数规则是：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 `lfu_log_factor` 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。
下面这段 Redis 的部分源码，显示了 LFU 策略增加计数器值的计算逻辑。其中，`baseval` 是计数器当前的值。计数器的初始值默认是 5（由代码中的 `LFU_INIT_VAL` 常量设置），而不是 0，这样可以避免数据刚被写入缓存，就因为访问次数少而被立即淘汰：
```c
double r = (double)rand()/RAND_MAX;
...
double p = 1.0/(baseval*server.lfu_log_factor+1);
if (r < p) counter++;   
```

了更进一步说明 LFU 策略计数器递增的效果，你可以看下下面这张表。这是 Redis官网上提供的一张表，它记录了当 `lfu_log_factor` 取不同值时，在不同的实际访问次数情况下，计数器的值是如何变化的：
![[image-123.png]]
正是因为使用了非线性递增的计数器方法，即使缓存数据的访问次数成千上万，LFU 策略也可以有效地区分不同的访问次数，从而进行合理的数据筛选。从刚才的表中，我们可以看到，当 `lfu_log_factor` 取值为 10 时，百、千、十万级别的访问次数对应的 counter 值已经有明显的区分了，所以，我们在应用 LFU 策略时，一般可以将 `lfu_log_factor` 取值为 10。

### 3.3.3 访问次数衰减
在一些场景下，有些数据在短时间内被大量访问后就不会再被访问了。那么再按照访问次数来筛选的话，这些数据会被留存在缓存中，但不会提升缓存命中率。为此，Redis 在实现 LFU 策略时，还设计了一个 counter 值的衰减机制。

LFU 策略使用衰减因子配置项 `lfu_decay_time` 来控制访问次数的衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 `lfu_decay_time` 值，所得的结果就是数据 counter 要衰减的值。
如果 `lfu_decay_time` 取值更大，那么相应的衰减值会变小，衰减效果也会减弱。所以，如果业务应用中有短时高频访问的数据的话，建议把 `lfu_decay_time` 值设置为 1，这样一来，LFU 策略在它们不再被访问后，会较快地衰减它们的访问次数，尽早把它们从缓存中淘汰出去，避免缓存污染。

---
# 4 引用
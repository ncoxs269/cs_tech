2025-03-31 10:11
Status: #MOC
Tags: [[计算机基础]]

# 1 进程和线程
## 1.1 进程
进程是一个具有一定独立功能的程序一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位，是应用程序运行的载体。进程是一种抽象的概念，从来没有统一的标准定义。
进程一般由程序、数据集合和进程控制块三部分组成。
- 程序用于描述进程要完成的功能，是控制进程执行的指令集；
- 数据集合是程序在执行时所需要的数据和工作区；
- 程序控制块(Program Control Block，简称PCB)，包含进程的描述信息和控制信息，是进程存在的唯一标志。

在程序启动时，操作系统会给该程序分配一块内存空间，对于程序但看到的是一整块连续的内存空间，称为虚拟内存空间，落实到操作系统内核则是一块一块的内存碎片的东西。为的是节省内核空间，方便对内存管理。
![[image-14.png]]
就这片内存空间，又划分为用户空间与内核空间，用户空间只用于用户程序的执行，若要执行各种IO操作，就会通过系统调用等进入内核空间进行操作。

## 1.2 线程
线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。
一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。
一个标准的线程由线程ID、当前指令指针(PC)、寄存器和栈组成。而进程由内存空间(代码、数据、进程空间、打开的文件)和一个或多个线程组成。

## 1.3 任务调度
大部分操作系统(如Windows、Linux)的任务调度是采用**时间片轮转的抢占式调度**方式。
在一个进程中，当一个线程任务执行几毫秒后，会由操作系统的内核进行调度，通过硬件的计数器中断处理器，让该线程强制暂停并将该线程的寄存器放入内存中，通过查看线程列表决定接下来执行哪一个线程，并从内存中恢复该线程的寄存器，最后恢复该线程的执行，从而去执行下一个任务。
上述过程中，任务执行的那一小段时间叫做**时间片**，任务正在执行时的状态叫运行状态，被暂停的线程任务状态叫做就绪状态。
这种方式保证了每个线程轮流执行，由于CPU的执行效率非常高，时间片非常短，在各个任务之间快速地切换，给人的感觉就是多个任务在“同时进行”，这也就是我们所说的并发：多个任务同时执行。

## 1.4 进程和线程的区别
1. 进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。
2. 一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线。
3. 进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段、数据集、堆等)及一些进程级的资源(如打开文件和信号)，某进程内的线程在其它进程不可见。
4. 调度和切换：线程上下文切换比进程上下文切换要快得多。
	进程切换要保存的现场太多如寄存器，栈，代码段，执行位置等。线程的切换只需要保存线程的执行现场(程序计数器等状态)到该线程的栈里，CPU把栈指针、指令寄存器的值指向下一个线程。
![[image-13.png]]

## 1.5 内核线程和用户线程
内核线程（Kernel Thread，KLT）就是直接由操作系统内核支持的线程。内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。
程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——**轻量级进程（Lightweight Process，LWP）**，轻量级进程就是我们通常意义上所讲的线程，也被叫做**用户线程**。它由用户程序管理，需绑定到内核态线程上执行。
用户线程与内核线程的对应关系有三种模型：一对一模型、多对一模型、多对多模型。

### 1.5.1 一对一模型
一个用户线程就唯一地对应一个内核线程。其调度完全由OS调度器来做，调度实现简单。例如 Java 就是这样。
线程之间的并发是真正的并发，一个线程因某种原因阻塞时其他线程的执行不受影响。

但一对一模型也有两个缺点：
1. 许多操作系统限制了内核线程的数量，因此一对一模型会使用户线程的数量受到限制；
2. 线程在用户态的运行，而线程的调度和管理在内核实现，在控制权从一个线程传送到另一个线程需要用户态到内核态再到用户态的模式切换，比较占用系统资源。并且许多操作系统内核线程调度时，上下文切换的开销较大，导致用户线程的执行效率下降。
3. 此外内核线程创建、销毁的效率也不高。

### 1.5.2 多对一模型
多对一模型将多个用户线程映射到一个内核线程上，线程之间的切换由用户态的代码来进行，系统内核感受不到线程的实现方式。例如 Python。
用户线程的建立、同步、销毁等都在用户态中完成，不需要内核的介入。因此相对一对一模型，多对一模型的线程上下文切换速度要快许多。
此外，多对一模型对用户线程的数量几乎无限制。

但多对一模型也有两个缺点：
1. 如果其中一个用户线程阻塞，那么其它所有线程都将无法执行，因为此时内核线程也随之阻塞了。不过可以使用 **jacket 技术**，就是把一个产生阻塞的系统调用转化成一个非阻塞的系统调用。
	例如不是直接调用一个系统 I/O 例程，而是调用一个应用级别的 I/O jacket 例程，这个 jacket 例程中的代码会检查并且确定 I/O 设备是不是正忙，如果忙的话，就在用户态下将该线程阻塞，然后把控制权交给另一个线程。隔一段时间后再次检查 I/O 设备。
	最后还是会执行阻塞调用，但使用 jacket 可以缩短被阻塞的时间。不过有些情况下是可以不被阻塞的，取决于具体的实现。
2. 在多处理器系统上，处理器数量的增加对多对一模型的线程性能不会有明显的增加，因为所有的用户线程都映射到一个处理器上了。

### 1.5.3 多对多模型
多对多模型结合了一对一模型和多对一模型的优点，将多个用户线程映射到多个内核线程上。
用户线程可以与不同的内核线程在运行时进行**动态关联**：当某个内核线程由于其上工作的线程的阻塞操作被内核调度出CPU时，当前与其关联的其余用户线程可以重新与其他内核建立关联关系。
当然这种动态关联机制的实现很复杂，也需要用户自己去实现。Go为了实现该模型自己实现了一个运行时调度器来负责Go中的用户线程与内核线程的动态关联。此模型有时也被称为 **混合型线程模型**，**即用户调度器实现用户线程到内核线程的“调度”，内核调度器实现内核线程到CPU上的调度**。

# 2 为什么需要多线程
深入到计算机底层来探讨，有两个方面：
- 单核时代： **在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率**。举个例子：当只有一个线程的时候会导致 CPU 计算时， IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50% 左右。但是当有两个线程的时候就不一样了， 当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100% 了。
- 多核时代: **多核时代多线程主要是为了提高 CPU 利用率**。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话， CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率。

又因为 CPU、内存、I/O 设备的速度是有极大差异的，为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、 操作系统、编译程序都做出了贡献，主要体现为:
- CPU 增加了缓存，以均衡与内存的速度差异。而这导致了**可见性**问题。
- 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异。而这导致了**原子性**问题。
- 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。而这导致了**有序性**问题。

# 3 并发出现问题的根源: 并发三要素
## 3.1 可见性: CPU 缓存引起
**可见性：一个线程对共享变量的修改，另外一个线程能够立刻看到**。

举个简单的例子，看下面这段代码：
```Java
//线程1执行的代码
int i = 0;
i = 10;
 
//线程2执行的代码
j = i;
```
假若执行线程 1 的是 CPU1，执行线程 2 的是 CPU2。由上面的分析可知，当线程 1 执行 `i=10` 这句时， 会先把`i`的初始值加载到 CPU1 的高速缓存中，然后赋值为 10，那么在 CPU1 的高速缓存当中`i`的值变为 10 了， 却没有立即写入到主存当中。
此时线程 2 执行 `j = i`，它会先去主存读取`i`的值并加载到 CPU2 的缓存当中，注意此时内存当中`i`的值还是 0， 那么就会使得`j`的值为 0，而不是 10。这就是可见性问题，线程 1 对变量`i`修改了之后，线程 2 没有立即看到线程 1 修改的值。

## 3.2 原子性: 分时复用引起
**原子性：即一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行**。

经典的转账问题：比如从账户 A 向账户 B 转 1000 元，那么必然包括 2 个操作：从账户 A 减去 1000元，往账户 B 加上 1000元。
试想一下，如果这 2 个操作不具备原子性，那么可能导致 A 转了 1000 元，然后因为某种原因后序操作中断，导致 B 没有收到这 1000 元。 这样会导致数据一致性被破坏。所以这 2 个操作必须要具备原子性才能保证不出现一些意外的问题。

## 3.3 有序性: 重排序引起
**有序性：即程序执行的顺序按照代码的先后顺序执行**。

举个简单的例子，看下面这段代码：
```Java
int i = 0;              
boolean flag = false;
i = 1;                //语句1  
flag = true;          //语句2
```
上面代码定义了一个 `int` 型变量，定义了一个 `boolean` 类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看， 语句 1 是在语句 2 前面的，那么 JVM 在真正执行这段代码的时候会保证语句 1 一定会在语句 2 前面执行吗? 不一定，为什么呢? 这里可能会发生**指令重排序（Instruction Reorder）**。

# 4 并发问题
## 4.1 死锁
### 4.1.1 什么是线程死锁
线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞， 因此程序不可能正常终止。
下面通过一个例子来说明线程死锁,代码模拟了上图的死锁的情况 (代码来源于《并发编程之美》)：
```Java
public class DeadLockDemo {
    private static Object resource1 = new Object();//资源 1
    private static Object resource2 = new Object();//资源 2

    public static void main(String[] args) {
        new Thread(() -> {
            synchronized (resource1) {
                System.out.println(Thread.currentThread() + "get resource1");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource2");
                synchronized (resource2) {
                    System.out.println(Thread.currentThread() + "get resource2");
                }
            }
        }, "线程 1").start();

        new Thread(() -> {
            synchronized (resource2) {
                System.out.println(Thread.currentThread() + "get resource2");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource1");
                synchronized (resource1) {
                    System.out.println(Thread.currentThread() + "get resource1");
                }
            }
        }, "线程 2").start();
    }
}
```
线程 A 通过 `synchronized(resource1)` 获得 `resource1` 的监视器锁，然后通过 `Thread.sleep(1000)` 让线程 A 休眠 1s， 为的是让线程 B 得到执行然后获取到 `resource2` 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源， 然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。

### 4.1.2 死锁的四个必要条件
学过操作系统的朋友都知道产生死锁必须具备以下四个条件：
- **互斥条件**：该资源任意一个时刻只由一个线程占用。
- **请求与保持条件**：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
- **不剥夺条件**: 线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
- **循环等待条件**: 若干进程之间形成一种头尾相接的循环等待资源关系。

### 4.1.3 如何避免线程死锁
为了避免死锁，我们只要破坏产生死锁的四个条件中的其中一个就可以了。现在我们来挨个分析一下：
- 破坏互斥条件：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。
- 破坏请求与保持条件：一次性申请所有的资源。
- 破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
- 破坏循环等待条件：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

## 4.2 活锁
活锁指的是 任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。 
如下图所示，在极端情况下，两个线程循环反复执行以下逻辑：线程 t1 获取 lock1 锁，线程 t2 获取到 lock2 锁  。
线程 t1 尝试获取 lock2 锁失败之后，释放掉 lock1 锁，与此同时，线程 t2 尝试获取 lock1 锁失败之后，释放掉 lock2 锁  。
然后线程 t1 和 t2 再重复执行上述逻辑，这就导致线程 t1 和 t2 一直循环加锁、尝试加锁、释放锁，我们把这种情况叫做活锁。
![[Pasted image 20250331213537.png]]

死锁和活锁的区别有两点：
1. 处于死锁状态的两个线程均处于阻塞状态，不消耗 CPU 资源。相反，处于活锁状态的两个线程，仍然在不停的执行加锁、尝试加锁、释放锁等代码逻辑，消耗 CPU 资源，比起死锁，活锁的性能损耗更大。
2. 死锁发生的概率很低，在高并发情况下，两个线程频繁竞争执行临界区，才有可能发生死锁。不过相对于死锁，活锁发生的概率更低，发生活锁，除了具备死锁发生的条件之外，还需要两个线程的执行过程非常同步，才能保证 for 循环一直不退出

为解决活锁可以引入一些随机性，例如如果检测到冲突，那么就暂停随机的一定时间进行重试。这回大大减少碰撞的可能性。典型的例子是以太网的CSMA/CD检测机制。

## 4.3 饥饿
饥饿：是指如果线程T1占用了资源R，线程T2又请求封锁R，于是T2等待。T3也请求资源R，当T1释放了R上的封锁后，系统首先批准了T3的请求，T2仍然等待。然后T4又请求封锁R，当T3释放了R上的封锁之后，系统又批准了T4的请求…，T2可能永远等待。

# 5 TODO
[[TODO]]

- 内核线程深究
- jacket 技术
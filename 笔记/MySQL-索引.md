2025-04-27 09:40
Status: #idea
Tags: [[MySQL]]


# 1 索引基础
## 1.1 索引的常见模型
### 1.1.1 哈希表
因为不是有序的，所以哈希索引做区间查询的速度是很慢的，必须全部扫描一遍了。所以，**哈希表这种结构适用于只有等值查询的场景**，比如 Memcached 及其他一些 NoSQL 引擎。

### 1.1.2 有序数组
有序数组在等值查询和范围查询场景中的性能就都非常优秀。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。所以，**有序数组索引只适用于静态存储引擎**，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。

### 1.1.3 搜索树
二叉搜索树也是课本里的经典数据结构了。当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。

**树可以有二叉，也可以有多叉**。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。
二叉树是搜索效率最高的，但是**实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上**。
为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，**“N 叉”树中的“N”取决于数据块的大小**。

### 1.1.4 小结
数据库技术发展到今天，跳表、LSM 树等数据结构也被用于引擎设计中，LevelDB，RocksDB 等KV 引擎都使用了 LSM 树和跳表。

## 1.2 InnoDB 的索引模型
### 1.2.1 基础概念
**在 MySQL 中，索引是在存储引擎层实现的**。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛，所以下面我就以 InnoDB 为例，和你分析一下其中的索引模型。

在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为**索引组织表**。InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。
在 InnoDB 中，**每一个索引在 InnoDB 里面对应一棵 B+ 树**。每一张表其实就是多个 B+ 树，即一个主键索引树和多个非主键索引树。执行查询的效率，使用主键索引 > 使用非主键索引 > 不使用索引。
如果不使用索引进行查询，则从主索引 B+ 树的叶子节点进行遍历。

根据叶子节点的内容，索引类型分为主键索引和非主键索引。
- **主键索引的叶子节点存的是整行数据**。在 InnoDB 里，主键索引也被称为**聚簇索引（clustered index）**。
- **非主键索引的叶子节点内容是主键的值**。在 InnoDB 里，非主键索引也被称为**二级索引（secondary index）**。

根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？
- 如果语句是 `select * from T where ID=500`，即主键查询方式，则只需要搜索 `ID` 这棵 B+ 树；
- 如果语句是 `select * from T where k=5`，即普通索引查询方式，则需要先搜索 k 索引树，得到 `ID` 的值为 500，再到 `ID` 索引树搜索一次。这个过程称为**回表**。当然，如果只是为了获取对应的主键值，是不会回表的。
也就是说，**基于非主键索引的查询需要多扫描一棵索引树**。

#### 1.2.1.1 查询示例
在下面这个表 `T` 中，如果我执行 `select * from T where k between 3 and 5`，需要执行几次树的搜索操作，会扫描多少行？下面是这个表的初始化语句：
```sql
mysql> create table T (
ID int primary key,
k int NOT NULL DEFAULT 0, 
s varchar(16) NOT NULL DEFAULT '',
index k(k))
engine=InnoDB;

insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');
```
![[image-37.png]]

我们一起来看看这条 SQL 查询语句的执行流程：
1. 在 `k` 索引树上找到 `k=3` 的记录，取得 `ID = 300`；
2. 再到 `ID` 索引树查到 `ID=300` 对应的 `R3`；
3. 在 `k` 索引树取下一个值 `k=5`，取得 `ID=500`；
4. 再回到 `ID` 索引树查到 `ID=500` 对应的 `R4`；
5. 在 `k` 索引树取下一个值 `k=6`，不满足条件，循环结束。
可以看到，这个查询过程读了 `k` 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。
所以扫描行数是2行，但是引擎读取记录是5次。

### 1.2.2 B 树和 B+ 树的区别
B 树和 B+ 树都是**多路平衡查找树**。

其中 B 树：**每个节点都存储 key 和 data**，所有节点组成这棵树，并且叶子节点指针为 null。
![[image-34.png]]

B+树： **只有叶子节点存储 data**，叶子节点包含了这棵树的所有键值。并且为所有叶子节点增加了一个**链接指针**，指向下一个叶子节点，组成了一个循环双向链表。
![[image-35.png]]

它们之间的区别如下：
- 因为内节点并不存储 data，所以一般 B+ 树的叶节点和非叶节点大小不同，而 B 树的每个节点大小一般是相同的，为一页。
- B+ 树内节点不存储数据，所有 data 存储在叶节点导致查询时间复杂度固定为 log n。而 B 树查询时间复杂度不固定，与 key 在树中的位置有关，最好为O(1)。
- B+ 树叶节点两两相连可大大增加**区间访问性**，可使用在范围查询等，而 B 树每个节点 key 和 data 在一起，则无法区间查找。
- B+树更适合外部存储。由于内节点无 data 域，每个节点能容纳更多 key，能索引的范围更大更精确，树高更低，减少磁盘IO。

### 1.2.3 一页能存多少数据探究
假设是主键索引树，数据类型 BIGINT，8字节。一行大小1K

基础知识：
- 指针大小：InnoDB 中，指向子节点的指针（页号）固定为 **6 字节**（因为 InnoDB 的表空间最大支持 2^32 页，6 字节足够存储页地址）。
- 页固定开销：页头（约 120 字节）+ 页尾（8 字节）+ 页目录（少量，简化按 136 字节总开销计算）。
	- **页目录（Page Directory）** 是数据页（包括存储行数据的叶子节点页和存储索引项的非叶子节点页）内部的一个关键组件，作用是快速定位页内的记录，避免逐行扫描，提升查询效率。
	- 页目录的核心作用类似书籍的 “目录”：通过预先记录部分关键记录的位置，实现**页内二分查找**，大幅减少查找时需要扫描的记录数量。
	- 页目录的位置和结构
		- 位置：位于页的中后部，介于 “页体”（存储实际记录）和 “页尾”（校验信息）之间。
		- 组成：由多个 “槽位（Slot）” 组成，每个槽位固定占用 2 字节，存储的是某条记录在页内的 “偏移量”（即该记录距离页起始位置的字节数）。
	- 页目录的工作原理（以数据页为例）
		1. 记录分组：页内的记录（用户记录）会被分成若干组，每组包含若干条连续记录（通常 8 条左右，数量不固定）。
		2. 槽位记录：每个槽位只记录本组最后一条记录的偏移量，且槽位按记录的主键顺序排序（与记录在页内的物理顺序一致）。
		3. 二分查找：当需要在页内查找某条记录时：
		    - 先对页目录的槽位进行二分查找，定位到目标记录可能所在的组（通过比较主键值）；
		    - 再在该组内从第一条记录开始顺序扫描，找到目标记录。
- 页可用空间 = 总页大小 - 固定开销 = 16384 字节 - 136 字节 = 16248 字节。

因此：
- 非叶子结点：16248 ÷ 14 ≈ 1160
- 叶子结点：16248 ÷ 1K ≈ 15

### 1.2.4 4层的B+树能存多少数据探究
和上面一样，假设是主键索引树，数据类型 BIGINT，8字节。一行大小1K
那么：
- **第 1 层（根节点）**：仅 1 个节点（B + 树初始根节点为叶子节点，随数据量增长升级为非叶子节点，此处按非叶子节点计算）。
- **第 2 层**：由根节点的索引项数量决定，共 1160 个节点。
- **第 3 层**：每个节点对应上层 1 个索引项，因此节点数 = 1160×1160=1160²=1,345,600 个。
- **第 4 层（叶子节点）**：每个节点对应第 3 层的 1 个索引项，因此节点数 = 1160²×15=20184000 个。
- 总节点数 = 各层节点数之和：1+1160+1,345,600+20184000 ≈ 2100万

### 1.2.5 B+树优化问题探究
#### 1.2.5.1 问题的影响
B + 树的查询效率直接取决于树高（每层对应一次磁盘 IO），4 层意味着单次查询需至少 4 次 IO。5000 多万行数据对应 4 层树高，说明当前索引节点的 “容量” 不够理想（即每个非叶子节点容纳的索引项太少），或数据分布导致树结构不够紧凑。优化的核心目标是：**降低树高（理想降至 2-3 层）、减少 IO 次数，或提升 IO 效率**。

#### 1.2.5.2 具体优化措施（按优先级排序）
##### 1.2.5.2.1 优化索引结构，减小索引项大小（直接降低树高）
- **主键优化**：若主键是 UUID、字符串等大字段（如 CHAR (36)），换成 INT/BIGINT 自增主键。
- **二级索引去冗余**：若二级索引包含长字段（如 VARCHAR (255)），检查是否必要（如联合索引中包含非筛选 / 排序的长字段），移除冗余字段，减小索引项大小。

##### 1.2.5.2.2 提高页利用率，减少页分裂（让节点更 “满”）
若数据插入无序（如非自增主键），会导致频繁的页分裂（页未满就分裂为两个半满页），单节点实际容纳的索引项远低于理论值，间接增加树高。
- **保证插入有序性**：使用自增主键（聚簇索引天然有序），或二级索引查询条件尽量基于有序字段插入，避免随机写入导致的页分裂。
- **定期清理碎片**：通过`OPTIMIZE TABLE`（InnoDB 会重建表）或`ALTER TABLE ... ENGINE=InnoDB`（Online DDL）整理数据页，将碎片化的半满页合并，提高页利用率（接近理论值），从而减少节点总数，降低树高。

##### 1.2.5.2.3 合理控制索引数量，避免 “树太多”
过多的二级索引会导致每个索引对应一颗独立 B + 树，5000 万行数据下，多棵 4 层树会占用大量磁盘空间和缓冲池，间接影响查询效率。
- **删除无用索引**：通过`sys.schema_unused_indexes`（MySQL 8.0+）或慢查询日志分析，删除未被使用的二级索引。
- **合并重复索引**：例如同时存在`idx(a)`和`idx(a,b)`，`idx(a)`可删除（后者包含前者前缀，功能覆盖）。

##### 1.2.5.2.4 硬件与配置优化（提升 IO 效率，即使树高不变也更快）
若树高暂时无法降低，可通过减少 IO 耗时弥补：
- **使用 SSD**：SSD 的随机 IO 速度是机械硬盘的 100 倍以上，4 次 IO 的耗时可从毫秒级降至微秒级。
- **调大缓冲池**：增大`innodb_buffer_pool_size`（建议占可用内存的 50%-70%），让更多索引页 / 数据页缓存在内存中，减少物理 IO（内存 IO 比磁盘 IO 快 10 万倍以上）。
- **预热索引页**：通过`LOAD INDEX INTO CACHE`将高频访问的索引页加载到缓冲池，避免冷启动时的磁盘 IO。

##### 1.2.5.2.5 分表分库（数据量持续增长时的终极方案）
若 5000 万行是增长中的数据量（未来可能达数亿），即使优化索引，树高仍可能继续增加。此时需通过分表拆分数据。

## 1.3 页分裂和页合并
B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 `ID` 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 `ID` 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。
![[image-36.png]]

而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为**页分裂**。在这种情况下，性能自然会受影响。
**除了性能外，页分裂操作还影响数据页的利用率**。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。

当然有分裂就有**合并**。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。
根据上一节 MVVC 中所述，删除其实只是标记被删除，并不释放磁盘空间。Innodb 存储引擎下，所有表都是这样的，当删除的记录达到页体积的百分之 50 才会尝试页合并。这样做减少了很多页合并操作，空间换时间。

## 1.4 自增主键
在建表语句中一般是这么定义的： `NOT NULL PRIMARY KEY AUTO_INCREMENT`。
插入新记录的时候可以不指定 `ID` 的值，系统会获取当前 `ID` 最大值加 1 作为下一条记录的 `ID` 值。也就是说，**自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景**。
并且，**主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小**。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。

**有没有什么场景适合用业务字段直接做主键的呢**？还是有的。比如，有些业务的场景需求是这样的：
1. 只有一个索引。
2. 该索引必须是唯一索引。
你一定看出来了，这就是典型的 **KV 场景**。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。

## 1.5 总结
- 索引是在引擎层实现的，InnoDB的索引是B+树结构
	- B+树只有叶子结点存储数据，非叶子节点只存储索引值；而B树非叶子节点也存储数据。所以一般 B+ 树的叶节点和非叶节点大小不同，而 B 树则相同；并且 B+ 树的查询效率固定为 O(logN)，B树最好能有 O(1)。
	- B+树的叶子结点之间有指针链接，从而串成一个循环双向链表。
	- B+每个非叶子节点能容纳更多 key，能索引的范围更大更精确，因此树高也更低，减少磁盘IO。并且双向链表还增强了区间访问性，利好范围查询
- InnoDB每个索引都是一颗B+树，称为索引组织表。其中主键索引的叶子结点是一行数据，又叫聚簇索引；其他索引的叶子结点是主键，又叫二级索引。使用二级索引查数据时，还需要再回到主键索引查询真实的行，称为回表。
- B+树有一些常见的面试题：
	- 一页能存多少数据
	- 4层B+树能存多少数据
	- B+树怎么优化
- 页分裂：当值插到一页中间并且页满了的时候，这个页就会分裂成两个。页分裂会影响性能，还会降低页的利用率。这也是为什么自增ID好的原因，它都是追加，不会在页中间插入。
- 页合并：相邻两页利用率较低时，才会合并页。空间换时间

# 2 索引优化
## 2.1 index dive
MySQL优化器在真正执行查询之前，对于每个可能使用到的索引来说，都会预先计算一下需要扫描的二级索引记录的数量，比方说对于下边这个查询：
```sql
SELECT * FROM s1 WHERE key1='xx';
```
优化器会分析出此查询只需要查找`key1`值为`'xx'`的记录，然后访问一下二级索引`idx_key1`，看一下值为`'xx'`的记录有多少。
如果符合条件的二级索引记录数量较少，那么统计结果是精确的；如果太多的话，会采用一定的手段计算一个模糊的值。
**这种在查询真正执行前，优化器先访问索引来计算需要扫描的索引数量的方式，称之为`index dive`**。

对于某些查询，比方说WHERE子句中有IN条件，并且IN条件中包含许多参数的话，比方说这样：
```sql
SELECT * FROM s1 WHERE key1 IN ('a', 'b', 'c', ... , 'zzzzzzz');
```
这样的话需要统计的`key1`值所在的区间就太多了，这样就不能采用`index dive`，而是采用之前在背地里产生的统计数据去估算二级索引记录有多少条。很显然估算记录条数比`index dive`的精确性差了很多。

不论采用`index dive`还是依据统计数据估算，最终得到一个需要扫描的二级索引条数，如果占整个记录条数的比例特别大，那么回表次数非常多，优化器就趋向于全表扫描避免回表。

## 2.2 覆盖索引
如果执行的语句是 `select ID from T where k between 3 and 5`，`ID` 的值已经在 `k` 索引树上了，因此不需要回表。也就是说，在这个查询里面，索引 `k` 已经“覆盖了”我们的查询需求，我们称为**覆盖索引**。
**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段**。

当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。

## 2.3 最左前缀原则
**B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录**。为了直观地说明这个概念，我们用 `(name，age)` 这个联合索引来分析。
![[image-38.png]]

当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 `ID4`，然后向后遍历得到所有需要的结果。
如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是 `where name like '张%'`。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 `ID3`，然后向后遍历，直到不满足条件为止。
可以看到，**这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符**。所以 `a%` 也可走索引，而 `%a%` 则没有。
**mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配**。
注意，**`where` 条件里面的索引顺序是没有关系的**。假如有组合索引 `a,b,c`，那么 `a,b,c`、`a,c`、`b,a`、`a` 等都会命中索引，但是 `b,c`、`b` 等会全表扫描。

### 2.3.1 根据空间选择如何建索引
如果既有联合查询，又有基于 `a`、`b` 各自的查询呢？查询条件里面只有 `b` 的语句，是无法使用 `(a,b)` 这个联合索引的，这时候你需要同时维护 `(a,b)`、`(b)` 这两个索引。
这时候，我们要考虑的原则就是**空间**了。比如上面这个市民表的情况，`name` 字段是比 `age` 字段大的 ，那我就建议你创建一个 `(name,age)` 的联合索引和一个 `(age)` 的单字段索引。**这样字段长的只建立一次，短的建立两次**。

## 2.4 索引下推
我们还是以市民表的联合索引 `(name, age)` 为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：
```sql
mysql> select * from tuser where name like '张%' and age=10 and ismale=1;
```
这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 `ID3`。然后是判断其他条件是否满足。

在 MySQL 5.6 之前，只能从 `ID3` 开始一个个回表。到主键索引上找出数据行，再对比字段值。而 MySQL 5.6 引入的**索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数**。
下面两张图，是这两个过程的执行流程图：
![[image-39.png]]
![[image-40.png]]
它们的区别是，InnoDB 在 `(name,age)` 索引内部就判断了 `age` 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 `ID4`、`ID5` 这两条记录回表取数据判断，就只需要回表 2 次。

### 2.4.1 范围查询之后的字段不能被利用吗？
假设有一条 sql：`select * from task where a = 1 and b > 20 and c < 30`。表中有一个索引 `(a,b,c)`，按照最左前缀规则，范围条件会阻断后续列的索引使用，所以sql中 `c<30` 是用不上的。
不过网上有人说 `(a,b,c)` 比 `(a,b)` 要好，因为虽然 c 走不了索引，但是能避免 c 的回表。

根据索引下推原则，数据库会先通过`a=1 and b>20`找到所有符合条件的索引记录（这些记录中包含 c 的值），直接在索引层面过滤掉`c>=30`的记录，仅对剩余记录执行回表。
不过需要注意的是，“(a,b,c) 比 (a,b) 好” 的说法在**c 的过滤条件能显著减少符合条件的行数**时成立，有以下问题：
1. 索引维护成本更高：联合索引 (a,b,c) 比 (a,b) 更长，会占用更多磁盘空间，且在插入、更新、删除时需要维护更长的索引结构，写入性能可能下降。**对于写入频繁的表，这种开销可能超过查询性能的收益**。
2. 数据分布影响优化器选择：MySQL 优化器会根据数据分布（如 a=1 的记录占比、b 和 c 的分布）选择执行计划。若 a 的选择性极差（例如 a=1 的记录占全表 80%），优化器可能直接选择全表扫描，此时两种索引的差异可忽略。

因此，实际优化中需结合**业务场景（读写比例、数据分布）** 测试两种索引的性能，再决定是否添加 c 列到索引中。

## 2.5 索引合并
索引合并(Index Merge)是 MySQL 优化器的一种查询优化技术，它允许对单个表的多个索引扫描结果进行合并，以提高查询性能。

### 2.5.1 索引合并的类型
MySQL 支持三种索引合并策略：
1. **Index Merge Intersection** (交集合并)
    - 对多个索引扫描结果取交集
    - 适用于 `AND` 连接的条件
2. **Index Merge Union** (并集合并)
    - 对多个索引扫描结果取并集
    - 适用于 `OR` 连接的条件
3. **Index Merge Sort-Union** (排序并集合并)
    - 对无法直接合并的索引扫描结果先排序再取并集
    - 适用于范围条件的 `OR` 连接

开启设置：
```bash
SET optimizer_switch='index_merge_intersection=on,index_merge_union=on,index_merge_sort_union=on';
```

### 2.5.2 会使用索引合并的情况
**多列独立索引的 OR 条件**：
```sql
SELECT * FROM users 
WHERE first_name = 'John' OR last_name = 'Smith';
```
- 需要 `first_name` 和 `last_name` 都有独立索引    
- 执行计划显示 `type: index_merge` 和 `Extra: Using union`

**多列独立索引的 AND 条件**：
```sql
SELECT * FROM users 
WHERE first_name = 'John' AND last_name = 'Smith';
```
- 当没有合适的组合索引时
- 执行计划显示 `type: index_merge` 和 `Extra: Using intersect`

**索引合并排序**：
```sql
SELECT * FROM users 
WHERE age < 20 OR salary > 10000;
```
- 当 `age` 和 `salary` 都有独立索引时
- 普通 Union 无法处理范围条件，Sort-Union 可以

**混合等值查询和范围查询的 OR 条件**：
```sql
SELECT * FROM products 
WHERE category = 'electronics' OR price > 5000;
```

**混合条件的复杂查询**：
```sql
SELECT * FROM users 
WHERE (first_name = 'John' AND age > 20) 
OR (last_name = 'Smith' AND status = 1);
```
可能各列有单独的索引：此时 MySQL 可能先分别用 `(first_name, age)` 和 `(last_name, status)` 条件扫描索引，然后合并结果集。`EXPLAIN` 会显示 `type: index_merge` 和 `Extra: Using union`。
也可能有两个组合索引（分别对应 or 两边）：这是最优情况，MySQL 可能使用这两个组合索引进行 Index Merge，效率比单列索引合并更高。
也可能只有部分列有索引：例如只有 `first_name` 和 `last_name` 有索引：MySQL 只能使用这两个索引做合并，然后对合并结果进行 age > 20 和 status = 1 的过滤，效率较低。

### 2.5.3 不会使用索引合并的情况
1. 全表扫描代价更低时：当优化器判断全表扫描比索引合并更高效时
2. 条件中包含 NOT、!=、<> 等否定逻辑
3. 索引列被函数 / 表达式操作
4. 使用 `FORCE INDEX` 强制使用特定索引时
5. 系统禁用了索引合并：`SET optimizer_switch='index_merge=off';`
6. 涉及全文索引或空间索引时，索引合并仅支持 B-tree 索引

### 2.5.4 索引合并的限制
1. 性能不一定最优：
    - 索引合并通常不如一个合适的组合索引高效
    - 合并操作本身有开销
2. 只适用于单个表：不能跨表合并索引扫描结果
3. 列必须完全独立：合并的索引不能有重叠列
4. 结果集大小影响：当合并结果集很大时，性能可能下降

### 2.5.5 优化建议
1. 优先考虑组合索引
2. 避免复杂的 OR 条件：可以通过业务逻辑拆分查询，降低单条查询的复杂度；或者确定没有交集，则用 UNION ALL。
3. 统计信息更新：`ANALYZE TABLE users;`
4. 使用查询提示：
```sql
SELECT /*+ INDEX_MERGE(users first_name, last_name) */ * FROM users 
WHERE (first_name = 'John' AND age > 20) 
OR (last_name = 'Smith' AND status = 1);
```

### 2.5.6 索引合并可能导致死锁
例如下面的sql：
```sql
update sop_task_statistics set task_num = task_num + #{dto.taskNum}, score = score + #{dto.score}
where slxt_account = #{dto.slxtAccount} and area_id = #{dto.areaId} and month_date = #{dto.monthDate}
```
因为数据库表分别对slxt_account、area_id、month_date字段建了索引，所以在执行上面的sql时会对上面的三个字段索引进行了锁定操作，并且进行了回表操作时也对主键索引进行了锁定，所以对索引的锁定次数达到了6次。注意，`select...for update`也可能出现这种情况。

我们用两个事务来分析下该sql的执行过程：
![[image-42.png]]

解决上面的问题有以下几种方法：
1. 创建组合索引（slxt_account,area_id,month_date）,这样在执行上面的sql语句时，通过组合索引直接定位到具体的主键索引id，更新操作变成了行锁，并且锁粒度细化到一行，这样就不会导致两个事务都锁定了对方需要获取到才能继续往下执行的资源。
2. 先查询，查询操作不会发生锁操作，查询到具体的主键id，然后通过id进行更新操作
3. 显示指定索引，固定执行计划，避免索引合并问题。

## 2.6 索引常见的失效情况
1. 隐式类型转换导致索引失效：例如索引是 `varchar` 类型，但值是数字
2. 字段被函数 / 表达式修饰
3. 不符合联合索引的前缀
4. 索引选择性极低（匹配大部分数据），优化器判断全表扫描更优。全表扫描还是顺序读，索引回表是随机读

## 2.7 各种走不走索引的分析
### 2.7.1 or 走不走索引
`OR` 条件能否走索引的核心是：**所有条件字段是否都有可利用的索引，且优化器认为使用索引更高效**。
- 能走索引：能利用上索引合并，`OR` 两边字段均有索引（单列或复合前缀），且满足索引使用规则。
- 不能走索引：存在无索引字段、或索引常见的失效情况一节。

可以通过业务逻辑拆分查询，降低单条查询的复杂度；或者确定没有交集，则用 UNION ALL。

### 2.7.2 in 走不走索引
in 走索引的情况有哪些：
1. 字段有单列索引
	- 注意，**需要 `IN` 列表值较少且索引选择性高**。当 `IN` 列表中的值数量较少（如几个到几十个），且字段的索引选择性高（即字段值重复少，索引能过滤掉大部分数据），优化器更倾向于使用索引。
2. 字段是复合索引的前缀列
	- 注意点同上
3. 主键 / 唯一索引字段：主键或唯一索引的查询效率极高，即使 `IN` 列表的值较多，只要匹配索引字段，通常会走索引。

in 不走索引的情况有哪些：
1. `IN` 列表值过多（超过优化器阈值）：当 `IN` 列表中的值数量极多（如几千甚至上万个），优化器可能判断 “使用索引多次查找的成本” 高于 “全表扫描一次性过滤”，从而放弃索引。
2. 索引常见的失效情况一节

### 2.7.3 not in、!=走不走索引
通常情况下，它们不会使用索引。当需要通过索引扫描 **大部分索引条目** 时（无论原因是 “排除太多值” 还是 “保留太多值”），索引的 “定位优势” 会消失，此时全表扫描（顺序读取）的成本反而更低。

在某些特定条件下，优化器可能会选择使用索引：
- not in 列表不长、表中行数不多、结果集行数也不多，优化器认为代价不大时
- 字段有主键 / 唯一索引，且 `NOT IN` 列表值极少
- 查询能走覆盖索引时

### 2.7.4 Order by 走不走索引
走索引的情况：
1. 如果一个SQL语句形如：
```sql
SELECT [column1],[column2],…. FROM [TABLE] ORDER BY [sort];
```
在[sort]这个栏位上建立索引就可以实现利用索引进行order by 优化。
2. WHERE + ORDER BY的索引优化，形如：
```sql
SELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] = [value] ORDER BY [sort];
```
建立一个联合索引(columnX,sort)来实现order by 优化，从而避免 file sort。比建立(sort,columnX)索引效果要好得多。

不走索引的情况：
1. 对不同的索引键做 ORDER BY ：(key1,key2分别建立索引)
```sql
SELECT * FROM t1 ORDER BY key1, key2;
```
2. 不符合最左前缀：(key_part1,key_part2建立联合索引)
```sql
SELECT * FROM t1 WHERE key2=constant ORDER BY key_part2;
```
3. 同时使用了 ASC 和 DESC：(key_part1,key_part2建立联合索引)
```sql
SELECT * FROM t1 ORDER BY key_part1 DESC, key_part2 ASC;
```
4. ORDER BY的栏位上应用表达式(函数)时，则无法利用索引来实现order by的优化
```sql
SELECT * FROM t1 ORDER BY YEAR(logindate) LIMIT 0,10;
```

## 2.8 总结
- index dive：优化器在执行查询前，会先通过访问索引或统计信息，判断要扫描的数据量，如果很大就会全表扫描，无需回表还是顺序读。
- 覆盖索引：查询的值在索引上就不需要回表
- 最左前缀：最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。数据库会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配
- 索引下推：对于联合索引，不符合最左前缀之后的索引字段，也会被利用以减少回表
- 索引合并：交集合并(AND)、并集合并(OR)、排序并集合并(范围条件的OR)
	- 可能导致死锁，因为不同事务可能使用不同的索引分别持有了一部分数据
- 索引常见失效情况：index dive、隐式类型转换、字段用函数表达式包围、不符合最左前缀
- 走不走索引：
	- or 和索引合并相关
	- in 和主键/唯一索引、列表长度、index dive相关
	- not in、!= 和列表长度、主键/唯一索引、index dive相关
	- order by 和排序、条件字段有没有索引相关

# 3 普通索引和唯一索引
许多场合，人们创建唯一索引的目的往往不是为了提高访问速度，而只是为了避免数据出现重复。
对于普通索引来说，查找到满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个不满足条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

在不同的业务场景下，应该选择普通索引，还是唯一索引？假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似这样的 SQL 语句：
```sql
select name from CUser where id_card = 'xxxxxxxyyyyyyzzzzz';
```
**从性能的角度考虑，你选择唯一索引还是普通索引呢？选择的依据是什么呢**？

简单起见，我们还是用[[#1.2.1.1 查询示例]]中的例子来说明，假设字段 `k` 上的值都不重复。接下来，我们就从这两种索引对查询语句和更新语句的性能影响来进行分析。

## 3.1 查询过程
假设，执行查询的语句是 `select id from T where k=5`。
- 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 `k=5` 条件的记录。    
- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

这个不同带来的性能差距会有多少呢？答案是，**微乎其微**。你知道的，**InnoDB 的数据是按数据页为单位来读写的**。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。
当然，如果 `k=5` 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。
但是，我们之前计算过，对于整型字段，一个数据页可以放近千个 `key`，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。

## 3.2 更新过程
### 3.2.1 change buffer
为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下 **change buffer**。
当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，**InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了**。
在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。
需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。

**将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。** 除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。

**对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束**。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，**而这必须要将数据页读入内存才能判断**。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。
因此，**唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用**。

change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 `innodb_change_buffer_max_size` 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

### 3.2.2 change buffer 的使用场景
现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？
因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，**所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大**。

因此，对于**写多读少**的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
反过来，假设一个业务的更新模式是**写入之后马上会做查询**，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。

## 3.3 索引选择和实践
大家对“是否使用唯一索引”有比较多的讨论，主要是纠结在“业务可能无法确保”的情况。这里，我再说明一下：
1. 首先，业务正确性优先。咱们这篇文章的前提是“业务代码已经保证不会写入重复数据”的情况下，讨论性能问题。如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。
	这种情况下，本篇文章的意义在于，如果碰上了大量插入数据慢、内存命中率低的时候，可以给你多提供一个排查思路。
2. 然后，在一些“归档库”的场景，你是可以考虑使用普通索引的。比如，线上数据只需要保留半年，然后历史数据保存在归档库。这时候，归档数据已经是确保没有唯一键冲突了。**要提高归档效率，可以考虑把表里面的唯一索引改成普通索引**。

## 3.4 change buffer 和 redo log
现在，我们要在表上执行这个插入语句：
```mysql
mysql> insert into t(id,k) values(id1,k1),(id2,k2);
```
这里，我们假设当前 `k` 索引树的状态，查找到位置后，`k1` 所在的数据页在内存 (InnoDB buffer pool) 中，`k2` 所在的数据页不在内存中。如图 2 所示是带 change buffer 的更新状态图。
![[image-46.png]]

分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）[^1]。
这条更新语句做了如下的操作（按照图中的数字顺序）：
1. Page 1 在内存中，直接更新内存；
2. Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息
3. 将上述两个动作记入 redo log 中（图中 3 和 4）。
图中的两个虚线箭头，是后台操作，不影响更新的响应时间。

那在这之后的读请求，要怎么处理呢？比如，我们现在要执行 `select * from t where k in (k1, k2)`。这里，我画了这两个读请求的流程图。
如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分。
![[image-47.png]]
从图中可以看到：
1. 读 Page 1 的时候，直接从内存返回。
2. 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。

redo log 与 change buffer(含磁盘持久化) 这2个机制，不同之处在于——优化了整个变更流程的不同阶段。 先不考虑redo log、change buffer 机制，简化抽象一个变更(insert、update、delete)流程：
1. 从磁盘读取待变更的行所在的数据页，读取至内存页中。
2. 对内存页中的行，执行变更操作。
3. 将变更后的数据页，写入至磁盘中。
步骤1，涉及随机读磁盘 IO；步骤3，涉及随机写磁盘 IO。**change buffer 机制，优化了步骤1——避免了随机读磁盘IO；redo log 机制， 优化了步骤3——避免了随机写磁盘IO，将随机写磁盘，优化为了顺序写磁盘**。

## 3.5 总结
- 业务上强诉求，那么就选唯一索引
- 普通索引的优势是：它写入数据时，如果数据不在内存中，那么可以通过 change buffer 把写入操作记录下来，无需从磁盘加载数据到内存再写，避免了随机读磁盘
	- 但是change buffer适合写多读少，如果写后马上读，change buffer反而起了副作用
	- 用了change buffer记录写操作，那么redo log里面记录的就是对change buffer的修改操作
- 不过唯一索引也有优势，就是能优化 in、not in

# 4 MySQL为什么有时候会选错索引
## 4.1 案例分析
不知道你有没有碰到过这种情况，一条本来可以执行得很快的语句，却由于 MySQL 选错了索引，而导致执行速度变得很慢？
我们一起来看一个例子吧。我们先建一个简单的表，表里有 `a`、`b` 两个字段，并分别建上索引：
```sql
CREATE TABLE `t` (
  `id` int(11) NOT NULL PRIMARY KEY AUTO_INCREMENT,
  `a` int(11) DEFAULT NULL,
  `b` int(11) DEFAULT NULL,
  KEY `a` (`a`),
  KEY `b` (`b`)
) ENGINE=InnoDB;
```

然后，我们往表 t 中插入 10 万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到 (100000,100000,100000)。我是用存储过程来插入数据的，这里我贴出来方便你复现：
```sql
delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=100000)do
    insert into t(a,b) values(i, i);
    set i=i+1;
  end while;
end;;
delimiter ;

# 注意要写上事务语句执行存储过程。原因是事务隐式提交，这里提交了 10w 次。你每次事务提交就要提交一次 redo 日志缓存，然后 redo 日志缓存又要写入磁盘，所以快速一点的方法是在外面包一层事务，速度明显提升
# 或者也可以在存储过程的 while 循环外包上事务语句
start transaction;
call idata();
commit;
```

在我们已经准备好的包含了 10 万行数据的表上，我们再做如下操作。
![[image-49.png]]
session A 就是开启了一个事务。随后，session B 把数据都删除后，又调用了 `idata` 这个存储过程，插入了 10 万行数据。
这时候，session B 的查询语句 `select * from t where a between 10000 and 20000` 就不会再选择索引 `a` 了。

我们可以通过**慢查询日志 slow log**来查看一下具体的执行情况。
为了说明优化器选择的结果是否正确，我增加了一个对照，即：使用 `force index(a)` 来让优化器强制使用索引 `a`（这部分内容，我还会在这篇文章的后半部分中提到）。下面的三条 SQL 语句，就是这个实验过程。
```sql
set long_query_time=0; # 记录所有执行时间超过 long_query_time 秒的所有查询
select * from t where a between 10000 and 20000; /*Q1*/
select * from t force index(a) where a between 10000 and 20000; /*Q2*/
```
如图 3 所示是这三条 SQL 语句执行完成后的慢查询日志。
![[image-50.png]]
可以看到，Q1 扫描了 10 万行（MySQL 8.0.18中，修复了这个情况，会使用索引 `a`，可能是改变了统计索引的策略），显然是走了全表扫描，执行时间是 40 毫秒。Q2 扫描了 10001 行，执行了 21 毫秒。也就是说，我们在没有使用 `force index` 的时候，MySQL 用错了索引，导致了更长的执行时间。
**这个例子对应的是我们平常不断地删除历史数据和新增数据的场景**。这时，MySQL 竟然会选错索引，是不是有点奇怪呢？今天，我们就从这个奇怪的结果说起吧。

## 4.2 优化器和扫描行数
选择索引是优化器的工作。而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。**在数据库里面，扫描行数是影响执行代价的因素之一**。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。
当然，**扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断**。
我们这个简单的查询语句并没有涉及到临时表和排序，所以 MySQL 选错索引肯定是在判断扫描行数的时候出问题了。那么，问题就是：**扫描行数是怎么判断的**？

### 4.2.1 索引基数和采样统计
MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。**这个统计信息就是索引的“区分度”**。显然，一个索引上不同的值越多，这个索引的区分度就越好。而**一个索引上不同的值的个数，我们称之为“基数”（cardinality）**。也就是说，这个基数越大，索引的区分度越好。
我们可以使用 `show index` 方法，看到一个索引的基数。如图 4 所示，就是表 `t` 的 `show index` 的结果 。虽然这个表的每一行的三个字段值都是一样的，但是在统计信息中，这三个索引的基数值（Cardinality）并不同，而且其实都不准确。
![[image-48.png]]

MySQL 是怎样得到索引的基数的呢？把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“**采样统计**” 。采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。
而数据表是会持续更新的，索引统计信息也不会固定不变。所以，**当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计**。在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 `innodb_stats_persistent` 的值来选择：
- 设置为 `on` 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
- 设置为 `off` 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。

你可以从上面的图看到，这次的索引统计值虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。
其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。

### 4.2.2 代价估计
接下来，我们再一起看看优化器预估的，这两个语句的扫描行数是多少。
![[image-51.png]]
rows 这个字段表示的是预计扫描行数。其中，Q1 的结果还是符合预期的，rows 的值是 104620；但是 Q2 的 rows 值是 37116（不是 10001），偏差就大了。
可能你的第一个疑问不是为什么不准，而是优化器为什么放着扫描 37000 行的执行计划不用，却选择了扫描行数是 100000 的执行计划呢？这是因为，**如果使用索引 `a`，每次从索引 `a` 上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的**。而如果选择扫描 10 万行，是直接在主键索引上扫描的，没有额外的代价。
需要注意的是，**mysql的回表次数不会计算在explain的row扫描行数中**，因为server层的执行器每次获取到一次数据，计扫描一行，而**回表不需要经过server层**。

MySQL 选错索引，这件事儿还得**归咎到没能准确地判断出扫描行数**。至于为什么，是**因为另一个事务仍未提交，所有的更新都是记录在 undo log 中，因此删除的数据只是标记删除**，数据仍然在数据页中；**又因为新插入的主键与原来不同**，session B后插入的数据需要找新的空位插入。所以出现的情况就是delete虽然删除了,但是未释放空间,insert又增加了空间。而索引的统计选择了N个数据页，这部分数据页不收到前台事务的影响，所以整体统计值会变大，直接影响了索引选择的准确性。

### 4.2.3 analyze
`analyze table t` 命令，可以用来重新统计索引信息。我们来看一下执行效果：
![[image-52.png]]
所以在实践中，如果你发现 `explain` 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。

## 4.3 其他索引选择异常和处理
如果只是索引统计不准确，通过 `analyze` 命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。依然是基于这个表 `t`，我们看看另外一个语句：
```mysql
mysql> select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;
```
从条件上看，这个查询没有符合条件的记录（因为 `a == b`），因此会返回空集合。在开始执行这条语句之前，你可以先设想一下，如果你来选择索引，会选择哪一个呢？为了便于分析，我们先来看一下 `a`、`b` 这两个索引的结构图。
![[image-53.png]]

如果使用索引 `a` 进行查询，那么就是扫描索引 `a` 的前 1000 个值，然后取到对应的 `id`，再到主键索引上去查出每一行，然后根据字段 `b` 来过滤。显然这样需要扫描 1000 行。如果使用索引 `b` 进行查询，那么就是扫描索引 `b` 的最后 50001 个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描 50001 行。
所以你一定会想，如果使用索引 `a` 的话，执行速度明显会快很多。那么，下面我们就来看看到底是不是这么一回事儿。图 8 是执行 `explain` 的结果。
![[image-54.png]]
可以看到，返回结果中 key 字段显示，这次优化器选择了索引 `b`，而 rows 字段显示需要扫描的行数是 50198。

因为有 order by b，优化器认为走索引 b 可以避免排序；又有 limit 1，优化器认为只要找到了 1 条满足条件的记录，索引 b 的遍历就可以提前终止，虽然可能要遍历 50001 条记录，但是优化器认为这是值得冒险的事，所以决定了走索引 b。

### 4.3.1 使用 force index
**一种方法是，像我们第一个例子一样，采用 `force index` 强行选择一个索引**。
刚开始分析时，我们认为选择索引 `a` 会更好。现在，我们就来看看执行效果：
![[image-55.png]]
可以看到，原本语句需要执行 2.23 秒，而当你使用 `force index(a)` 的时候，只用了 0.05 秒，比优化器的选择快了 40 多倍。也就是说，优化器没有选择正确的索引，`force index` 起到了“矫正”的作用。

### 4.3.2 引导 MySQL
**我们可以考虑修改语句，引导 MySQL 使用我们期望的索引**。比如，在这个例子里，显然把 `order by b limit 1`” 改成 `order by b,a limit 1` ，语义的逻辑是相同的。我们来看看改之后的效果：
![[image-56.png]]
现在 `order by b,a` 这种写法，要求按照 `b,a` 排序，就意味着使用这两个索引都需要排序。因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描 1000 行的索引 `a`。

如果你觉得修改语义这件事儿不太好，这里还有一种改法。
```mysql
mysql> select * from  (select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1;
```
![[image-57.png]]
在这个例子里，我们用 `limit 100` 让优化器意识到，使用 `b` 索引代价是很高的。其实是我们根据数据特征诱导了一下优化器，也不具备通用性。`limit` 了之后，它就知道最多取 100 条数据。当看到 `b` 的第一步扫描要比 `a` 的第一步扫描多这么多，而多出来的这些都不会进入第二次扫描(因为只取前 100条)，MySQL 就会选择 `a` 做索引来减少第一次扫描的量。

### 4.3.3 选择合适的索引
第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。
不过，在这个例子中，我没有找到通过新增索引来改变优化器行为的方法。这种情况其实比较少，尤其是经过 DBA 索引优化过的库，再碰到这个 bug，找到一个更合适的索引一般比较难。
如果我说还有一个方法是删掉索引 `b`，你可能会觉得好笑。但实际上我碰到过两次这样的例子，最终是 DBA 跟业务开发沟通后，发现这个优化器错误选择的索引其实根本没有必要存在，于是就删掉了这个索引，优化器也就重新选择到了正确的索引。

## 4.4 总结
- 扫描行数是影响执行代价的因素之一，优化器还会结合是否使用临时表、是否排序等因素进行综合判断
- 扫描行数是通过统计信息估算的，这个统计信息是索引的基数，也就是索引不同值的个数。
	- MySQL通过采样统计估算基数，InnoDB 会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以页面数就得到了基数。
	- 当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。
- `analyze table t` 命令，可以用来重新统计索引信息。
- sql 中采用 `force index` 可以强行选择一个索引。

# 5 字符串加索引
[[TODO]]

---
# 6 引用
[!=走不走索引](https://juejin.cn/post/6844903921450745863)


[^1]: 数据表空间：就是一个个的表数据文件，对应的磁盘文件就是“表名.ibd”； 系统表空间：用来放系统信息，如数据字典等，对应的磁盘文件是“ibdata1”。
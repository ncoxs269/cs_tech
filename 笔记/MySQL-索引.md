2025-04-27 09:40
Status: #idea
Tags: [[MySQL]]


# 1 索引基础
## 1.1 索引的常见模型
索引的出现是为了提高查询效率，但是**实现索引的方式却有很多种，所以这里也就引入了索引模型的概念**。

### 1.1.1 哈希表
**哈希表是一种以键 - 值（key-value）存储数据的结构**，我们只要输入待查找的键即 key，就可以找到其对应的值即 value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。
不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。

哈希出来的数组，顺序是没有实际意义的。因为不是有序的，所以哈希索引做区间查询的速度是很慢的。你可以设想下，如果你现在要找身份证号在 `[ID_card_X, ID_card_Y]` 这个区间的所有用户，就必须全部扫描一遍了。
所以，**哈希表这种结构适用于只有等值查询的场景**，比如 Memcached 及其他一些 NoSQL 引擎。

### 1.1.2 有序数组
有序数组在等值查询和范围查询场景中的性能就都非常优秀。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。所以，**有序数组索引只适用于静态存储引擎**，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。

### 1.1.3 搜索树
二叉搜索树也是课本里的经典数据结构了。当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。

**树可以有二叉，也可以有多叉**。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是**实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上**。
为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，**“N 叉”树中的“N”取决于数据块的大小**。
以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200（MySQL 默认一个页的长度为 16K，一个整数（`bigint`）字段索引的长度为 8B，另外每个索引还跟着 6B 的指向其子树的指针；所以 16K/14B ≈ 1170）。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。

### 1.1.4 小结
数据库技术发展到今天，跳表、LSM 树等数据结构也被用于引擎设计中，这里我就不再一一展开了。LevelDB，RocksDB 等KV 引擎都使用了 LSM 树和跳表。

## 1.2 InnoDB 的索引模型
### 1.2.1 基础概念
**在 MySQL 中，索引是在存储引擎层实现的**，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛，所以下面我就以 InnoDB 为例，和你分析一下其中的索引模型。

在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为**索引组织表**。InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。
在 InnoDB 中，**每一个索引在 InnoDB 里面对应一棵 B+ 树**。每一张表其实就是多个 B+ 树，即一个主键索引树和多个非主键索引树。执行查询的效率，使用主键索引 > 使用非主键索引 > 不使用索引。如果不使用索引进行查询，则从主索引 B+ 树的叶子节点进行遍历。

根据叶子节点的内容，索引类型分为主键索引和非主键索引。
- **主键索引的叶子节点存的是整行数据**。在 InnoDB 里，主键索引也被称为**聚簇索引（clustered index）**。
- **非主键索引的叶子节点内容是主键的值**。在 InnoDB 里，非主键索引也被称为**二级索引（secondary index）**。

根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？
- 如果语句是 `select * from T where ID=500`，即主键查询方式，则只需要搜索 `ID` 这棵 B+ 树；
- 如果语句是 `select * from T where k=5`，即普通索引查询方式，则需要先搜索 k 索引树，得到 `ID` 的值为 500，再到 `ID` 索引树搜索一次。这个过程称为**回表**。当然，如果只是为了获取对应的主键值，是不会回表的。
也就是说，**基于非主键索引的查询需要多扫描一棵索引树**。

#### 1.2.1.1 查询示例
在下面这个表 `T` 中，如果我执行 `select * from T where k between 3 and 5`，需要执行几次树的搜索操作，会扫描多少行？下面是这个表的初始化语句：
```sql
mysql> create table T (
ID int primary key,
k int NOT NULL DEFAULT 0, 
s varchar(16) NOT NULL DEFAULT '',
index k(k))
engine=InnoDB;

insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');
```
![[image-37.png]]

我们一起来看看这条 SQL 查询语句的执行流程：
1. 在 `k` 索引树上找到 `k=3` 的记录，取得 `ID = 300`；
2. 再到 `ID` 索引树查到 `ID=300` 对应的 `R3`；
3. 在 `k` 索引树取下一个值 `k=5`，取得 `ID=500`；
4. 再回到 `ID` 索引树查到 `ID=500` 对应的 `R4`；
5. 在 `k` 索引树取下一个值 `k=6`，不满足条件，循环结束。
可以看到，这个查询过程读了 `k` 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。
所以扫描行数是2行，但是引擎读取记录是5次。

### 1.2.2 B 树和 B+ 树的区别
B 树和 B+ 树都是**多路平衡查找树**。

其中 B 树：每个节点都存储 key 和 data，所有节点组成这棵树，并且叶子节点指针为 null。
![[image-34.png]]

B+树： 只有叶子节点存储 data，叶子节点包含了这棵树的所有键值。并且为所有叶子节点增加了一个链接指针，指向下一个叶子节点，组成了一个循环双向链表。
![[image-35.png]]

它们之间的区别如下：
- 因为内节点并不存储 data，所以一般 B+ 树的叶节点和内节点大小不同，而 B 树的每个节点大小一般是相同的，为一页。
- B+ 树内节点不存储数据，所有 data 存储在叶节点导致查询时间复杂度固定为 log n。而 B 树查询时间复杂度不固定，与 key 在树中的位置有关，最好为O(1)。
- B+ 树叶节点两两相连可大大增加**区间访问性**，可使用在范围查询等，而 B 树每个节点 key 和 data 在一起，则无法区间查找。
- B+树更适合外部存储。由于内节点无 data 域，每个节点能容纳更多 key，能索引的范围更大更精确。

## 1.3 索引维护
B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 `ID` 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 `ID` 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。
![[image-36.png]]

而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为**页分裂**。在这种情况下，性能自然会受影响。
**除了性能外，页分裂操作还影响数据页的利用率**。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。

当然有分裂就有**合并**。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。
根据上一节 MVVC 中所述，删除其实只是标记被删除，并不释放磁盘空间。Innodb 存储引擎下，所有表都是这样的，当删除的记录达到页体积的百分之 50 才会尝试页合并。这样做减少了很多页合并操作，空间换时间。

## 1.4 自增主键
自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： `NOT NULL PRIMARY KEY AUTO_INCREMENT`。
插入新记录的时候可以不指定 `ID` 的值，系统会获取当前 `ID` 最大值加 1 作为下一条记录的 `ID` 值。也就是说，**自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景**。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。
并且，**主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小**。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。

**有没有什么场景适合用业务字段直接做主键的呢**？还是有的。比如，有些业务的场景需求是这样的：
1. 只有一个索引。
2. 该索引必须是唯一索引。
你一定看出来了，这就是典型的 **KV 场景**。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。

# 2 索引优化
## 2.1 索引 dive
MySQL优化器在真正执行查询之前，对于每个可能使用到的索引来说，都会预先计算一下需要扫描的二级索引记录的数量，比方说对于下边这个查询：
```sql
SELECT * FROM s1 WHERE key1='xx';
```
优化器会分析出此查询只需要查找`key1`值为`'xx'`的记录，然后访问一下二级索引`idx_key1`，看一下值为`'xx'`的记录有多少。如果符合条件的二级索引记录数量较少，那么统计结果是精确的，如果太多的话，会采用一定的手段计算一个模糊的值。
这种在查询真正执行前优化器就率先访问索引来计算需要扫描的索引记录数量的方式称之为`index dive`。

对于某些查询，比方说WHERE子句中有IN条件，并且IN条件中包含许多参数的话，比方说这样：
```sql
SELECT * FROM s1 WHERE key1 IN ('a', 'b', 'c', ... , 'zzzzzzz');
```
这样的话需要统计的`key1`值所在的区间就太多了，这样就不能采用`index dive`的方式去真正的访问二级索引`idx_key1`，而是需要采用之前在背地里产生的一些统计数据去估算匹配的二级索引记录有多少条。很显然根据统计数据去估算记录条数比`index dive`的方式精确性差了很多）。

反正不论采用`index dive`还是依据统计数据估算，最终要得到一个需要扫描的二级索引记录条数，如果这个条数占整个记录条数的比例特别大，那么就趋向于使用全表扫描执行查询，否则趋向于使用这个索引执行查询。

## 2.2 覆盖索引
在 [[#4.2.1.1 查询示例]] 中，如果执行的语句是 `select ID from T where k between 3 and 5`，这时只需要查 `ID` 的值，而 `ID` 的值已经在 `k` 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 `k` 已经“覆盖了”我们的查询需求，我们称为**覆盖索引**。
**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段**。

当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。

## 2.3 最左前缀原则
**B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录**。为了直观地说明这个概念，我们用 `(name，age)` 这个联合索引来分析。
![[image-38.png]]

当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 `ID4`，然后向后遍历得到所有需要的结果。
如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是 `where name like '张%'`。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 `ID3`，然后向后遍历，直到不满足条件为止。
可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。**这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符**。所以 `a%` 也可走索引，而 `%a%` 则没有。
**mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配**。
注意，`where` 条件里面的索引顺序是没有关系的。假如有组合索引 `a,b,c`，那么 `a,b,c`、`a,c`、`b,a`、`a` 等都会命中索引，但是 `b,c`、`b` 等会全表扫描。

如果既有联合查询，又有基于 `a`、`b` 各自的查询呢？查询条件里面只有 `b` 的语句，是无法使用 `(a,b)` 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 `(a,b)`、`(b)` 这两个索引。
这时候，我们要考虑的原则就是**空间**了。比如上面这个市民表的情况，`name` 字段是比 `age` 字段大的 ，那我就建议你创建一个 `(name,age)` 的联合索引和一个 `(age)` 的单字段索引。**这样字段长的只建立一次，短的建立两次**。

## 2.4 索引下推
我们还是以市民表的联合索引 `(name, age)` 为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：
```sql
mysql> select * from tuser where name like '张%' and age=10 and ismale=1;
```
这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 `ID3`。然后是判断其他条件是否满足。

在 MySQL 5.6 之前，只能从 `ID3` 开始一个个回表。到主键索引上找出数据行，再对比字段值。而 MySQL 5.6 引入的**索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数**。
下面两张图，是这两个过程的执行流程图：
![[image-39.png]]
![[image-40.png]]
它们的区别是，InnoDB 在 `(name,age)` 索引内部就判断了 `age` 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 `ID4`、`ID5` 这两条记录回表取数据判断，就只需要回表 2 次。

## 2.5 索引合并
索引合并(Index Merge)是 MySQL 优化器的一种查询优化技术，它允许对单个表的多个索引扫描结果进行合并，以提高查询性能。

### 2.5.1 索引合并的类型
MySQL 支持三种索引合并策略：
1. **Index Merge Intersection** (交集合并)
    - 对多个索引扫描结果取交集
    - 适用于 `AND` 连接的条件
2. **Index Merge Union** (并集合并)
    - 对多个索引扫描结果取并集
    - 适用于 `OR` 连接的条件
3. **Index Merge Sort-Union** (排序并集合并)
    - 对无法直接合并的索引扫描结果先排序再取并集
    - 适用于范围条件的 `OR` 连接

开启设置：
```bash
SET optimizer_switch='index_merge_intersection=on,index_merge_union=on,index_merge_sort_union=on';
```

### 2.5.2 会使用索引合并的情况
**多列独立索引的 OR 条件**：
```sql
SELECT * FROM users 
WHERE first_name = 'John' OR last_name = 'Smith';
```
- 需要 `first_name` 和 `last_name` 都有独立索引    
- 执行计划显示 `type: index_merge` 和 `Extra: Using union`

**多列独立索引的 AND 条件**：
```sql
SELECT * FROM users 
WHERE first_name = 'John' AND last_name = 'Smith';
```
- 当没有合适的组合索引时
- 执行计划显示 `type: index_merge` 和 `Extra: Using intersect`

**索引合并排序**：
```sql
SELECT * FROM users 
WHERE age < 20 OR salary > 10000;
```
- 当 `age` 和 `salary` 都有独立索引时
- 普通 Union 无法处理范围条件，Sort-Union 可以

**混合等值查询和范围查询的 OR 条件**：
```sql
SELECT * FROM products 
WHERE category = 'electronics' OR price > 5000;
```

**混合条件的复杂查询**：
```sql
SELECT * FROM users 
WHERE (first_name = 'John' AND age > 20) 
OR (last_name = 'Smith' AND status = 1);
```
可能各列有单独的索引：此时 MySQL 可能先分别用 `(first_name, age)` 和 `(last_name, status)` 条件扫描索引，然后合并结果集。`EXPLAIN` 会显示 `type: index_merge` 和 `Extra: Using union`或者有两个组合索引。
也可能有两个组合索引（分别对应 or 两边）：这是最优情况，MySQL 可能使用这两个组合索引进行 Index Merge，效率比单列索引合并更高。
也可能只有部分列有索引：例如只有 `first_name` 和 `last_name` 有索引：MySQL 只能使用这两个索引做合并，然后对合并结果进行 age > 20 和 status = 1 的过滤，效率较低。

### 2.5.3 不会使用索引合并的情况
1. 全表扫描代价更低时：当优化器判断全表扫描比索引合并更高效时
2. 没有合适的独立索引：查询条件涉及的列没有独立索引    
3. 使用 `FORCE INDEX` 强制使用特定索引时
4. 系统禁用了索引合并：`SET optimizer_switch='index_merge=off';`
5. 涉及全文索引或空间索引时

### 2.5.4 索引合并的限制
1. 性能不一定最优：
    - 索引合并通常不如一个合适的组合索引高效
    - 合并操作本身有开销
2. 只适用于单个表：不能跨表合并索引扫描结果
3. 列必须完全独立：合并的索引不能有重叠列
4. 结果集大小影响：当合并结果集很大时，性能可能下降

### 2.5.5 优化建议
1. 优先考虑组合索引
2. 使用 `UNION ALL` 替代复杂 OR 条件
```sql
SELECT * FROM users WHERE first_name = 'John'
UNION ALL
SELECT * FROM users WHERE last_name = 'Smith';
```
3. 统计信息更新：`ANALYZE TABLE users;`
4. 使用查询提示：
```sql
SELECT /*+ INDEX_MERGE(users first_name, last_name) */ * FROM users 
WHERE (first_name = 'John' AND age > 20) 
OR (last_name = 'Smith' AND status = 1);
```

### 2.5.6 索引合并可能导致死锁
例如下面的sql：
```sql
update sop_task_statistics set task_num = task_num + #{dto.taskNum}, score = score + #{dto.score}
where slxt_account = #{dto.slxtAccount} and area_id = #{dto.areaId} and month_date = #{dto.monthDate}
```
因为数据库表分别对slxt_account、area_id、month_date字段建了索引，所以在执行上面的sql时会对上面的三个字段索引进行了锁定操作，并且进行了回表操作时也对主键索引进行了锁定，所以对索引的锁定次数达到了6次。注意，`select...for update`也可能出现这种情况。

我们用两个事务来分析下该sql的执行过程：
![[image-42.png]]

解决上面的问题有以下几种方法：
1. 创建组合索引（slxt_account,area_id,month_date）,这样在执行上面的sql语句时，通过组合索引直接定位到具体的主键索引id，更新操作变成了行锁，并且锁粒度细化到一行，这样就不会导致两个事务都锁定了对方需要获取到才能继续往下执行的资源。
2. 先查询，查询操作不会发生锁操作，查询到具体的主键id，然后通过id进行更新操作
3. 显示指定索引，固定执行计划，避免索引合并问题。

## 2.6 or 走不走索引
除非 or 的条件都是一个字段、或者符合索引合并，或者 OR 条件的选择性很高时（匹配很少行）才会走索引。
如果 or 的条件不是一个字段，考虑使用 UNION ALL 进行优化。

## 2.7 不等于走不走索引
通常情况下，`!=` 运算符不会使用索引。在某些特定条件下，优化器可能会选择使用索引：
- 当 `!=` 查询匹配行数不多，优化器任务代价不大时
- 当 `!=` 查询能走覆盖索引时

## 2.8 Order by 走不走索引
走索引的情况：
1. 如果一个SQL语句形如：
```sql
SELECT [column1],[column2],…. FROM [TABLE] ORDER BY [sort];
```
在[sort]这个栏位上建立索引就可以实现利用索引进行order by 优化。
2. WHERE + ORDER BY的索引优化，形如：
```sql
SELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] = [value] ORDER BY [sort];
```
建立一个联合索引(columnX,sort)来实现order by 优化，从而避免 file sort。比建立(sort,columnX)索引效果要好得多。

不走索引的情况：
1. 对不同的索引键做 ORDER BY ：(key1,key2分别建立索引)
```sql
SELECT * FROM t1 ORDER BY key1, key2;
```
2. 不符合最左前缀：(key_part1,key_part2建立联合索引)
```sql
SELECT * FROM t1 WHERE key2=constant ORDER BY key_part2;
```
3. 同时使用了 ASC 和 DESC：(key_part1,key_part2建立联合索引)
```sql
SELECT * FROM t1 ORDER BY key_part1 DESC, key_part2 ASC;
```
4. ORDER BY的栏位上应用表达式(函数)时，则无法利用索引来实现order by的优化
```sql
SELECT * FROM t1 ORDER BY YEAR(logindate) LIMIT 0,10;
```

# 3 普通索引和唯一索引
许多场合，人们创建唯一索引的目的往往不是为了提高访问速度，而只是为了避免数据出现重复。
对于普通索引来说，查找到满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个不满足条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

在不同的业务场景下，应该选择普通索引，还是唯一索引？假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似这样的 SQL 语句：
```sql
select name from CUser where id_card = 'xxxxxxxyyyyyyzzzzz';
```
**从性能的角度考虑，你选择唯一索引还是普通索引呢？选择的依据是什么呢**？

简单起见，我们还是用[[#1.2.1.1 查询示例]]中的例子来说明，假设字段 `k` 上的值都不重复。接下来，我们就从这两种索引对查询语句和更新语句的性能影响来进行分析。

## 3.1 查询过程
假设，执行查询的语句是 `select id from T where k=5`。
- 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 `k=5` 条件的记录。    
- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

这个不同带来的性能差距会有多少呢？答案是，**微乎其微**。你知道的，**InnoDB 的数据是按数据页为单位来读写的**。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。
当然，如果 `k=5` 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。
但是，我们之前计算过，对于整型字段，一个数据页可以放近千个 `key`，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。

## 3.2 更新过程
### 3.2.1 change buffer
为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下 **change buffer**。
当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，**InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了**。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。
需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。

**将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。**除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。

**对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束**。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，**而这必须要将数据页读入内存才能判断**。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。
因此，**唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用**。

change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 `innodb_change_buffer_max_size` 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

### 3.2.2 change buffer 的使用场景
现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？
因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，**所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大**。

因此，对于**写多读少**的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
反过来，假设一个业务的更新模式是**写入之后马上会做查询**，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。

## 3.3 索引选择和实践
大家对“是否使用唯一索引”有比较多的讨论，主要是纠结在“业务可能无法确保”的情况。这里，我再说明一下：
1. 首先，业务正确性优先。咱们这篇文章的前提是“业务代码已经保证不会写入重复数据”的情况下，讨论性能问题。如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。
	这种情况下，本篇文章的意义在于，如果碰上了大量插入数据慢、内存命中率低的时候，可以给你多提供一个排查思路。
2. 然后，在一些“归档库”的场景，你是可以考虑使用普通索引的。比如，线上数据只需要保留半年，然后历史数据保存在归档库。这时候，归档数据已经是确保没有唯一键冲突了。**要提高归档效率，可以考虑把表里面的唯一索引改成普通索引**。

## 3.4 change buffer 和 redo log
现在，我们要在表上执行这个插入语句：
```mysql
mysql> insert into t(id,k) values(id1,k1),(id2,k2);
```
这里，我们假设当前 `k` 索引树的状态，查找到位置后，`k1` 所在的数据页在内存 (InnoDB buffer pool) 中，`k2` 所在的数据页不在内存中。如图 2 所示是带 change buffer 的更新状态图。
![[image-46.png]]

分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）[^1]。
这条更新语句做了如下的操作（按照图中的数字顺序）：
1. Page 1 在内存中，直接更新内存；
2. Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息
3. 将上述两个动作记入 redo log 中（图中 3 和 4）。
图中的两个虚线箭头，是后台操作，不影响更新的响应时间。

那在这之后的读请求，要怎么处理呢？比如，我们现在要执行 `select * from t where k in (k1, k2)`。这里，我画了这两个读请求的流程图。
如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分。
![[image-47.png]]
从图中可以看到：
1. 读 Page 1 的时候，直接从内存返回。
2. 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。

redo log 与 change buffer(含磁盘持久化) 这2个机制，不同之处在于——优化了整个变更流程的不同阶段。 先不考虑redo log、change buffer 机制，简化抽象一个变更(insert、update、delete)流程：
1. 从磁盘读取待变更的行所在的数据页，读取至内存页中。
2. 对内存页中的行，执行变更操作。
3. 将变更后的数据页，写入至磁盘中。
步骤1，涉及随机读磁盘 IO；步骤3，涉及随机写磁盘 IO。**change buffer 机制，优化了步骤1——避免了随机读磁盘IO；redo log 机制， 优化了步骤3——避免了随机写磁盘IO，将随机写磁盘，优化为了顺序写磁盘**。

# 4 MySQL为什么有时候会选错索引
## 4.1 案例分析
不知道你有没有碰到过这种情况，一条本来可以执行得很快的语句，却由于 MySQL 选错了索引，而导致执行速度变得很慢？
我们一起来看一个例子吧。我们先建一个简单的表，表里有 `a`、`b` 两个字段，并分别建上索引：
```sql
CREATE TABLE `t` (
  `id` int(11) NOT NULL PRIMARY KEY AUTO_INCREMENT,
  `a` int(11) DEFAULT NULL,
  `b` int(11) DEFAULT NULL,
  KEY `a` (`a`),
  KEY `b` (`b`)
) ENGINE=InnoDB;
```

然后，我们往表 t 中插入 10 万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到 (100000,100000,100000)。我是用存储过程来插入数据的，这里我贴出来方便你复现：
```sql
delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=100000)do
    insert into t(a,b) values(i, i);
    set i=i+1;
  end while;
end;;
delimiter ;

# 注意要写上事务语句执行存储过程。原因是事务隐式提交，这里提交了 10w 次。你每次事务提交就要提交一次 redo 日志缓存，然后 redo 日志缓存又要写入磁盘，所以快速一点的方法是在外面包一层事务，速度明显提升
# 或者也可以在存储过程的 while 循环外包上事务语句
start transaction;
call idata();
commit;
```

在我们已经准备好的包含了 10 万行数据的表上，我们再做如下操作。
![[image-49.png]]
session A 就是开启了一个事务。随后，session B 把数据都删除后，又调用了 `idata` 这个存储过程，插入了 10 万行数据。
这时候，session B 的查询语句 `select * from t where a between 10000 and 20000` 就不会再选择索引 `a` 了。

我们可以通过**慢查询日志 slow log**来查看一下具体的执行情况。
为了说明优化器选择的结果是否正确，我增加了一个对照，即：使用 `force index(a)` 来让优化器强制使用索引 `a`（这部分内容，我还会在这篇文章的后半部分中提到）。下面的三条 SQL 语句，就是这个实验过程。
```sql
set long_query_time=0; # 记录所有执行时间超过 long_query_time 秒的所有查询
select * from t where a between 10000 and 20000; /*Q1*/
select * from t force index(a) where a between 10000 and 20000; /*Q2*/
```
如图 3 所示是这三条 SQL 语句执行完成后的慢查询日志。
![[image-50.png]]
可以看到，Q1 扫描了 10 万行（MySQL 8.0.18中，修复了这个情况，会使用索引 `a`，可能是改变了统计索引的策略），显然是走了全表扫描，执行时间是 40 毫秒。Q2 扫描了 10001 行，执行了 21 毫秒。也就是说，我们在没有使用 `force index` 的时候，MySQL 用错了索引，导致了更长的执行时间。
**这个例子对应的是我们平常不断地删除历史数据和新增数据的场景**。这时，MySQL 竟然会选错索引，是不是有点奇怪呢？今天，我们就从这个奇怪的结果说起吧。

## 4.2 优化器和扫描行数
选择索引是优化器的工作。而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。**在数据库里面，扫描行数是影响执行代价的因素之一**。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。
当然，**扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断**。
我们这个简单的查询语句并没有涉及到临时表和排序，所以 MySQL 选错索引肯定是在判断扫描行数的时候出问题了。那么，问题就是：**扫描行数是怎么判断的**？

### 4.2.1 索引基数和采样统计
MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。**这个统计信息就是索引的“区分度”**。显然，一个索引上不同的值越多，这个索引的区分度就越好。而**一个索引上不同的值的个数，我们称之为“基数”（cardinality）**。也就是说，这个基数越大，索引的区分度越好。
我们可以使用 `show index` 方法，看到一个索引的基数。如图 4 所示，就是表 `t` 的 `show index` 的结果 。虽然这个表的每一行的三个字段值都是一样的，但是在统计信息中，这三个索引的基数值（Cardinality）并不同，而且其实都不准确。
![[image-48.png]]

MySQL 是怎样得到索引的基数的呢？把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择**“采样统计”**。采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。
而数据表是会持续更新的，索引统计信息也不会固定不变。所以，**当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计**。在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 `innodb_stats_persistent` 的值来选择：
- 设置为 `on` 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
- 设置为 `off` 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。

你可以从上面的图看到，这次的索引统计值虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。
其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。

### 4.2.2 代价估计
接下来，我们再一起看看优化器预估的，这两个语句的扫描行数是多少。
![[image-51.png]]
rows 这个字段表示的是预计扫描行数。其中，Q1 的结果还是符合预期的，rows 的值是 104620；但是 Q2 的 rows 值是 37116（不是 10001），偏差就大了。
可能你的第一个疑问不是为什么不准，而是优化器为什么放着扫描 37000 行的执行计划不用，却选择了扫描行数是 100000 的执行计划呢？这是因为，**如果使用索引 `a`，每次从索引 `a` 上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的**。而如果选择扫描 10 万行，是直接在主键索引上扫描的，没有额外的代价。
需要注意的是，**mysql的回表次数不会计算在explain的row扫描行数中**，因为server层的执行器每次获取到一次数据，计扫描一行，而**回表不需要经过server层**。

MySQL 选错索引，这件事儿还得**归咎到没能准确地判断出扫描行数**。至于为什么，是**因为另一个事务仍未提交，所有的更新都是记录在 undo log 中，因此删除的数据只是标记删除**，数据仍然在数据页中；**又因为新插入的主键与原来不同**，session B后插入的数据需要找新的空位插入。所以出现的情况就是delete虽然删除了,但是未释放空间,insert又增加了空间。而索引的统计选择了N个数据页，这部分数据页不收到前台事务的影响，所以整体统计值会变大，直接影响了索引选择的准确性。

### 4.2.3 analyze
`analyze table t` 命令，可以用来重新统计索引信息。我们来看一下执行效果：
![[image-52.png]]
所以在实践中，如果你发现 `explain` 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。

## 4.3 其他索引选择异常和处理
如果只是索引统计不准确，通过 `analyze` 命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。依然是基于这个表 `t`，我们看看另外一个语句：
```mysql
mysql> select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;
```
从条件上看，这个查询没有符合条件的记录（因为 `a == b`），因此会返回空集合。在开始执行这条语句之前，你可以先设想一下，如果你来选择索引，会选择哪一个呢？为了便于分析，我们先来看一下 `a`、`b` 这两个索引的结构图。
![[image-53.png]]

如果使用索引 `a` 进行查询，那么就是扫描索引 `a` 的前 1000 个值，然后取到对应的 `id`，再到主键索引上去查出每一行，然后根据字段 `b` 来过滤。显然这样需要扫描 1000 行。如果使用索引 `b` 进行查询，那么就是扫描索引 `b` 的最后 50001 个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描 50001 行。
所以你一定会想，如果使用索引 `a` 的话，执行速度明显会快很多。那么，下面我们就来看看到底是不是这么一回事儿。图 8 是执行 `explain` 的结果。
![[image-54.png]]
可以看到，返回结果中 key 字段显示，这次优化器选择了索引 `b`，而 rows 字段显示需要扫描的行数是 50198。

因为有 order by b，优化器认为走索引 b 可以避免排序；又有 limit 1，优化器认为只要找到了 1 条满足条件的记录，索引 b 的遍历就可以提前终止，虽然可能要遍历 50001 条记录，但是优化器认为这是值得冒险的事，所以决定了走索引 b。

### 4.3.1 使用 force index
**一种方法是，像我们第一个例子一样，采用 `force index` 强行选择一个索引**。
刚开始分析时，我们认为选择索引 `a` 会更好。现在，我们就来看看执行效果：
![[image-55.png]]
可以看到，原本语句需要执行 2.23 秒，而当你使用 `force index(a)` 的时候，只用了 0.05 秒，比优化器的选择快了 40 多倍。也就是说，优化器没有选择正确的索引，`force index` 起到了“矫正”的作用。

### 4.3.2 引导 MySQL
**我们可以考虑修改语句，引导 MySQL 使用我们期望的索引**。比如，在这个例子里，显然把 `order by b limit 1`” 改成 `order by b,a limit 1` ，语义的逻辑是相同的。我们来看看改之后的效果：
![[image-56.png]]
现在 `order by b,a` 这种写法，要求按照 `b,a` 排序，就意味着使用这两个索引都需要排序。因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描 1000 行的索引 `a`。

如果你觉得修改语义这件事儿不太好，这里还有一种改法。
```mysql
mysql> select * from  (select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1;
```
![[image-57.png]]
在这个例子里，我们用 `limit 100` 让优化器意识到，使用 `b` 索引代价是很高的。其实是我们根据数据特征诱导了一下优化器，也不具备通用性。`limit` 了之后，它就知道最多取 100 条数据。当看到 `b` 的第一步扫描要比 `a` 的第一步扫描多这么多，而多出来的这些都不会进入第二次扫描(因为只取前 100条)，MySQL 就会选择 `a` 做索引来减少第一次扫描的量。

### 4.3.3 选择合适的索引
第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。
不过，在这个例子中，我没有找到通过新增索引来改变优化器行为的方法。这种情况其实比较少，尤其是经过 DBA 索引优化过的库，再碰到这个 bug，找到一个更合适的索引一般比较难。
如果我说还有一个方法是删掉索引 `b`，你可能会觉得好笑。但实际上我碰到过两次这样的例子，最终是 DBA 跟业务开发沟通后，发现这个优化器错误选择的索引其实根本没有必要存在，于是就删掉了这个索引，优化器也就重新选择到了正确的索引。

# 5 字符串加索引
[[TODO]]

---
# 6 引用
[!=走不走索引](https://juejin.cn/post/6844903921450745863)


[^1]: 数据表空间：就是一个个的表数据文件，对应的磁盘文件就是“表名.ibd”； 系统表空间：用来放系统信息，如数据字典等，对应的磁盘文件是“ibdata1”。
2025-12-06 17:23
Status: #idea
Tags:

# 1 面试问题
## 1.1 hive SQL 和 mysql 有什么区别？它比mysql有什么优势？
sql 层面的不同：
- MySQL：支持标准 SQL，侧重事务型功能（索引、存储过程、触发器），靠索引提升单条记录查询效率。
- Hive：HiveSQL 是类 SQL，扩展了大数据适配功能（比如自定义函数 UDF）。
	- hive sql很适合做覆写一个表的整个分区或追加操作，但是像mysql那样修改某一条记录则很低效。
	- 但是它能处理多表关联、复杂聚合这类 MySQL 扛不住的计算。

hive难以细粒度的修改数据，不是它的缺陷，而是它和mysql的应用场景不同。

核心定位与场景（最根本）：
- MySQL 是**联机事务处理（OLTP）** 数据库，它面向实时处理场景
- Hive不是数据库，而是**基于 Hadoop 的 SQL 解析引擎和定义数据的存储格式**，属于联机分析处理（OLAP）。面向大数据离线分析场景，适合低频次、TB/PB 级海量数据的批量分析和计算
	- **离线分析场景本就不需要频繁改单条数据**。

底层存储与计算（差异的根源）：
- MySQL：**数据存在本地文件系统** / 共享存储（如 SAN），**计算依赖单机** / 小集群，能力受单节点 CPU / 内存限制；用 InnoDB 等引擎做**行式存储**，行式存储适合随机读写单条记录，所以能支持细粒度更新。
- Hive：本身不存数据，数据全靠 **HDFS（Hadoop 分布式文件系统）** 存储 ——HDFS 是分布式、高容错的，能**横向扩容到成百上千节点，天生适配海量数据**。计算则把 Hive SQL 翻译成 Spark/MapReduce 分布式任务，分散到集群节点并行执行。Hive 默认用 ORC/Parquet **列式存储**，只读取分析需要的列（比如算成本只读价格、数量列，不用读全表），批量分析效率远高于行式存储。

数据操作与事务：
- MySQL：支持细粒度增删改查、完整 ACID 事务、行锁 / 表锁，这是为了满足交易场景的一致性（比如改一笔订单的价格）。
- Hive：早期不支持细粒度更新和事务，不是 “缺陷”，而是**适配 HDFS 特性** ——HDFS 文件写入后难以修改（追加可行，修改成本极高），所以核心操作是 “覆盖 / 追加分区”（比如按日期分区计算每日成本，直接写入当天分区）。
	- Hive 3.0 后虽支持 ACID，但仅用于缓慢变化维度等小众场景，并非核心设计目标，因为**离线分析场景本就不需要频繁改单条数据**（成本算价只需要批量计算全量数据，不需要改某一条物料的价格）。

扩展性与性能：
- MySQL：垂直扩展为主（升级服务器配置），水平扩展（分库分表）复杂度高，能处理 GB 级数据，毫秒级响应。
- Hive：水平扩展简单（加集群节点即可），能线性提升存储 / 计算能力，处理 TB/PB 级数据，高吞吐但延迟高（符合离线分析的节奏）。

## 1.2 Hive的底层结构是什么呢？
### 1.2.1 Hive 的存储底层：先明确 “Hive 不存数据，只映射数据”
Hive 本身不是数据库，没有自己的存储引擎 —— 它的 “存储” 分为两层：
1. **元数据层**：表结构、分区信息、数据存储路径、文件格式等（存在 Metastore，通常用 MySQL 托管）；
2. **实际数据层**：所有数据都以文件形式存在 HDFS 上（分布式存储，数据分散在集群多个节点），Hive 只是通过 SQL 解析，映射到 HDFS 的文件。

而 Hive 的核心优化，就体现在 “HDFS 上的文件格式”—— 日常用的 ORC/Parquet 是**列式存储**，这是和 MySQL 行式存储的核心差异，也是 Hive 能高效处理批量分析的关键。

### 1.2.2 核心重点：Hive 列式存储（ORC/Parquet）的底层工作机制
#### 1.2.2.1 列式存储的 “数据组织方式”（核心：按列分块，而非按行）
假设成本算价表有 4 列：`order_id（订单ID）、price（单价）、quantity（数量）、date（日期）`，共 100 万行数据：
- **MySQL 行式存储**：把每一行的所有字段存在一起（比如一行是「1001, 50.0, 2, 20251001」），100 万行就是 100 万个 “行数据块”，读的时候要么读整行，要么通过 B + 树找某一行；
- **Hive ORC 列式存储**：（Parquet 逻辑类似，只是分块 / 压缩细节不同）把所有列的数据单独聚合，拆成 “列块 + 元数据” 的分层结构，最终存在 HDFS 的一个 / 多个文件里，结构如下（从大到小）：
	- 文件头（File Header）：存列数、压缩方式、文件创建时间等全局元数据
	- 多个Stripe（列块，默认250MB/个）：ORC的核心数据单元，分布式计算按Stripe并行处理。列块内部会做 “编码 + 压缩”
		- Index Data（列索引）：每列的轻量索引（比如price列的min=10.0、max=1000.0，date列的min=20251001、max=20251031）
		- Row Data（行数据）：按列存储的实际数据（所有order_id放一个块，所有price放一个块，以此类推）
		- Stripe Footer：存该Stripe的列偏移量、数据长度等
	- 文件尾（File Footer）：存所有Stripe的统计信息、列的总统计、数据偏移量等

#### 1.2.2.2 为什么列式存储批量分析更快？


---
# 2 引用
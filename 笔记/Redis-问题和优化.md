2025-11-26 16:03
Status: #idea
Tags:

# 1 缓存三大问题
## 1.1 缓存雪崩
缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理。应用将大量请求发送到数据库层，导致数据库层的压力激增。
原因和处理如下：
1. 第一个原因是有**大量数据同时过期**，处理方法：给过期时间加一个较小的随机数。
2. 第二个原因是**Redis 缓存实例故障宕机**，处理方法如下：
	1. 在业务系统中实现服务熔断或请求限流机制：当 Redis 不可用时，对数据库的请求进行限流；或者直接返回 "活动繁忙，请稍后再试"，不请求数据库。
	2. Redis 采用集群架构（如 3 主 3 从），避免单点故障
3. 第三个原因是**一致性hash环的集群特性**导致的：集群中某个节点挂掉了，请求分散到其他集群，但把其他集群也都冲垮了。 解决办法：如果场景是热的极热、冷的极冷，不建议使用一致性hash环。

## 1.2 缓存击穿
缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。
缓存击穿的情况，**经常发生在热点数据过期失效时**。

为了避免缓存击穿给数据库带来的激增压力，解决方法：
1. 对于访问特别频繁的热点数据不设置or设置比业务时间长的过期时间。
2. 访问数据时，刷新过期时间；
3. 如果访问太频繁可以定时刷新过期时间。
 
此外对数据库的访问要做好限流和熔断。

## 1.3 缓存穿透
缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。这样一来，缓存也就成了“摆设”，如果应用持续有大量请求访问数据，就会同时给缓存和数据库带来巨大压力。

一般来说，有两种情况：
- 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；
- 恶意攻击：专门访问数据库中没有的数据。

解决方法：
1. **第一种方案是，缓存空值或缺省值**。一旦发生缓存穿透，我们就可以针对查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值（例如，库存的缺省值可以设为 0）。这种情况的失效时间都设置比较短
2. **第二种方法是，使用布隆过滤器快速判断数据是否不存在，避免从数据库中查询数据是否存在，减轻数据库压力**。
	- 布隆过滤器由一个初值都为 0 的 bit 数组和 N 个哈希函数组成，可以用来快速判断某个数据是否存在。当我们想标记某个数据存在时（例如，数据已被写入数据库），布隆过滤器会通过三个操作完成标记：
		1. 首先，使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值。
	    2. 然后，我们把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置。
	    3. 最后，我们把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作。
    - **注意Redis实现的布隆过滤器bigkey问题**：Redis布隆过滤器是使用String类型实现的，存储的方式是一个bigkey，建议使用时单独部署一个实例，专门存放布隆过滤器的数据，不要和业务数据混用，否则在集群环境下，数据迁移时会导致Redis阻塞问题。
    - **预加载**：应用刚启动的时候，布隆过滤器全是0，所以需要预加载，把数据库的数据都来过滤器这边设置一遍。
    - TODO:
	    - 布隆过滤器和数据库一致性问题
	    - 删除数据后，怎么处理布隆过滤器？
3. **最后一种方案是，在请求入口的前端进行请求检测**。缓存穿透的一个原因是有大量的恶意请求访问不存在的数据。

# 2 BigKey
## 2.1 定义
Bigkey 是指 占用内存过大或元素数量过多 的 Redis Key，没有统一标准，通常参考：
- 字符串类型：体积 > 10KB（或根据业务调整为 50KB/100KB）；
- 集合类型（Hash/List/Set/ZSet）：元素数量 > 10000 个，或整体体积 > 100KB。

Bigkey 会导致：内存碎片化、主从同步延迟、过期删除 / DEL 命令阻塞、网络带宽占用过高 等问题。

## 2.2 Bigkey 发现与排查
核心思路：**非阻塞扫描 + 精确统计 + 监控预警**，避免使用 `KEYS *`（阻塞全量扫描）。

### 2.2.1 直接排查工具 / 命令
1. `redis-cli --bigkeys`（最常用）
	- 功能：非阻塞扫描所有 Key，按类型（string/hash/list/set/zset）统计 **最大 Key 的体积 / 元素数**，并输出整体分布；
	- 原理：基于 `SCAN` 迭代扫描，不会阻塞 Redis 主线程；
	- 用法：`redis-cli -h 127.0.0.1 -p 6379 -a password --bigkeys`
2. `MEMORY USAGE key [SAMPLES count]`（精确统计单 Key 内存）
	- 功能：返回 Key 的 **实际占用内存（包括元数据）**，集合类型可通过 `SAMPLES` 指定抽样字段数（默认 5）；
	- 用法：`MEMORY USAGE order:detail:202405 SAMPLES 100`
3. `SCAN` 迭代扫描 + 批量统计
	- 场景：需要自定义筛选条件（如只查哈希类型、按体积阈值过滤）；
	- 原理：`SCAN cursor MATCH pattern COUNT count` 非阻塞迭代，配合 `TYPE`/`MEMORY USAGE` 过滤，自己写代码实现流程

### 2.2.2 监控预警工具
1. Redis 自带监控
	- `INFO memory`：查看整体内存占用、碎片率，间接判断是否有 Bigkey（如内存突增但 Key 数少）；
	- `INFO replication`：主从同步延迟（Bigkey 同步占用带宽，延迟 > 1s 需警惕）；
	- 慢查询日志：`CONFIG SET slowlog-log-slower-than 10000`（记录 >10ms 命令），Bigkey 的 `GET`/`HGETALL`/`DEL` 易触发。
2. 第三方监控
	- Redis Insight：可视化 Key 大小、类型分布，支持筛选 Bigkey；
	- Prometheus + Grafana：通过 `redis_key_size`（需 exporter 采集）指标设置告警（如 Key 大小 > 50KB 报警）；
	- 业务监控：记录 Redis 命令耗时，若 `GET`/`HGETALL` 等命令耗时突增，可能是 Bigkey 导致。

## 2.3 Bigkey 解决方法
核心原则：**拆分（优先）、压缩、异步删除、替换存储**，避免直接 `DEL` 阻塞。

### 2.3.1 按 Key 类型针对性处理
1. 字符串类型（大文本 / 二进制）
	- 拆分：将大字符串按固定大小拆分（如 10KB / 段），存储为 `key:1`、`key:2`，读取时拼接；
	    - 示例：用户头像（20KB）→ 拆分为 `avatar:10086:1`（10KB）、`avatar:10086:2`（10KB）；
	- 压缩：用 `gzip` 压缩后存储（需业务层解压），适合文本类数据（压缩比可达 3-10 倍）；
	- 替换存储：大文件（如 >1MB）迁移至对象存储（OSS/S3），Redis 只存文件 URL 或索引。
2. 哈希类型（字段过多，如 >10000 个）
	- 分片拆分：按字段前缀 / 哈希取模拆分到多个哈希表；
    - 示例：订单详情 `order:detail`（10 万字段）→ 按用户 ID 取模 `order:detail:{uid%100}`，拆分到 100 个哈希表；
	- 冷热分离：只保留热点字段在 Redis，冷字段迁移至 MySQL/ES。
3. 列表类型（元素过多，如日志 / 消息队列）
	- 按时间分片：按天 / 小时拆分列表，如 `log:20240520`、`log:20240521`，定期删除历史列表；
	- 限制长度：用 `LPUSH + LTRIM` 组合，只保留最近 N 个元素（如 `LTRIM log:latest 0 9999` 保留 1 万条）；
	- 替换存储：高吞吐场景用 Kafka/RabbitMQ 替代 Redis 列表做消息队列。
4. 集合 / 有序集合（元素过多）
	- 分片拆分：按元素哈希取模拆分，如 `user:tags:{uid%50}`，拆分到 50 个集合；
	- 冷热分离：热点元素保留在 Redis，冷元素迁移至 ES/ClickHouse。

### 2.3.2 安全删除 Bigkey（避免阻塞）
1. Redis 4.0+：`UNLINK` 命令（推荐），异步删除 Key，主线程只标记 Key，后台线程异步清理内存，无阻塞；
2. 分批删除集合类型 Bigkey
	- 哈希：`HSCAN` 迭代删除字段（每次删 100 个，避免阻塞）
	- 列表：`LPOP/RPOP` 分批删除（每次删 1000 个）
	- 集合 / ZSet：`SSCAN/ZSCAN` 迭代删除元素，逻辑同哈希。

## 2.4 避免 Bigkey 出现的最佳实践
1. 设计层面：提前规避
	- 数据分片标准化：
	    - 集合类型：单 Key 元素数上限控制（如 ≤ 5000 个），超过则自动分片；
	    - 字符串类型：单 Key 体积上限（如 ≤ 10KB），大数据优先用对象存储；
	- Key 结构设计：
	    - 避免用 `all:xxx` 类 Key（如 `all:users` 存储所有用户），改为按维度分片（`user:10086`、`user:10087`）；
	    - 哈希类型：按业务模块拆分字段（如 `user:info:10086` 存基础信息，`user:tags:10086` 存标签），避免单哈希存所有字段。
2. 开发层面：规范操作
	- 禁用高危命令：
	    - 集合类型：禁用 `HGETALL`/`SMEMBERS`/`ZRANGEBYSCORE 0 +inf`（全量获取元素），改用 `HSCAN`/`SSCAN` 迭代获取；
	    - 字符串类型：避免存储大文本 / 二进制，优先存索引 / ID；
	- 序列化优化：用 Protocol Buffers（PB）替代 JSON（体积小 30%-50%），减少单 Key 体积；
	- 过期策略：给 Key 设置合理过期时间（`EXPIRE`），避免数据长期堆积形成 Bigkey。
3. 监控层面：提前预警
4. 运维层面：兜底保障
	- 内存碎片清理：开启 Redis 自动内存碎片整理（`CONFIG SET activedefrag yes`），避免 Bigkey 删除后产生大量碎片；
	- 定期数据迁移：将冷数据从 Redis 迁移至低成本存储（如 MySQL/ES），保持 Redis 存储热点数据。

# 3 如何存储很多key
## 3.1 问题
在用Redis存储诸如商品库存缓存时，如果每个商品都在Redis中存储一个键值对，那么商品数量多了，对Redis性能会有较大影响吗？ 
如果把商品按照某种方法划分成不同的map，这样Redis存储的键值对数量就少了，转而存多个map。这种方法的缺点是不能对单独的商品设置过期时间了。而且它真的比上面方法的性能要好吗？

## 3.2 单键存储优缺点
Redis 的键空间（key space）是基于哈希表实现的，核心操作（GET/SET/DEL）的时间复杂度都是O(1)，这意味着：即使有几百万、几千万个商品键，Redis 的单键读写性能依然非常高，不会出现明显的性能衰减。
但这并不代表单键存储没有问题，它的影响主要体现在**内存开销**和**管理成本**上，而非核心读写性能：
1. **内存开销更大**：每个 Redis 键都带有元数据（如过期时间、数据类型、LRU 缓存淘汰相关信息、dictEntry 结构体等），这部分开销大约是**几十字节**（比如一个 dictEntry 约占 32/64 字节，具体取决于系统架构）。如果有 1000 万个商品键，仅元数据的开销就可能达到几百 MB 甚至 GB 级别，而哈希 map 可以大幅减少这种元数据开销。
2. **持久化压力**：RDB 和 AOF 持久化时，处理大量小键的序列化 / 反序列化开销，会比处理少量哈希键更大。
3. **键管理更麻烦**：比如用`SCAN`命令遍历所有商品库存键时，遍历 1000 万个单键比遍历几百个哈希键要耗时；生产环境中禁用的`KEYS`命令更是会直接阻塞 Redis。

## 3.3 哈希 map 存储的优缺点及性能对比
将商品按规则（如分类、ID 区间）划分到不同的哈希 map 中（比如`stock:category_1`对应分类 1 的所有商品库存，`stock:id_0_999`对应 ID0-999 的商品库存），这种方式的性能和优点如下：
- **内存效率极高**：哈希 map 将多个商品的库存数据归到一个 key 下，仅需一份键元数据，能节省大量内存（尤其是当商品数量庞大时）。
    - 更关键的是，Redis 的哈希有**ziplist（压缩列表）** 内部编码：当哈希的字段数量少（默认≤512 个，可配置`hash-max-ziplist-entries`）、字段值小（默认≤64 字节，可配置`hash-max-ziplist-value`）时，会使用 ziplist 存储，这种编码的内存利用率远超单键的哈希表结构。
- **批量操作更高效**：可以用`HMGET/HMSET/HINCRBY`等命令批量操作同一哈希中的多个商品，减少网络请求次数（相比多次`GET/SET`），降低网络往返开销。
- **键数量大幅减少**：简化了键的管理，遍历和维护成本更低。

主要缺点：
- **无法单独设置过期时间**：这是**最核心的缺点**。Redis 的过期时间只能作用于**键**，不能作用于哈希的**字段**。如果你的业务需要单个商品库存缓存过期（比如某商品下架后缓存自动失效），这种方式就会受限。
- **数据分片困难**：如果一个哈希的字段数量过多，后续想要将数据分片到不同 Redis 节点（比如集群扩容），会比单键存储更麻烦（单键可直接用一致性哈希分片）。
- **大哈希的潜在问题**：
    - 当哈希的字段数量超过 ziplist 的阈值，Redis 会将其内部编码切换为`hashtable`，此时内存开销会增加，且操作的常数项耗时会变大（虽然还是 O (1)）。
    - 如果一个哈希中有几十万个字段，执行`HGETALL/HKEYS`等命令会一次性返回大量数据，可能造成 Redis 阻塞和网络带宽占用（解决方案：用`HSCAN`遍历字段）。

和单键存储对比：在核心读写性能上，两者几乎没有差异；但在内存效率和批量操作上，哈希 map 更有优势。

## 3.4 折中方案：兼顾哈希优势和单个过期需求
如果你既想利用哈希 map 的内存优势，又需要单个商品的过期时间，可以参考以下方案：
1. **分段哈希 + 短过期时间**：将商品分成更小的哈希段（比如每个哈希只存 100 个商品），给每个哈希键设置一个较短的过期时间（比如 5 分钟），业务层在读取时如果缓存失效，就重新从数据库加载并刷新缓存。这种方式牺牲了一点过期精度，但能兼顾性能和过期需求。
2. **哈希 map + 额外过期存储**：单独用一个 ZSET（有序集合）存储商品的过期时间，比如`expire:stock`的 ZSET 中，member 是商品 ID，score 是过期时间戳。业务层读取商品库存时，先检查 ZSET 中该商品的过期时间，若已过期则删除哈希中的字段并刷新缓存。
	- 还可以用一个定时任务检查 ZSET 头部，定期清理已过期的缓存

---
# 4 引用
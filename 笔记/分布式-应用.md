2025-04-12 15:24
Status: #idea
Tags: [[分布式]]

# 1 分布式ID
## 1.1 什么是分布式ID
`全局唯一ID`就叫`分布式ID`。

拿MySQL数据库举个栗子：在我们业务数据量不大的时候，单库单表完全可以支撑现有业务，数据再大一点搞个MySQL主从同步读写分离也能对付。
但随着数据日渐增长，主从同步也扛不住了，就需要对数据库进行分库分表，但分库分表后需要有一个唯一ID来标识一条数据，数据库的自增ID显然不能满足需求；特别一点的如订单、优惠券也都需要有`唯一ID`做标识。此时一个能够生成`全局唯一ID`的系统是非常必要的。

## 1.2 分布式ID的要求
- 全局唯一：必须保证ID是全局性唯一的，基本要求
- 高性能：高可用低延时，ID生成响应要块，否则反倒会成为业务瓶颈
- 高可用：100%的可用性是骗人的，但是也要无限接近于100%的可用性
- 好接入：要秉着拿来即用的设计原则，在系统设计和实现上要尽可能的简单
- 趋势递增：最好趋势递增（也就是有序），这个要求就得看具体业务场景了，一般不严格要求

## 1.3 分布式ID方案
### 1.3.1 基于UUID
UUID却并不适用于实际的业务需求。像用作订单号`UUID`这样的字符串没有丝毫的意义，看不出和订单相关的有用信息。
而对于数据库来说用作业务`主键ID`，它不仅是太长还是无序的字符串，存储性能差查询也很耗时，所以不推荐用作`分布式ID`。

### 1.3.2 基于数据库自增ID
基于数据库的`auto_increment`自增ID完全可以充当`分布式ID`，具体实现：需要一个单独的MySQL实例用来生成ID。
当我们需要一个ID的时候，向表中插入一条记录返回`主键ID`，但这种方式有一个比较致命的缺点，访问量激增时MySQL本身就是系统的瓶颈，用它来实现分布式服务风险比较大，不推荐！

### 1.3.3 基于数据库集群模式
害怕一个主节点挂掉没法用，那就做双主模式集群，也就是两个Mysql实例都能单独的生产自增ID。
那这样还会有个问题，两个MySQL实例的自增ID都从1开始，会生成重复的ID怎么办？**解决方案**：设置`起始值`和`自增步长`。
例如一个起始值=1，步长=2；另一个起始值=2，步长等于2。

那如果集群后的性能还是扛不住高并发咋办？就要进行MySQL扩容增加节点，这是一个比较麻烦的事。
增加第三台`MySQL`实例需要人工修改一、二两台`MySQL实例`的起始值和步长，把`第三台机器的ID`起始生成位置设定在比现有`最大自增ID`的位置远一些，但必须在一、二两台`MySQL实例`ID还没有增长到`第三台MySQL实例`的`起始ID`值的时候，否则`自增ID`就要出现重复了，**必要时可能还需要停机修改**。

### 1.3.4 基于数据库的号段模式
号段模式是当下分布式ID生成器的主流实现方式之一，号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000个ID，具体的业务服务将本号加载到内存。表结构如下：
```sql
CREATE TABLE id_generator (
  id int(10) NOT NULL,
  max_id bigint(20) NOT NULL COMMENT '当前最大id',
  step int(20) NOT NULL COMMENT '号段的布长',
  biz_type    int(20) NOT NULL COMMENT '业务类型',
  version int(20) NOT NULL COMMENT '版本号',
  PRIMARY KEY (`id`)
)
```
version ：是一个观锁，每次都更新version，乐保证并发时数据的正确性。
等这批号段ID用完，再次向数据库申请新号段，对`max_id`字段做一次`update`操作，`update max_id= max_id + step`，update成功则说明新号段获取成功，新的号段范围是`(max_id ,max_id +step]`。

这种`分布式ID`生成方式不强依赖于数据库，不会频繁的访问数据库，对数据库的压力小很多。

### 1.3.5 基于Redis模式
`Redis`也同样可以实现，原理就是利用`redis`的 `incr`命令实现ID的原子性自增。
用`redis`实现需要注意一点，要考虑到redis持久化的问题。

### 1.3.6 基于雪花算法（Snowflake）模式
雪花算法（Snowflake）是twitter公司内部分布式项目采用的ID生成算法：
![[image-130.png]]
`Snowflake`生成的是Long类型的ID。
- 第一个bit位（1bit）：Java中long的最高位是符号位代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。
- 时间戳部分（41bit）：毫秒级的时间，不建议存当前时间戳，而是用（当前时间戳 - 固定开始时间戳）的差值，可以使产生的ID从更小的值开始；41位的时间戳可以使用69年，(1L << 41) / (1000L * 60 * 60 * 24 * 365) = 69年
- 工作机器id（10bit）：也被叫做`workId`，这个可以灵活配置，机房或者机器号组合都可以。
- 序列号部分（12bit），自增值支持同一毫秒内同一个节点可以生成4096个ID

根据这个算法的逻辑，只需要将这个算法实现出来，封装为一个工具方法，那么各个业务应用可以直接使用该工具方法来获取分布式ID，只需保证每个业务应用有自己的工作机器id即可，而不需要单独去搭建一个获取分布式ID的应用。

### 1.3.7 百度（uid-generator）
`uid-generator`是由百度技术部开发，项目GitHub地址 [https://github.com/baidu/uid-generator](https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Fbaidu%252Fuid-generator)。
`uid-generator`是基于`Snowflake`算法实现的，与原始的`snowflake`算法不同在于，`uid-generator`支持`自定义时间戳`、`工作机器ID`和 `序列号` 等各部分的位数，而且`uid-generator`中采用用户自定义`workId`的生成策略。

### 1.3.8 美团（Leaf）
`Leaf`由美团开发，github地址：[https://github.com/Meituan-Dianping/Leaf](https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252FMeituan-Dianping%252FLeaf)  
`Leaf`同时支持号段模式和`snowflake`算法模式，可以切换使用。

#### 1.3.8.1 号段模式
先导入源码 [https://github.com/Meituan-Dianping/Leaf](https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252FMeituan-Dianping%252FLeaf) ，在建一张表leaf_alloc：
```sql
DROP TABLE IF EXISTS `leaf_alloc`;

CREATE TABLE `leaf_alloc` (
  `biz_tag` varchar(128)  NOT NULL DEFAULT '' COMMENT '业务key',
  `max_id` bigint(20) NOT NULL DEFAULT '1' COMMENT '当前已经分配了的最大id',
  `step` int(11) NOT NULL COMMENT '初始步长，也是动态调整的最小步长',
  `description` varchar(256)  DEFAULT NULL COMMENT '业务key的描述',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '数据库维护的更新时间',
  PRIMARY KEY (`biz_tag`)
) ENGINE=InnoDB;
```

然后在项目中开启`号段模式`，配置对应的数据库信息，并关闭`snowflake`模式：
```properties
leaf.name=com.sankuai.leaf.opensource.test
leaf.segment.enable=true
leaf.jdbc.url=jdbc:mysql://localhost:3306/leaf_test?useUnicode=true&characterEncoding=utf8&characterSetResults=utf8
leaf.jdbc.username=root
leaf.jdbc.password=root

leaf.snowflake.enable=false
#leaf.snowflake.zk.address=
#leaf.snowflake.port=
```

#### 1.3.8.2 snowflake模式
`Leaf`的snowflake模式依赖于`ZooKeeper`，`Leaf`中`workId`是基于`ZooKeeper`的顺序Id来生成的。每个应用在使用`Leaf-snowflake`时，启动时都会都在`Zookeeper`中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个`workId`。

### 1.3.9 滴滴（Tinyid）
`Tinyid`由滴滴开发，Github地址：[https://github.com/didi/tinyid](https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Fdidi%252Ftinyid)。
`Tinyid`是基于号段模式原理实现的，与`Leaf`如出一辙，每个服务获取一个号段（1000,2000]、（2000,3000]、（3000,4000]

# 2 分布式事务
## 2.1 可靠事件队列
它是一个符合BASE理论的机制，让系统最终达成一致。

假设有一个电商系统，下单操作依赖于三个服务：支付服务（进行银行扣款）、库存服务（扣减商品库存）和积分服务（为用户增加积分）。下单过程中，我们优先处理最核心、风险最高的服务，按照支付扣款、仓库出库以及为用户增加积分的顺序执行。
1. 首先，用户向商店发送了一个交易请求，如购买一件价值 ￥100 的商品。
2. 接着，支付服务创建一个本地扣款事务。如果扣款事务执行成功，系统将在消息队列中新增一条待处理消息。
3. 系统中有一个持续运行的服务，定期轮询消息队列，检查是否存在待处理的消息。如果发现待处理消息，它将通知库存服务和积分服务进行相应的处理。

在可靠消息队列方案中，一旦第一步扣款成功，就不再考虑失败回滚的情况，后面只有成功一条路可选。
这种依赖持续重试来确保可靠性的解决方案在计算机领域被广泛应用，它还有专有的名称 —— **“最大努力交付”（Best-Effort Delivery）**。因此，可靠事件队列也称为**“最大努力一次提交”（Best-Effort 1PC）机制**，也就是将最容易出错的业务通过本地事务完成后，借助不断重试的机制促使同一个事务中其他操作也顺利完成。

## 2.2 TCC
TCC（Try、Confirm、Cancel）事务模型由三个阶段组成：
1. **Try 阶段**：该阶段的主要任务是预留资源或执行初步操作，但不提交事务。Try 阶段确保所有相关操作可以成功执行且没有资源冲突。例如，在预订系统中，这一阶段可能包括检查商品库存并暂时锁定商品。
2. **Confirm 阶段**：如果 Try 阶段成功，系统进入 Confirm 阶段。在此阶段，系统会提交所有操作，确保事务最终生效。由于 Try 阶段已保证资源的可用性和一致性，Confirm 阶段的执行是无条件的，不会发生失败。
3. **Cancel 阶段**：如果 Try 阶段失败，或需要回滚事务，系统进入 Cancel 阶段。此时，系统会撤销 Try 阶段中的所有预留操作并释放资源。Cancel 阶段确保事务无法完成时，系统能够恢复最初的状态。

按照 TCC 事务模型的规定，Confirm 和 Cancel 阶段只返回成功，不会返回失败。如果 Try 阶段之后，出现网络问题或者服务器宕机，那么事务管理器要不断重试 Confirm 阶段或者 Cancel 阶段，直至完成整个事务流程。
我们没必要裸编码实现 TCC 事务模型，而是利用分布式事务中间件（如 Seata、ByteTCC）降低编码工作，提升开发效率。

## 2.3 Saga
Saga 核心思路是将大事务拆分为多个可并行执行的子事务，并在每个子事务中引入补偿操作。补偿（也称为逆向恢复）是在分布式事务发生异常时，通过一系列操作将事务状态回滚到之前的状态，从而避免不一致的情况发生。

Saga 事务模型由两部分组成：
1. 一部分是**将大事务 T 拆分成若干小事务**，命名为 T1，T2，Tn，每个子事务都具备原子性。如果分布式事务 T 能够正常提交，那么它对数据的影响应该与连续按顺序成功提交子事务 Ti 等价。
2. 另一部分是**为每个子事务设计对应的补偿动作**，命名为 C1，C2，Cn。Ti 与 Ci 满足以下条件：
    - Ti 与 Ci 具备幂等性。
    - Ti 与 Ci 满足交换律，即无论先执行 Ti 还是先执行 Ci，其结果都是一样的。
    - Ci 必须保证成功提交，即不考虑 Ci 的失败回滚情况。如果出现失败，则持续重试直至成功或者被人工介入为止。

如果 T1 到 Tn 均执行成功，那么整个事务顺利完成，否则根据下面两种机制之一进行事务恢复：
- **正向操作**（Forward Recovery）：如果 Ti 提交失败，则一直对 Ti 进行重试，直至成功为止（使用最大努力交付机制）。这种恢复方式不需要进行补偿，适用于事务最终都要执行成功的情况。如订单服务中银行已经扣款，那么就一定要发货。
- **逆向恢复**（Backward Recovery）：如果 Ti 提交失败，则执行对应的补偿 Ci，直至恢复到 Ti 之前的状态，这里要求 Ci 必须成功（使用最大努力交付机制）。

Saga 非常适合处理流程较长、且需要保证事务最终一致性的业务场景。例如，在一个旅游预订平台中，用户可能同时预订机票、酒店和租车服务，这些服务可能由不同的微服务或第三方供应商提供。在这种场景下，Saga 事务模型允许系统逐步执行每个操作，并在任一步骤失败时有序地执行补偿操作，从而确保系统的一致性并提升用户体验。
与 TCC 相比，Saga 通常采用事件驱动设计，即每个服务都是异步执行的，无需设计资源的冻结状态或处理撤销冻结的操作。但缺点是不具备隔离性，多个 Saga 小事务操作同一数据源时，无法保证操作的原子性，可能出现数据被覆盖的情况。

Saga 事务通常不通过裸编码实现，而是在事务中间件的支持下完成。前面提到的 Seata 中间件也支持 Saga 事务模型。

---
# 3 引用
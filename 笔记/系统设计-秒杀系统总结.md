2025-10-28 16:04
Status: #idea
Tags: [[场景题和设计题]]

# 1 概览
高可靠系统的三个维度：高可用，一致性，高性能。
实现高可靠的架构原则：
1. 数据尽量少：请求的上传和响应数据、系统依赖的数据都要少
2. 请求数尽量少
3. 路径尽量短：极致方法是合并部署
4. 强依赖尽量少：对系统分级，高级系统尽量减少对低级系统的强依赖
5. 不要有单点：通过无状态、或冗余备份（如数据库）实现

秒杀系统关键问题：瞬时高并发。
秒杀系统的技术场景：几乎都是写请求，但是成功的很少

秒杀业务流程：秒杀 -> 下单 -> 支付
秒杀系统架构：
- ~~秒杀详情系统~~
- ~~秒杀交易系统~~
- 秒杀系统
- ~~商品、库存系统~~
- 交易系统
- 支付系统

# 2 流程
## 2.1 预热期：秒杀前准备
1. 选择哪些商品参与秒杀，每个商品多少库存。
2. 秒杀消息宣发，吸引用户。
3. 用户报名，大致得知多少用户参与
4. **预热缓存**
	1. 静态资源（如商品标题、描述、图片等）同步到 CDN
	2. 将商品库存加载到缓存
5. 系统初始化与校验：
	1. 检查所有服务组件是否正常运行，包括 Redis 集群、MySQL 数据库、消息队列、API 网关等。
	2. 进行压力测试，模拟一定规模的并发请求，验证系统的稳定性和性能。
	3. 设置限流规则、熔断策略、降级预案等，服务集群扩容至目标实例数,确保系统能够应对突发情况。

## 2.2 抢购期：流量峰值处理
1. 秒杀系统展示商品信息和秒杀按钮，秒杀开始前按钮置灰。这里是**动静分离**的地方，静态资源请求发给CDN，CDN获取不到再回源到源站。
2. 开始后，用户点击秒杀按钮，**前端首先进行本地校验**，包括：检查当前时间是否在活动时间内；验证用户是否已经登录；检查用户是否已经参与过本次秒杀；进行简单的防重复点击处理（按钮置灰 300ms）。
3. 然后答题or验证码，**请求按时间分片**，开始秒杀。秒杀请求发到秒杀系统
4. 秒杀请求达到lvs/nginx负载均衡集群，请求被分配到不同的API网关
	- 注意：nginx也可以实现全局限流
5. API网关实现限流（IP / 用户 ID / 接口维度）、用户登录、初步校验（活动参与资格、黑名单）等功能
	- 然后是热点数据限制（感觉在API网关做更好？）：用商品的hash分组把请求划分成不同的队列进行处理。避免热点商品抢占了所有连接
6. 然后请求到达秒杀服务器，这里也可以再用令牌桶算法实现一道限流。和前面的限流一起形成了**分层限流**
7. （假设不用MQ排队请求，这样是同步请求）
	- 问题：用了MQ之后的流程
8. **防重判断**：如果用户用完了秒杀次数，那么就直接返回秒杀失败
9. **安全和反作弊措施**：参见恶意请求拒绝
10. 缓存查询：先查询库存的 **本地||redis 缓存||分级缓存||分段缓存**，不存在再去数据库找。库存为0了就直接返回失败，否则继续往下走
	- 这里允许一定的缓存数据不一致，最坏情况就是多放了些请求
11. 接下来是**扣减库存**。扣减失败返回秒杀失败，否则继续往下走
	- 扣减逻辑不复杂，比如没有复杂的 SKU 库存和总库存这种联动关系的话，那么可以直接在redis中扣减
	- 复杂的扣减，还是需要在mysql中扣减.。要做好排队，减少抢锁冲突，应对高并发写
12. 扣减成功，返回秒杀成功

## 2.3 下单&履约期：异步创建订单
1. MQ异步调用订单系统生成订单。可以采用分布式通知型事务保证一致性。
	- MQ事务消息
	- 本地消息表
2. 通知服务消费消息，向用户发送短信 / APP 推送
3. 用户支付完成，则秒杀彻底结束。如果一段时间没支付，超时订单取消，则继续往下走
4. 订单取消，订单系统会调用秒杀系统的RPC告知，秒杀系统恢复这个商品的库存

# 3 核心需求
- 预热期
	- 动静分离
	- 业务手段
		- 商品报名，框定秒杀范围，方便预热
		- 用户报名，预估用户数
- 抢购期
	- 前端本地校验：简单防重、活动时间判断、用户是否登录等
	- 流量削峰：
		- 流量按时间分片：验证码
		- 分层过滤
		- 分层限流，以及多种限流策略（令牌、用户ID、IP、接口请求次数）和限流算法（漏桶、令牌桶、滑动窗口）
		- MQ排队：请求变成异步
	- 限制热点数据：通过按商品分组排队请求，限制热点商品抢占所有资源
	- 安全防护：
		- 防止用户重复秒杀
		- 恶意请求拒绝
	- 高效的缓存架构：只要求缓存读的最终一致性
		- Redis切片集群、主从架构
		- 本地缓存
		- 分级缓存：本地+Redis缓存
		- 分段缓存：一份库存拆分成几份
	- 库存扣减
		- 要点：
			- 高并发写
			- 强一致性，防超卖
		- Redis、MySQL两种扣减架构
			- Redis：数据库库存同步问题；崩溃恢复问题
			- MySQL：
				- 高并发抢行锁问题：排队；
				- 缓存失效风暴问题：同时更新缓存 or 缓存批量更新
				- 分库分表
	- 异步请求如何返回结果（用了MQ排队请求的情况）：轮询接口；长连接 SSE
- 下单&履约期
	- 异步下单，用分布式事务保障一致性
	- 订单超时取消（MQ延时消息），补偿库存

# 4 关键技术
## 4.1 安全防护
### 4.1.1 恶意请求拒绝
恶意请求和黄牛攻击是秒杀系统面临的安全挑战。黄牛脚本的危害不仅是 "抢走商品"，还会占用大量带宽和服务器资源，导致真实用户抢不到商品。
1. **设备指纹识别**：通过前端采集用户设备信息（如浏览器 UA、屏幕分辨率、操作系统版本、设备唯一标识），生成 "设备指纹"。若某设备指纹短期内多次请求，或与黑名单指纹匹配，直接拦截。
2. **行为分析**：真人用户的操作有 "时间间隔" 和 "正常轨迹"（如先浏览商品、再加入购物车、最后抢购），而脚本是 "瞬时连续点击"。通过后端分析用户行为：若从进入页面到点击抢购的时间＜1 秒，或同一用户 1 分钟内点击抢购＞10 次，标记为疑似作弊，要求完成 "滑块验证码" 或 "图文验证码"。
3. **黑名单机制**：将历史作弊用户（如用脚本下单的用户、多次取消秒杀订单的用户）的 ID、IP、设备指纹加入黑名单，后续请求直接拒绝。某平台通过黑名单机制，减少了 40% 的作弊请求。
4. 给某些类目设置最大购买件数、以及对重复下单不付款的操作进行次数限制等

还可以针对用户ID、IP限流，参见 [[#2.2.4.1 针对性限流]]
### 4.1.2 防止重复秒杀
#### 4.1.2.1 重试的关键限制规则
用户没秒杀成功，则允许重试但不能无限制，需通过以下规则避免系统压力：
1. 时间限制：仅在秒杀活动有效期内允许重试，活动结束后直接隐藏按钮或置灰。
2. 频率限制：同一用户 / IP / 设备对同一商品，设置重试间隔（如 3-5 秒），避免高频连续点击。
3. 次数限制：可设置单用户单商品最大重试次数（如 5 次），超过次数后提示 “今日参与次数已用尽”。
4. 失败类型区分：
    - 允许重试场景：网络超时、系统繁忙、库存暂时不足（未售罄）。
    - 禁止重试场景：已抢到过该商品（无论是否支付）、账号疑似作弊、活动已结束、商品售罄。
5. 高并发峰值：当系统 QPS 接近阈值时，可临时收紧重试规则（如延长重试间隔、减少重试次数），优先保障系统稳定。
#### 4.1.2.2 前端层：提前拦截重复操作
前端是第一道防线，主要拦截用户无意识的重复点击或简单脚本重复提交。
- 按钮置灰与禁用：用户点击 “抢购” 后，立即将按钮置灰并禁用（如 1-3 秒），禁止短时间内重复点击。
- 本地存储标记：用户成功发起一次抢购请求后，通过 localStorage/sessionStorage 记录 “已参与秒杀（商品 ID + 用户 ID）”，下次点击时直接提示 “已参与，请勿重复提交”。
- 请求防抖：使用防抖函数（如 300ms），过滤短时间内的多次点击，仅保留最后一次有效请求。
- 页面跳转限制：抢购成功后，直接跳转到订单页或结果页，禁止回退到秒杀页再次提交。
#### 4.1.2.3 接入层：拦截重复请求
API 网关 / 负载均衡层进一步过滤重复请求，减少后端压力：
- ~~基于请求 ID 去重：前端发起请求时生成唯一 requestID（如 UUID），携带在请求头中；网关层记录近期 requestID，重复请求直接拦截。~~
- IP + 商品维度限流：限制同一 IP 对同一商品的请求频率（如 10 秒内最多 2 次），避免脚本高频重复提交。
- 令牌桶限流：网关层为每个用户分配秒杀令牌，同一用户对同一商品仅能获取 1 个有效令牌，重复请求无令牌直接拒绝。通过限制令牌数量，也能限制总体请求的用户数量
#### 4.1.2.4 应用层：核心去重校验
应用层通过业务规则和分布式存储，确保重复请求无法通过核心逻辑。
- 唯一标识校验：以 “用户 ID + 商品 ID” 作为唯一组合，秒杀前先查询 Redis（如键为`seckill:user:${userID}:${goodsID}`），次数为0则返回 “已参与”，否则扣减次数（设置过期时间与秒杀活动时长一致）。

**通过缓存限制秒杀失败的用户**。
#### 4.1.2.5 数据层：最终一致性保障
数据层作为最后一道防线，通过数据库约束杜绝重复记录。
- 唯一索引约束：在秒杀订单表中，为 “用户 ID + 商品 ID” 建立联合唯一索引，即使前面校验失效，数据库也会拒绝重复插入订单，直接抛出主键冲突异常。

**数据库记录秒杀成功的用户**。
## 4.2 高可用
### 4.2.1 隔离
- 业务隔离：让商家报名，使热点已知，方便提前预热
- 系统隔离：独立系统&集群
- 数据隔离：独立数据库、独立缓存
### 4.2.2 流量削峰
#### 4.2.2.1 答题or验证码
作用：
- 防止用户刷接口
- 让流量基于时间分片

秒杀验证码系统抗高并发的核心是 **“轻量化生成 + 分布式验证 + 缓存兜底”**，通过 “本地生成避免中心瓶颈、缓存复用减少计算、异步异步解耦高峰压力”，可支撑每秒 10 万 + 验证请求，关键是不让验证码成为秒杀的 “新瓶颈”。
##### 4.2.2.1.1 核心设计原则：验证码系统必须 “轻、快、可扩展”
1. 生成逻辑极简：避免复杂图形 / 算法（如不用 AI 识别、不用复杂扭曲），优先选择 “易生成、易验证” 的类型；
2. 验证路径最短：减少网络跳转和数据库交互，核心流程 “本地生成→缓存存储→本地验证”；
3. 无状态设计：应用层不存储验证码状态，依赖分布式缓存（Redis）共享验证信息，支持水平扩容；
4. 熔断降级兜底：极端峰值时可降级为 “极简验证码”（如 4 位数字）或临时关闭（需配合其他限流），避免系统雪崩。
##### 4.2.2.1.2 验证码类型选择：优先 “轻量化”，拒绝重计算
不同验证码的并发支撑能力差异极大，秒杀场景优先选前 3 种：

| 验证码类型        | 生成耗时    | 验证耗时    | 单实例并发能力      | 适用场景         |
| ------------ | ------- | ------- | ------------ | ------------ |
| 4-6 位数字验证码   | 微秒级     | 微秒级     | 10 万 + QPS   | 极高并发秒杀（优先选）  |
| 数字 + 字母混合验证码 | 微秒级     | 微秒级     | 8 万 + QPS    | 中高并发，需简单防刷   |
| 滑动拼图（本地生成）   | 毫秒级     | 毫秒级     | 5 万 + QPS    | 需增强防刷，容忍少量延迟 |
| 图形扭曲验证码      | 毫秒级     | 毫秒级     | 1 万 + QPS    | 防刷要求高，并发较低场景 |
| AI 图文识别验证码   | 10 + 毫秒 | 10 + 毫秒 | 5000-1 万 QPS | 秒杀场景不推荐（重计算） |
##### 4.2.2.1.3 生成模块：本地生成 + 缓存存储，无中心瓶颈
应用层本地生成验证码，不依赖第三方服务或中心节点，生成后仅存 Redis（或本地缓存），不写数据库。
关键设计：
1. 生成算法轻量化：用`ThreadLocalRandom`（Java）生成随机数 / 字符串，避免 SecureRandom（加密级随机，耗时高）；
2. 验证码 ID 全局唯一：用 “用户 ID + 设备 ID + 时间戳” 生成唯一 ID（如`verify:10086:device123:1699999999`），避免重复验证；
3. 过期时间短：设置 60 秒过期，减少 Redis 存储压力；
4. 本地缓存预生成：提前生成一批验证码（如 1 万条）存本地内存，高峰时直接取用，生成压力平摊到低峰期。
5. 动态难度调整：高峰期用 4 位数字，低峰期自动切换为 6 位混合或滑动拼图，平衡性能与防刷；
6. 拒绝高频刷新：同一用户 10 秒内最多请求 1 次验证码，避免恶意刷新消耗资源。
7. 验证码绑定用户 / 设备：避免攻击者批量生成验证码；
##### 4.2.2.1.4 验证模块：Redis 单点查询，异步解耦高峰
关键优化：
1. 验证结果异步通知：验证成功后，通过本地消息队列（如 Disruptor）或 Redis 消息通知秒杀系统，不阻塞验证码响应；
2. 限制验证次数：同一用户 / 设备 1 分钟内最多验证 5 次，避免恶意重试压垮系统；
3. 缓存复用：减少重复生成与验证
	- 同一用户 5 分钟内重复请求验证码，直接返回缓存中的未过期验证码（避免频繁生成）；
	- 验证成功后，Redis 键立即删除，避免重复验证请求穿透到存储层。
4. Redis 集群分片：验证码 Redis 键按 “用户 ID 哈希” 分片，避免单 Redis 实例承载所有验证请求。
##### 4.2.2.1.5 部署架构：水平扩容 + 就近接入，分散压力
- 多实例部署：验证码应用层部署多台机器，前端通过负载均衡（如 Nginx）随机路由，支持无限水平扩容；
- 就近接入：CDN / 边缘节点部署静态验证码资源（如滑动拼图背景图），用户请求无需回源，减少核心链路压力；
- 资源隔离：验证码系统的 Redis 集群、应用实例与秒杀核心系统完全隔离，避免验证码峰值影响秒杀流程。
- 限流熔断：防止恶意攻击与极端峰值
	- 接入层限流：Nginx 层面限制单 IP 每秒最多 10 次验证码请求，超出直接返回 “系统繁忙”；
	- 应用层熔断：当 Redis 响应时间 > 50ms 或错误率 > 10%，临时降级为 “无需验证码”（需配合其他限流，如用户等级校验），避免验证码系统崩溃导致秒杀不可用。
#### 4.2.2.2 分层过滤
- 分层架构设计，通过层层过滤和分流，将瞬时流量压力逐级化解。典型的五层架构包括：接入层(CDN、负载均衡、API)、应用层、缓存层、消息队列层和存储层​。每一层都承担" 过滤无效请求、减轻下游压力 "的职责，形成一个" 流量漏斗 "​。
- 秒杀系统：
	- 第一层在浏览器和CDN拦截大部分静态数据读取
	- 第二层前端校验，检查用户资格、活动状态、答题正确性等
	- 第三层应用层读系统，数据走Cache，过滤无效请求（库存没有了之后的请求）
	- 第四层应用层写系统，做数据的二次检验，对系统做好保护和限流
	- 第五层数据层，完成数据的强一致性校验
#### 4.2.2.3 排队
- 消息队列承接瞬时流量，把同步请求变成异步
- 也需要保护MQ，MQ之前应该有很多层限流。
### 4.2.3 限流
分层限流：
- 在客户端，在远程调用时我们设置连接池的线程数，超出这个并发线程请求，就将线程进行排队或者直接超时丢弃
- 在接入层
	- 基于 Nginx/OpenResty 设置全局限流（如 10 万 QPS）
	- 还可以加入针对性限流
	- 还有令牌限流：网关层为每个用户分配秒杀令牌，同一用户对同一商品仅能获取 N 个有效令牌（让用户能重试），重复请求无令牌直接拒绝。通过限制令牌数量，也能限制总体请求的用户数量
- 在应用层
	- 使用 Redis 实现分布式限流，通过 Lua 脚本保证原子性：解决单机限流不够精确的问题，我们可能有1000个实例，但是下游存储只有一套
	- 单个机器可以用令牌桶、漏桶、滑动窗口限流算法
- 在服务层，采用 Hystrix 或 Sentinel 实现熔断降级，当依赖服务故障时快速返回默认结果
#### 4.2.3.1 针对性限流
可以对同一用户ID限流。但有时候只对某个用户限流是不够的，有些高手可以模拟多个用户请求，这时需要加同一ip限流功能。
但这种限流方式可能会有误杀的情况，比如同一个公司或网吧的出口ip是相同的，如果里面有多个正常用户同时发起请求，有些用户可能会被限制住。
别以为限了用户和ip就万事大吉，有些高手甚至可以使用代理，每次都请求都换一个ip。这时可以限制请制求的接口总次数。
### 4.2.4 降级
它是一个有目的、有计划的执行过程，所以对降级我们一般需要有一套预案来配合执行。如果我们把它系统化，就可以通过预案系统和开关系统来实现降级。
### 4.2.5 熔断
使用 Sentinel 或 Hystrix 监控服务调用情况，当某服务调用失败率超过 50%，自动熔断，暂时停止调用该服务，返回默认结果（如 "支付暂时不可用，请稍后重试"），避免连锁故障。
### 4.2.6 拒绝服务
当系统负载达到一定阈值时，例如 CPU 使用率达到 90% 或者系统 load 值达到 2\*CPU 核数时，系统直接拒绝所有请求，这种方式是最暴力但也最有效的系统保护方式。
这种系统过载保护虽然在过载时无法提供服务，但是系统仍然可以运作，当负载下降时又很容易恢复，所以每个系统和每个环节都应该设置这个兜底方案，对系统做最坏情况下的保护。
### 4.2.7 监控告警体系
监控告警体系是系统稳定运行的保障。使用 Prometheus+Grafana 监控 QPS、响应时间、错误率、库存剩余量、消息队列堆积数等指标，设置阈值告警（如 QPS 超过 50 万、错误率超过 1% 时，通过短信 / 邮件告警）。同时，通过 SkyWalking 或 Zipkin 追踪秒杀请求的全链路，快速定位耗时节点。
### 4.2.8 故障恢复
### 4.2.9 自动扩缩容
### 4.2.10 多活架构
将系统部署在多个地域的机房（如华东、华北），通过 DNS 解析将用户流量引导到就近机房；若某机房故障，自动将流量切换到其他机房，实现 "异地多活"。
### 4.2.11 缓存三大问题
参见[[Redis-应用#3 缓存三大问题]]
### 4.2.12 TODO：请求持久化与重试
## 4.3 一致性
### 4.3.1 库存读取的最终一致性
库存的读取（判断还有没有商品、要不要防请求进来）缓存没有必要极致追求数据的准确性，只要保证最终一致性。缓存本身为了减少数据库的压力。
最坏情况也就是多放了一些请求进来。
### 4.3.2 库存扣减的强一致性
通过redis或mysql的原子操作实现
### 4.3.3 下单和库存两个操作的事务怎么保证
背景：下单、库存操作分别是两个系统。
解决办法：
1. 两阶段提交：可以分两步来做，先创建订单但是先不生效，然后减库存，如果减库存成功后再生效订单，否则订单不生效。类似于MySQL日志的两阶段提交
2. 分布式事务
### 4.3.4 订单超时后如何补偿库存
下单时发送一条 “延迟消息” 到 MQ，延迟时间 = 订单超时时间；消息到期后被消费，触发库存补偿。
- **操作流程**：
    1. 下单成功：扣减库存后，发送消息`{orderId:10086, shardId:3, num:1}`到延迟队列，延迟 15 分钟；
    2. 消息到期：消费者接收到消息，查询订单状态（通过订单服务 API）；
    3. 补偿执行：若订单未支付，执行Redis库存orMySQL库存补偿，并调用订单服务标记 “已取消”，同步数据库。
- **优势**：
    - 可靠性高：MQ 支持消息持久化、重试机制，不会丢失（即使服务宕机，重启后继续消费）；
    - 可扩展：通过 MQ 分区 / 分片，支持百万级超时订单的补偿；
    - 解耦：补偿逻辑与订单服务完全分离，不影响核心下单流程。
- **注意**：需处理 “消息重复消费”（如用 Redis 记录`order:compensated:10086`，补偿前检查是否已处理）。
## 4.4 高性能
### 4.4.1 性能影响因素
性能指标：
- **响应时间（Response Time，RT）**：服务器处理响应的耗时，由**CPU 执行时间**和**线程等待时间**（比如 RPC、IO 等待、Sleep、Wait 等）组成。
	- CPU 的执行真正消耗了服务器的资源，对性能影响最大
- **QPS（Query Per Second，每秒请求数）** =（1000ms / 响应时间）× 线程数量
- 线程数最佳实践：`线程数 = [(线程等待时间 + 线程 CPU 时间) / 线程 CPU 时间] × CPU 数量`。如果考虑超线程，还可以 x 2

发现瓶颈：
- 性能工具： JProfiler 和 Yourkit 这两个工具，它们可以列出整个请求中每个函数的 CPU 执行时间
- 压测：
	- 简单地判断 CPU 是不是瓶颈：一个办法就是看当 QPS 达到极限时，你的服务器的 CPU 使用率是不是超过了 95%。如果没有超过，那么表示 CPU 还有提升的空间，要么是有锁限制，要么是有过多的本地 I/O 等待发生。
	- 除了CPU，系统的每一个中间件, 每一台机器, 都应该有promethus监控大屏。系统到qps极限时, 查监控大屏上谁的的cpu/内存/磁盘/网络满了, 差不多就是瓶颈了。

做好应用基线：
- 比如性能基线（QPS、RT等，何时性能突然下降）、成本基线（去年双 11 用了多少台机器）、链路基线（依赖哪些关键接口，我们的系统发生了哪些变化）
- 你可以通过这些基线持续关注系统的性能，做到在代码上提升编码质量，在业务上改掉不合理的调用，在架构和调用链路上不断的改进。
### 4.4.2 动静分离
动态静态分类：数据中是否含有和访问者相关的个性化数据。

静态数据
- 缓存地点要离用户近
- 让web型缓存（varnish）或CDN缓存
- 可以对URL的结果进行缓存。https协议的链接只在最外层，内部系统用http
- CDN要点
	- 离访问量大的地区近，离主站远但和主站的网络好
	- 节点容量大且数量不多，数量不多则访问量集中、命中率高
	- CDN作为二级缓存，没取到去一级缓存（web型缓存）
	- vs 浏览器。浏览器不可控，CDN可以主动失效

动态数据：
- ESI：web服务器请求动态数据，把结果插入到静态页面中返回
- CSI：浏览器自己请求动态内容，对服务器友好，适合秒杀系统
### 4.4.3 热点数据
热点数据发现
- 静态热点数据：就是能够提前预测的热点数据
- 动态热点数据发现系统
	- 收集交易链路上各个环节中的中间件产品的热点Key或抓取日志，如 Nginx、缓存、RPC 服务框架等这些中间件
	- 提供订阅给其他系统

热点数据缓存
- 更新方式
	- 定时更新
	- 主动更新：
		- 用阿里metaq技术，就是数据库字段更新会产生一条消息。让一个失效中心去监控，收到更新后给缓存发送失效请求
		- 没有的话，就在数据库库存更新操作时，手动发一条MQ消息
- 一致性：缓存没有必要极致追求数据的准确性，只要保证最终一致性。缓存本身为了减少数据库的压力。
- 单点问题
	- 冗余备份：当热点数据过热时，单个缓存也撑不住，需要弄多个实例缓存一样的内容，用nginx路由。用在web型缓存中
	- 本地缓存：热点数据存在机器内存上面。设置短时间的失效时间，不主动失效
	- 分段缓存：例如将商品总库存逻辑上划分为 N 个分片，每个分片持有 T/N 的库存。当用户请求到达时，随机或轮询选择一个分片进行扣减操作，有效分散了热点压力。
		- 但是这样又面临其他问题
- 分层缓存：本地缓存、redis

热点数据限制：对被访问商品的 ID 做一致性 Hash，在部分服务调用的地方对请求进行 Hash 分组，每个分组设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。

热点数据隔离
- 热点数据移到其他单独缓存、数据库中
- 动态隔离怎么做
#### 4.4.3.1 本地缓存的主动失效
本地缓存弄个短的失效时间就行，秒杀场景下失效间隔很短，主动失效得不偿失。但如果其他系统想要做，可以按下面的来。
本地缓存的失效设计核心是 **“主动通知 + 被动兜底”**，既要确保库存变更后各机器的本地缓存能及时同步，又要避免因通知丢失导致的长期不一致，具体可按 “实时失效” 和 “最终一致” 两层设计落地。
##### 4.4.3.1.1 第一层：实时失效 —— 库存变更后主动通知所有机器
###### 4.4.3.1.1.1 基于 “消息队列广播” 的主动通知
这是通用性最强、可靠性最高的方案，适合多机器分布式部署场景，步骤如下：
1. 库存变更时发送广播消息：在数据库扣减库存的事务提交后，立即向消息队列发送一条 “库存变更广播消息”，消息体包含 商品 ID，并将队列设置为 “**广播模式**”，确保同一条广播消息能被所有机器消费到
2. 应用机器接收消息后清空本地缓存：每个应用机器启动一个消息消费线程，监听 “库存变更广播队列”，收到消息后调用本地缓存的删除方法，清空该商品的本地缓存；

通知实时性高（延迟通常 < 100ms），所有机器能同步清空缓存；消息队列有持久化机制，即使某台机器临时离线，重启后仍能消费消息补清缓存，避免遗漏。
###### 4.4.3.1.1.2 基于 “Redis 发布订阅” 的轻量通知（适合中小规模）
若已使用 Redis，可无需额外引入 MQ，用 Redis 的 Pub/Sub（发布订阅）机制实现广播，步骤更简洁：
1. 库存变更时发布 Redis 消息：事务提交后，调用 Redis 的`PUBLISH "stock_change_topic" "商品ID"`，向 “库存变更主题” 发布消息。
2. 应用机器订阅主题并清空缓存：每个应用机器启动一个 Redis 订阅线程，订阅`"stock_change_topic"`，收到消息后立即清空对应商品的本地缓存。

注意：Redis Pub/Sub 是 “无持久化” 的，若机器离线期间发布的消息会丢失，需搭配 “被动兜底” 机制（见下文）；适合机器数量少（<50 台）、对通知可靠性要求不极致的场景。
##### 4.4.3.1.2 第二层：被动兜底 —— 避免通知丢失导致的缓存不一致
即使主动通知机制 99% 可靠，仍可能因 “消息队列宕机”“网络抖动”“机器离线” 导致部分机器的本地缓存未清空，此时需通过 “被动失效” 确保最终一致，核心是 **“设置缓存过期时间 + 缓存刷新策略”**。
1. 给本地缓存设置 “短过期时间”（基础兜底）：为所有商品的本地缓存设置 **5-30 秒的过期时间**（具体时长按库存变更频率调整：秒杀场景变更频繁，设 5 秒；普通商品变更少，设 30 秒）。
2. 定时刷新（针对热点商品）：启动一个定时任务（如每 10 秒），批量查询热点商品的最新库存，主动更新本地缓存（覆盖旧值），进一步缩短不一致窗口。
	- 被动过期后首次查询会触发数据库请求（缓存穿透），高并发下可能出现 “缓存雪崩”
	- 主动刷新则可以批量刷新，避免集中穿透，而且它主要聚焦热点商品（如秒杀爆款）
3. “查询时校验” 终极兜底（极端场景）：
	- 当本地缓存显示 “库存> 0” 时，且缓存快过期了（如剩余时间<2s），先查询一次 Redis或数据库（轻量查询），确认库存是否真实 > 0；若真实库存已为 0，立即清空本地缓存，避免用旧缓存拦截请求；
	- 注意：给 “校验” 加 “频率限制”—— 同一商品短时间内只校验 1 次，例如当前时间 - 上次校验时间 > 500ms（可调整），则执行 1 次数据库校验，同时更新上次校验时间。
#### 4.4.3.2 分级缓存
##### 4.4.3.2.1 核心运作逻辑：查询 “从近到远”，更新 “从近到远”
查询流程（优先用离应用最近的缓存，减少网络 / IO 开销）
```
用户发起库存查询 → ① 查应用本地缓存（如Caffeine）
  ├─ 命中（缓存有值）→ 直接返回结果（微秒级，无网络开销）
  ├─ 未命中 → ② 查Redis缓存（内存数据库，毫秒级）
     ├─ 命中 → 返回结果，同时将数据写入本地缓存（预热，下次查询更快）
     ├─ 未命中 → ③ 查数据库（MySQL）
        ├─ 查到数据 → 返回结果，同时写入Redis和本地缓存（双缓存更新）
        └─ 未查到（如商品不存在）→ 返回“无此商品”，可写入空缓存（防穿透）
```
关键：90% 以上的查询会命中本地缓存，仅 10% 以内的请求会到 Redis，1% 以内的请求会到数据库，数据库压力被层层过滤。

更新流程（库存扣减时，先删缓存再更数据库，避免脏数据）
```
用户发起库存扣减 → ① 先删除当前应用的本地缓存（避免本地仍用旧值）
  → ② 再删除Redis缓存（避免其他应用从Redis读旧值）
  → ③ 执行数据库库存扣减（原子操作，如UPDATE ... WHERE stock>=1）
  → ④ 数据库更新成功后，可选：
     ├─ 主动刷新Redis缓存（写入新库存值，避免下次查询穿透到数据库）
     └─ 发送广播消息，通知其他应用删除本地缓存（确保分布式一致性）
```
##### 4.4.3.2.2 问题：为什么更新是先删缓存再更新数据库
“先删缓存再更数据库” 还是 “先更数据库再删缓存”，核心取决于 **缓存的 “读写比例” 和 “是否承载并发控制”** —— 库存扣减场景用 “先删缓存”，是为了避免高并发下的 “超卖风险”；而只读缓存（如商品详情页）用 “先更数据库”，是为了减少缓存不一致的概率，两者适用场景完全不同。

库存扣减的关键是 “数据库扣减是唯一权威”，缓存（Redis / 本地）仅用于 “挡流量 + 快速判断”，若用 “先更数据库再删缓存”，会出现致命的超卖风险：
1. 商品库存10件，Redis缓存值=10；
2. 用户A发起扣减：先更新数据库（10→9），但还没来得及删Redis；
3. 同时用户B发起扣减：查Redis得到旧值10（认为有库存），直接进入数据库扣减；
4. 数据库此时库存已为9，B扣减后变为8，但Redis仍显示10；
5. 后续大量用户查Redis看到10，持续进入数据库扣减，直到数据库库存为0，Redis仍显示10，最终导致“超卖”（数据库0但用户仍能看到有库存）。
	- 这里用户可能不会看到超卖，而是相对于数据库来说，库存已经没有但你还能来扣减

**因为秒杀系统的请求几乎都是写请求**。所以请求单纯查询数据库旧值写入Redis的情况不会出现。

只读缓存（如商品详情）的核心是 “读多写少”，且没有 “并发控制” 需求（商品详情更新不会导致 “超卖”）：
- 若用 “先删缓存”，会导致大量读请求穿透到数据库（缓存空窗），数据库压力骤增；
- 用 “先更数据库再删缓存”，即使更新后、删缓存前有少量请求读旧缓存，也只是 “短时间不一致”，且后续请求会读数据库最新值并写入缓存，影响范围小。

总结：两种策略的选择逻辑：

| 决策依据              | 选择策略              | 核心原因                 |
| ----------------- | ----------------- | -------------------- |
| 是否有 “并发控制 / 超卖风险” | 有 → 先删缓存再更数据库     | 避免旧缓存导致的虚假库存，守住数据库权威 |
| 读写比例              | 写密集（如库存扣减）→ 先删缓存  | 缓存空窗影响小，且数据库最终校验     |
| 读写比例              | 读密集（如商品详情）→ 先更数据库 | 减少缓存穿透，降低数据库压力       |

库存扣减场景：“先删缓存再更数据库” 是 “两害相权取其轻”—— 宁愿承受 “短时间缓存空窗 + 少量数据库查询”，也不愿冒 “旧缓存导致超卖” 的致命风险。
而且数据库扣减是 “原子校验”，再配合 “延迟双删”，可完全解决旧值回写问题。
##### 4.4.3.2.3 分级缓存的核心价值：1+1>2 的优势
1. 性能拉满：本地缓存无网络开销（微秒级响应），扛高并发，可支撑 10 万 + QPS 查询；Redis 兜底分布式，查询速度比数据库快 100 倍，承接本地缓存未命中的请求。
2. 容错性更强：一层缓存故障，另一层补位
#### 4.4.3.3 分段缓存解决单点问题
分段缓存（也叫 “库存分片”）是高并发库存场景的 “杀手锏” 方案，核心是通过 “**将单商品库存拆分为多份，分散到不同 Redis 分片**”，把单点并发压力分摊到多个节点，从架构层面突破单 Redis 实例的性能瓶颈。
##### 4.4.3.3.1 库存分片规则设计（核心）
- **分片数量**：根据预估并发量设置（如单 Redis 分片可扛 1 万 QPS，10 万 QPS 就分 10 片），通常取 10-100 片（过多会增加管理成本）；
- **分片键设计**：用`stock:{goodsId}:{shardId}`作为 Redis 键，例如商品 ID=1001 的 10 个分片键为：
    `stock:1001:0`、`stock:1001:1`、…、`stock:1001:9`，每个键初始值 = 10（100/10）；
- **总库存计算**：不单独存储总库存，而是通过`SUM(stock:1001:*))`动态计算（但实际扣减时不依赖总库存，避免分布式计算瓶颈）。
##### 4.4.3.3.2 扣减流程
用户扣减成功则返回，扣减失败则看情况是否重试，兼顾体验与性能：
1. 限制重试次数（核心）：最多重试 2-3 次（如总分片数 10，重试 2 次即停止），避免单次请求消耗过多资源
2. 用 “可用分片列表” 减少无效重试（关键优化）
	1. 应用层本地缓存记录 “当前有库存的分片 ID 列表”（如`Set<Integer> availableShards`），定期（如 1 秒）从 Redis 更新（通过`KEYS stock:1001:*`筛选出值 > 0 的分片）；
	2. 扣减时优先从`availableShards`中随机选择，而非全部分片，避免重试已售罄的分片
3. 对 “最后一个有库存的分片” 做特殊保护：当监控到某商品仅剩 1 个分片（或2+个）有库存时，自动触发 “流量限制”：
	- 该分片的扣减请求仅允许 “未重试过的新请求” 进入，重试请求直接拒绝；
	- 配合应用层限流（如该分片每秒仅处理 1000 请求），避免被重试流量压垮。
##### 4.4.3.3.3 扩容与缩容（动态调整分片）
若某商品并发突增，可临时增加分片（如从 10 片扩至 20 片）：
1. 从现有分片匀出部分库存（如每个旧分片匀 5 个到新分片）；
2. 新分片键生效（`stock:1001:10`…`stock:1001:19`）；
3. 扣减逻辑自动识别新分片，无需停服。
##### 4.4.3.3.4 适用场景：不是所有库存系统都需要
最适合的场景：
- **高并发秒杀 / 促销**：单商品瞬时 QPS>1 万（如 “618” 爆款、限量抢购），必须通过分片分散压力；
- **库存总量固定，扣减后不频繁调整**：如电影票、演唱会门票（售罄后不再补库存），分片后无需复杂的库存再分配。

不适合的场景：
- **普通商品日常库存管理**：QPS 低（单商品 < 100），分片会增加系统复杂度，性价比低；
- **库存频繁变动**：如电商日常商品（频繁补货、退换货），分片会导致库存调整逻辑复杂，易出现数据不一致。
### 4.4.4 TODO：数据库主从模式&分库分表
让从库抗库存读查询的并发，反正保证最终一致性就行
### 4.4.5 库存扣减
#### 4.4.5.1 库存扣减的方式
1. 下单减库存：简单精准，但是有人可能恶意不支付。
	- 秒杀系统会用，因为秒杀下单不支付的现象是很少的
2. 付款减库存：会有库存超卖现象
3. 预扣库存：下单后库存为其保留一定的时间（如 10 分钟），超过库存将自动释放。一定程度防止恶意支付。这是业务系统常用方式
	- 但恶意买家完全可以在 10 分钟后再次下单，或者采用一次下单很多件的方式把库存减完。
	- 结合安全和反作弊的措施：
		- 给经常下单不付款的买家进行识别打标
		- 给某些类目设置最大购买件数
		- 以及对重复下单不付款的操作进行次数限制
		- ......
#### 4.4.5.2 缓存扣减
lua脚本实现原子性，**防止超卖**。
前提：如果你的秒杀商品的减库存逻辑非常单一，比如没有复杂的 SKU 库存和总库存这种联动关系的话，我觉得完全可以。但是如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存。

Redis 挂了后库存数据恢复的核心是 “持久化 + 兜底校验 + 故障转移”，确保缓存数据不丢失、恢复后与数据库一致。
##### 4.4.5.2.1 核心恢复原则
Redis 库存数据恢复的核心是 “双重保障”：一是通过 Redis 自身持久化减少数据丢失，二是依赖数据库底账做最终校验，避免恢复后数据不一致。
##### 4.4.5.2.2 Redis 层面：减少库存数据丢失
通过 Redis 持久化机制，确保挂了之后能恢复大部分库存数据，减少丢失范围。
1. 开启混合持久化（RDB+AOF）
	- RDB：定时生成内存快照（如每 5 分钟，或满足 “1000 次写操作 + 60 秒”），保存库存键（如`seckill:stock:${goodsId}`）的当前值。
	- AOF：记录每一次库存扣减的写操作（如`DECR seckill:stock:1001`），以日志形式追加到文件。
	- 混合模式：Redis 4.0 + 支持，AOF 文件头部是 RDB 快照，后续是增量 AOF 日志，兼顾 RDB 的恢复速度和 AOF 的完整性。
2. 关键配置优化
	- AOF 刷盘策略设为`everysec`：每秒将 AOF 缓冲区数据刷到磁盘，既保证性能，又将数据丢失风险控制在 1 秒内。
	- 关闭 AOF 重写期间的 fsync：避免重写时阻塞写操作，同时确保重写后日志完整。
3. 主从同步：开启 Redis 集群（主从 + 哨兵 / Cluster）：主节点挂了后，哨兵自动将从节点提升为主节点，从节点通过复制同步了主节点的库存数据，实现秒级故障转移，几乎无数据丢失。
##### 4.4.5.2.3 业务层面：兜底校验与数据一致性
即使 Redis 持久化恢复失败，也能通过数据库和业务逻辑兜底，确保库存数据准确。
1. 异步同步：每次 Redis 扣减库存后，通过消息队列发送 “库存变更日志” 到数据库，异步更新数据库。
	- 需要注意同步插入本地消息表防止消息丢失，然后用异步消息发送API。异步插入消息表+批量插入数据库可以提升性能，但有消息丢失风险。
	- 秒杀成功率低，所以对数据库插入压力不大。注意消息大小要小，快速插入。
	- 若 Redis 扣减成功，但数据库插入失败，需立即执行 Redis INCR 操作回滚库存，避免库存不一致。
2. 数据扣减库存和下单在同一事务：这样保障了一旦出什么事故也不会超卖
3. 定时对账：三层校验
	- 实时层：Redis 库存 vs 本地消息表（确保 Redis 操作完整，1 分钟 / 次）；
	- 中间层：本地消息表（已发送） vs 数据库订单 / 库存（确保消息被正确消费，5 分钟 / 次）；
	- 最终层：数据库库存 vs 订单汇总（确保数据库自身一致，10 分钟 / 次）。
4. 库存重加载：恢复时：从数据库读取对应商品的库存底账，重新写入 Redis，覆盖可能丢失的缓存数据。
	- 库存重加载需加锁：避免多实例同时重加载导致 Redis 库存被重复覆盖
	- 还需要等消息队列中的消息都消费完，才能同步到redis
5. 故障期间的降级处理
	- Redis 挂了后，暂时降级为 “数据库直接处理库存”。注意要通过限流+排队+降级保护数据库，防止被冲垮。
	- 待 Redis 恢复并加载完数据库底账后，再切回 “Redis 扣减 + DB 兜底” 模式。
##### 4.4.5.2.4 具体恢复流程（Redis 挂了之后）
1. **故障检测**：哨兵或监控系统发现 Redis 主节点挂了，触发告警。
2. **故障转移（集群场景）**：哨兵自动选举健康的从节点升级为主节点，应用通过哨兵获取新主节点地址。
3. **单机恢复（非集群场景）**：重启 Redis，优先通过混合持久化文件恢复数据：先加载 RDB 快照，再回放 AOF 增量日志，恢复到挂掉前的库存状态。
4. **库存重加载**：从数据库读取对应商品库存，重新写入 Redis。
5. **解除限制**：逐步放宽接入层限流阈值，恢复非核心业务逻辑
6. **恢复服务**：确认 Redis 库存与数据库一致后，恢复正常秒杀流程，Redis 继续承担高并发扣减任务。
#### 4.4.5.3 MySQL扣减
##### 4.4.5.3.1 基于数据库的乐观锁，防止超卖
```sql
update product set stock=stock-1 where id=product and stock > 0;
```

还需要解决热点商品占满数据库连接、和高并发抢锁的问题
##### 4.4.5.3.2 排队
- Redis分布式锁：将并发控制从数据库层上移到缓存层。优点是响应延迟低，缺点是单商品QPS低（500-1000 QPS），适合中小规模秒杀
- 应用层做排队：按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量。
	- 应用层只能做到单机的排队，但是应用机器数本身很多，可能一个商品在很多机器上都有队列，所以这种排队方式控制并发的能力仍然有限。
	- 注意队列限流，给每个商品的本地队列设置容量上限（如 500 条），超过则直接返回 “系统繁忙，请重试”，避免队列无限堆积导致超时。同时监控队列长度，超过阈值（如 300 条）则触发告警，手动扩容机器。
	- 负载均衡要确保同一商品的请求均匀分布到所有应用机器，避免单台机器被热点商品压垮。
- 消息队列排队：
	- 优点是流量削峰能力强，支持更大的QPS
		- 故障隔离，系统容错性更强：若 MySQL 临时不可用，消费端可暂停消费，消息队列会持久化存储消息，待 MySQL 恢复后继续处理，避免请求丢失
		- 支持动态扩容，弹性应对流量：秒杀过程中若消息堆积，可快速扩容消费端实例（如从 2 台增至 10 台），分摊处理压力，比纯 MySQL 方案的扩容更灵活（无需调整分表分片）。
	- 缺点是请求变成异步，需要额外想办法通知用户结果
		- 增加维护成本，消息丢失、重复消费等问题都要解决
- 数据库层做排队：阿里的数据库团队开发了针对这种 MySQL 的 InnoDB 层上的补丁程序（patch），可以在数据库层上对单行记录做到并发排队。
	- 缺点：依赖特定 MySQL 分支，通用性差；维护成本高，需深度数据库经验，不适合中小团队；排队延迟可能累积，不适合低延迟场景。

总结：

| 方案            | 削峰能力                | 一致性保障难度            | 延迟情况        | 维护成本         | 适用场景                      |
| ------------- | ------------------- | ------------------ | ----------- | ------------ | ------------------------- |
| 消息队列方案        | 强（支持 10 万 + QPS 峰值） | 高（需处理丢失 / 重复 / 顺序） | 中（1-5 秒）    | 中（需维护 MQ）    | 中大规模秒杀，容忍延迟               |
| InnoDB 排队补丁方案 | 3000-5000 TPS       | 低                  | 中（排队延迟）     | 高（需内核经验）     | 大规模秒杀，依赖 MySQL 生态，团队有内核能力 |
| 应用层本地队列方案     | 中（支持 2000-5000 QPS） | 低（仅单机器串行）          | 低（10-100ms） | 低（无额外组件）     | 中小规模秒杀，追求低延迟              |
| Redis 分布式锁方案  | 弱（支持 500-1000 QPS）  | 中（需处理锁超时 / 死锁）     | 低（5-20ms）   | 中（需维护 Redis） | 小规模秒杀，对一致性要求高             |
##### 4.4.5.3.3 避免缓存失效风暴——缓存更新不删除
高并发秒杀场景下，“数据库扣减库存 + 缓存频繁失效” 会导致 缓存命中率骤降至极低，缓存几乎形同虚设，所有请求最终都穿透到数据库，反而引发数据库压力飙升 —— 这就是秒杀场景中典型的 “**缓存失效风暴**”。

因此，可以考虑数据库库存更新成功，就更新缓存值而非删除。
只要满足以下条件，这个策略就能稳得住：
1. 秒杀规模中等：单商品峰值 QPS<5000，库存扣减频率 < 100 次 / 秒（不会出现 “每秒几十次缓存更新” 压垮 Redis）；
2. 库存变更单一：主要是 “扣减库存”，极少有 “补库存、退库存” 等反向操作（避免缓存更新逻辑复杂）；
3. 能容忍短窗口不一致：比如缓存更新延迟 1-10ms（多机器并发更新可能导致），用户感知不到。

虽然策略简单，但高并发下仍有几个细节要注意，否则可能出现 “缓存值错误”：
1. 多机器并发更新缓存，导致 “旧值覆盖新值”：轻量解决：给缓存加 “版本号”，确保只有 “新值” 能覆盖 “旧值”：
	- 缓存键设计：`stock:{goodsId}` 存库存值，`stock:version:{goodsId}` 存版本号（每次扣减 + 1）；
	- 更新逻辑：
	    1. 数据库扣减时，同时更新版本号（`UPDATE seckill_stock SET stock=stock-1, version=version+1 WHERE goods_id=? AND stock>=1`）；
	    2. 缓存更新时，先查 Redis 的当前版本号，仅当 “数据库版本号> Redis 版本号” 时，才更新缓存（`IF version_db > version_redis THEN SET stock=新值, version=version_db`）；
	- 优势：仅增加一个版本号字段，逻辑极简，完全避免旧值覆盖新值。
2. 库存售罄后，缓存未及时更新为 0
	- 问题：数据库库存已扣减至 0，但某机器因网络延迟，仍将 “1” 写入缓存，导致后续请求看到 “有库存” 并穿透到数据库（虽数据库会返回 0，但浪费资源）。
	- 轻量解决：售罄时 “强制锁定缓存”：
		- 数据库扣减后，若查询到库存 = 0，直接给 Redis 缓存设置 “库存 = 0”+ 较长过期时间（如 1 小时）；
		- 同时通过 Redis 发布订阅，广播 “商品售罄” 消息，所有机器收到后，立即将本地缓存更新为 0 并锁定（不再更新）；
		- 优势：仅在 “售罄” 这一个特殊节点加逻辑，简单且能彻底杜绝售罄后的穿透。
##### 4.4.5.3.4 避免缓存失效风暴——批量更新
这种方法，不再每次扣减库存都删除缓存，而是累计一定次数 / 时间后，批量更新缓存，延长缓存有效时间：
- **操作逻辑**：
    1. 数据库扣减库存时，不立即删除缓存，而是记录 “库存变更次数”（如用 Redis 计数器`stock:update:count:{goodsId}`）；
    2. 当计数器达到阈值（如 10 次扣减），或间隔达到阈值（如 500ms），触发 “批量更新缓存”：查询数据库最新库存，写入 Redis 和本地缓存；
    3. 若库存已降至 0，直接写入 “库存 = 0” 的缓存，并设置较长过期时间（如 1 小时），彻底杜绝后续穿透。
- **关键优势**：缓存失效频率从 “每秒 500 次” 降至 “每秒 2-10 次”（按 500ms 间隔），命中率大幅提升；
- **一致性保障**：最大不一致窗口 = 500ms，远低于用户感知阈值，且库存为 0 时立即锁定缓存，无超卖风险。

以下 “极端场景”可以考虑：
1. 单商品峰值 QPS>1 万，库存扣减频率 > 300 次 / 秒（Redis 写 QPS 接近瓶颈）；
2. Redis 集群性能有限，无法承载高频写操作（如单机 Redis，写 QPS 上限约 1 万）；
3. 业务对 Redis 写延迟敏感（如高频写导致 Redis 响应时间 > 50ms）。
##### 4.4.5.3.5 其他优化
- 热点商品动态迁移到单独库中
- 事务轻量化：避免大事务，事务内不进行复杂计算；拆分事务，仅 “扣减库存” 放在独立事务，订单创建、日志记录等移至事务外异步执行（通过本地消息表或 MQ）。
## 4.5 用户体验
### 4.5.1 异步请求怎么通知用户结果
有以下两种方案：
1. 一是可以给前端一个查询接口轮询，这种查询流量，因为后端完全知晓结果, 可以全部放到redis中(甚至local cache), 不会有穿透到DB的流量, 因此可以做到速度很快。实现也简单，兼容所有浏览器/APP。缺点是服务端的请求数会增加不少，有轻微服务器压力。
2. 二是采用主动 push 的方式，也就是 WebSocket/Server-Sent Events（SSE）技术，这种就要求服务端和客户端保持长连接了。它是实时推送（推荐，适合高并发），无轮询压力，用户体验最佳。缺点是服务端的连接数会比较多，需处理长连接断开重连（如每隔 30 秒心跳检测，断开后自动重连）。

此外要有多渠道结果通知，确保用户 “不错过” 结果。若用户提交请求后关闭页面 / APP，通过短信、APP 推送、站内信告知结果。

如果异步的请求失败直接丢弃就好了，最坏的结果就是这个人没有抢到而已。
## 4.6 事后复盘优化
每次秒杀活动结束后，都要进行全面的复盘分析：
- 数据统计：统计活动的各项数据，包括参与人数、成功人数、成功率、峰值 QPS、平均响应时间等；
- 问题分析：分析活动中出现的问题，如系统故障、性能瓶颈、用户投诉等，找出问题的根本原因；
- 性能评估：评估系统的性能表现，与预期目标对比，分析差距和改进空间；
- 用户反馈：收集用户的反馈意见，了解用户体验，发现产品和流程的改进点；
- 优化建议：根据复盘结果，提出系统优化建议，包括架构调整、代码优化、流程改进等。


---
# 5 引用